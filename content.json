{"meta":{"title":"Data Science YJ","subtitle":"Yujin's study blog for Data Science","description":null,"author":"Yujin Jeon","url":"https://jyujin39.github.io"},"pages":[{"title":"","date":"2019-09-23T04:14:17.296Z","updated":"2018-12-18T05:28:36.000Z","comments":true,"path":"images/모형결합.html","permalink":"https://jyujin39.github.io/images/모형결합.html","excerpt":"","text":"모형 결합모형 결합(model combining) 방법은 앙상블 방법론(ensemble methods)라고도 한다. 단일모형으로 예측이 잘 되지 않을 때, 복수의 모형을 결합해 예측성능을 높이고자 할 때 사용한다. 장점 개별 모형의 성능이 안좋을 때는 결합모형을 하게 되면 성능이 향상된다. 단일모형으로 할 때보다 과최적화를 방지할 수 있다. 모형 결합 방법은 크게 취합(aggregation) 방법론과 부스팅(boosting) 방법론으로 나눌 수 있다. 취합(aggregation) 처음부터 여러 모델로 한 문제를 푼다. 부스팅(boosting) 한 모델이 문제를 풀다가 잘 못하면 그 다음 다른모형을 투입한다. 그 두 모형이 풀다가 잘 못푸는 문제가 생기면 한 모델을 또 추가한다. 모형마다 하는 역할이 다르다. 각 방법론의 대표적인 방법들은 아래와 같다. 취합 방법론 다수결 (Majority Voting) 배깅 (Bagging) 랜덤 포레스트 (Random Forests) 부스팅 방법론 에이다부스트 (AdaBoost) 그레디언트 부스트 (Gradient Boost) 1. 취합 aggregation1) 다수결 방법: 가장 단순한 모형결합 방법으로, 전혀 다른 모형끼리도 결합할 수 있다. 5가지 모형이 있으면 그 5개의 모형들로 하나의 분류문제를 다 풀어본다. scikitlearn의 ensemble 서브패키지는 다수결 방법을 위해 VotingClassifier 클래스를 제공하는데, 이를 이용해 모형들을 합치면 이 세 모형이 마치 하나의 모델인것처럼 사용할 수 있게 된다. 이렇게 모델을 취합하는 방법은 두 가지로 나뉜다. hard voting: 모형들의 가중치가 모두 동일한 단순투표. 개별모형의 결과를 단순히 취합. soft voting: 모형마다 가중치를 다르게 주는 가중치 투표. 개별모형의 조건부 확률값을 취합. 두 방식으로 각각 했을때 분류 결과가 달라진다. 예를 들어 로지스틱 회귀모형, QDA 모형, 가우시안 나이브 베이즈 모형, 이 세 가지 모형으로 하나의 이진분류 문제를 다수결방법으로 푼다고 하자. 이 때 가우시안 나이브 베이즈모형에만 다른 모형들에 비해 가중치를 두 배로 주고 예측을 진행하면, 각각의 모형에서 예측한 클래스와 소프트 보팅으로 다수결방법을 했을 때 예측된 클래스는 다음과 같다. 소프트 다수결 모형은 각 모형마다의 가중치를 고려해 확률값의 합으로 클래스를 결정하기 때문에 세 모델의 조건부확률값의 합이 더 큰 클래스 2로 예측한다. 그러나 만약 하드 다수결모형을 사용했다면 1개의 모델(QDA)에서만 선택된 클래스 2가 아닌, 나머지 2개의 모델에서 예측된 클래스 1을 답으로 예측해내게 된다. 모형 결합을 사용한 성능 향상다수결 모형의 핵심가정 : 개별 모델들은 상호간에 영향을 받지 않고 독립적으로 문제를 예측한다. 위 가정을 따르면 N개의 모델이 모여 정답을 출력할 확률은 아래와 같아진다. \\sum^N_{k>\\frac{N}{2}}\\binom N k p^k (1-p)^{N-k}아래 그래프를 보면, 개별모형의 성능이 정답률 60프로일 때, 그런 모형이 10개가 모이면 성능이 80프로, 100개가 모이면 거의 99프로까지도 올라가는 것을 확인할 수 있다.. 다만, 개별모형의 성능이 50프로가 안되면 모형결합을 했을 때 오히려 더 성능이 나빠지는 것도 확인된다. 즉, 다수결모형을 만들 때는 최소한 정확도가 50은 넘는 개별모형들로 모아야 한다. 그런데 우리가 지금까지 배운 모형의 종류가 5개 정도밖에 안 되는데 어떻게 10개, 100개의 모형을 모을 수 있을까? 2) 배깅배깅(bagging)은 동일한 확률모형을 쓰지만 모형마다 데이터를 다르게 줌으로써 서로 다른 결과를 출력하는 다수의 모형을 만들어 다수결모형을 적용하는 방법이다. 부트스트래핑이나 크로스 밸리데이션에서처럼 트레이닝데이터를 랜덤하게 선택해서 각각의 모형에 주면 모형마다 다른 결과가 나오게 된다. 이런 식으로 다른 결과를 출력하는 모델들을 많이 만들어내는 것이다. 배깅은 트레이닝데이터를 선택하는 방식에 따라 다음과 같이 부르기도 한다. 같은 데이터 샘플을 중복사용(replacement)하지 않으면: Pasting 같은 데이터 샘플을 중복사용하면: Bagging 데이터가 아니라 다차원 독립변수 중 일부 차원을 선택하는 경우는: Random Subspaces 데이터 샘플과 독립변수 차원 모두 일부만 랜덤하게 사용하면: Random Patches 배깅 방법은 회귀분석, 분류 등 어떤 문제도 풀어낸다는 장점이 있지만, 계산량이 많다는 단점이 있다. Scikit-Learn 의 ensemble 서브패키지는 배깅 모형 결합을 위한 BaggingClassifier 클래스를 제공한다. 아래는 모형 한 개를 사용했을 때와 배깅모형을 사용했을 때의 분류 결과를 시각화한 것이다. depth=5로 설정한 개별모형 빨간 영역 안에 끼어들어간 녹색 아웃라이어 데이터를 분류하기 위해 그 위치에 해당하는 부분만 영역이 나누어졌다. 하지만 이것은 분명한 오버피팅이다. 그 영역에 새로운 데이터가 들어온다면 빨간색일 가능성이 높은데 녹색으로 분류되어버리기 때문이다. 배깅 모형(10개의 개별모형을 합침) 배깅모형을 사용한 경우에는 오버피팅이 이루어지지 않은 것을 확인할 수 있다. 이유가 뭘까? 배깅방법은 모델들에 데이터를 분배하기 때문에 각 모델에는 데이터의 일부만 들어가게 된다. 따라서 대부분의 모델에는 아웃라이어인 데이터가 안들어갔을 확률이 높다. 즉, 여러 모델 중 아웃라이어에 대해 오버피팅을 하지 않은 모델이 더 많게 된다. 이러한 모델들로 다수결을 하게 되면 오버피팅 발생 확률이 낮아진다. 자동으로 정규화가 되는 것이다. 3) 랜덤 포레스트의사결정나무 여러 개를 개별모형으로 사용해서 포레스트라는 이름이 붙여진 랜덤포레스트(Random Forest)는 정말 많이 사용되는 다수결방법이다. 배깅과 마찬가지로 랜덤포레스트 방법에서는 트리 여러 개에 데이터들을 분배해서 준다. 각 트리에서 하위 노드로 내려갈 때는, 부모노드에서썼던 그 변수를 그대로 선택하는 게 아니라 전체 데이터에서 다시 한 번 서브스페이싱(subspacing)을 해서 랜덤하게 변수를 선택해 사용한다. 노드마다마다 이렇게 랜덤하게 데이터 서브스페이싱을 새로 한다. 이렇게 하면 개별모델들의 독립성이 증가해 모형성능의 변동이 감소하는 효과가 있다. 원래 개별 의사결정나무는 greedy한 선택, 즉 위에서 내려올 때 항상 그순간에 가장 좋은 변수를 사용한다. 그런데 랜덤포레스트는 제약조건을 줘서 non-greedy한 변수선택을 한다. 랜덤포레스트의 극단적 형태인 Extremely Randomized Trees 모형은 맨 처음 변수를 분배할 때부터 어디부터 어디까지 특정 범위로 주는게 아니라 각 노드마다 아예 하나의 변수를 랜덤하게 준다. 랜덤 포레스트의 장점 중 하나는 각 독립변수의 중요도(Feature Importance)를 계산할 수 있다는 점이다. feature importance 랜덤하게 선택된 변수들의 IG, 즉 아래 노드로 내려가면서 엔트로피가 얼마나 감소하는지를 비교해보면 각 변수의 중요도를 계산할 수 있다. 의사결정나무의 경우 선택되는 변수들이 정해져 있기 때문에 선택 기회조차 얻지 못하는 변수들에 대해서는 IG를 계산하기가 힘들다. 그런데 랜덤포레스트의 경우 변수가 랜덤으로 선택되기 때문에 좀더 공정하게 변수들의 중요도를 파악할 수 있다. 2. 부스팅 boosting한 번에 하나씩 모형을 추가하고, 각 모형은 서로 다른 문제를 푼다. 추가되는 모형의 목표는 이전에 추가되어온 모형 혹은 모형들이 잘 못 푼 문제를 푸는 것이다. 이진분류에만 쓸 수 있으며, class값은 1 혹은 -1이다. 새로운 모형이 추가될 때 해당 모형의 가중치가 결정된다. C_m(x_i) = \\text{sign}(\\alpha_1k_1(x_i) + \\cdots + \\alpha_mk_m(x_i))1) 에이다부스트adaptive + boost = adaboost 1부터 N까지의 트레이닝 데이터에 대해, km이 분류를 해서 1 혹은 -1의 답을 낸다. 그 답이 정답이라면 0점, 오답이라면 1점을 부여. 틀리면 벌점 1점이 생기는 벌점제도와 같다. 벌점을 최소화하는 모델을 찾아 선택한다. L_m = \\sum_{i=1}^N w_{m,i}I(k_m(x_i)\\neq y_i)$I$ : 0 혹은 1 $w_m$ : 모델마다 다른 가중치(벌점). 문제를 틀려서 얻는 벌점은 모델마다 다르다. 어떤 로직에 의해 이미 결정된 수치. 모델을 선택한 후 가중치 $\\alpha_m$ 을 결정해야 한다. \\epsilon_m = \\dfrac{\\Sigma^N_{i=1} w_{m,i}I(k_m(x_i)\\neq y_i)}{\\Sigma^N_{i=1}w_{m,i}}$\\epsilon _m$: 벌점을 0-1사이로 정규화한 점수. 분모: 다 틀렸을 때 계산된 벌점 분자: 실제 틀린 문제에 대한 벌점. 즉, 모델의 성능 \\alpha_m = \\frac{1}{2}\\log\\left(\\frac{1-\\epsilon_m}{\\epsilon_m}\\right)위 L은 k번째 멤버에 대한 손실함수이고, 에이다부스팅은 아래와 같이 전체 모형집단에 대한 손실함수를 최소화하는 모형집단을 찾아나가는 과정이라고 볼 수 있다. L_m = \\sum^N_{i=1} \\exp(-y_iC_m(x_i))결국 이걸 최소화하는거나 위 손실함수를 최소화하는 거나 똑같다. 그전에 적용한 모형이 정답을 맞추지 못한 데이터는 가중치가 커지고 맞춘애들은 가중치가 작게 돼서 다음 모델이 가중치가 커진 데이터를 중점으로 분류를 하게 된다. 2) 그레디언트 부스트변분법을 사용한 모형이다. 손실 범함수(loss functional)를 최소화하는 개별 분류함수 $k_m$ 을 찾는다. C_m = C_{m-1} - \\alpha_m \\dfrac{\\delta L(y,C_{m-1})}{\\delta C_{m-1}} = C_{m-1} + \\alpha_m k_m결국 범함수를 최적화하는 과정. 앞에서는 기존의 데이터에서 가중치만 바꿔서 잘 추정하는 $k_m$ 을 선택했다면 여기서는 범함수의 그레디언트와 가장 비슷한 $k_m$ 을 찾는다. 만약 손실범함수가 오차제곱형태라면 , L(y, C_{m-1}) = \\frac{1}{2}(y-C_{m-1})^2범함수의 미분은 실제 목푯값 y와 $C_{m-1}$ 과의 차이, 즉 잔차가 된다. -\\frac{dL(y,C_m)}{dC_m} = y - C_{m-1}이때는 이전 모델과 y와의 잔차와 가장 비슷한 다음 모델을 찾는 것이 그레디언트부스팅 방법이 된다. 그래디언트 부스팅만을 전문으로 구현해놓은 라이브러리들이 있다. XGBoost 라이브러리 :scikit learn에 비해 빠르다. Light GBM (gradient boosting machine) 라이브러리 : xgboost보다 더 빨라서 많이 쓰인다. 그래디언트 부스팅모델에 들어가게 되는 것은 함수이므로 decision tree classifier가 아니라 decision tree regressor이다. 따라서 개별 모형들은 0 또는 1의 클래스가 아니라 각각 다른 높이를 지닌 계단식 함수값을 출력한다. 그걸 다 합쳤을 때 최종결과에서 바이너리 클래스로 분류하게 되는 것이다."},{"title":"","date":"2019-09-23T04:14:17.309Z","updated":"2018-12-18T13:44:50.000Z","comments":true,"path":"images/모형결합2.html","permalink":"https://jyujin39.github.io/images/모형결합2.html","excerpt":"","text":"2. 부스팅 boosting부스트(boost) 방법은 처음부터 여러 개의 모형을 합쳐 문제를 푸는 취합(aggregation)과 달리 하나의 모형에서 시작해 하나씩 모형을 추가해나간다. 이 때 모형들의 집합을 위원회(commitee) $C$ 라고 하고, m개의 모형을 갖는 위원회를 $C_m$ 으로 표시한다. 위원회에 포함된 개별모형은 weak classifier라고 부르며 $k$ 로 표시한다. C_1 = {k_1}\\\\ C_2 = C1 \\cup k_2 = \\{k_1,k_2\\}\\\\ \\vdots\\\\ C_m = C_{m-1} \\cup k_m = \\{k_1,k_2,\\cdots ,k_m\\}m번째로 위원회에 추가되는 개별모형 $k_m$ 의 목표는 이전단계의 위원회 $C_{m-1}$ 이 잘 못 푼 문제를 풀어내는 것이다. 위원회의 최종 결정은 다수결 방법을 사용하지 않고 각각의 개별모형의 출력을 가중치 $\\alpha$ 로 가중선형조합한 값을 판별함수로 사용한다. 새로운 모형이 추가될 때 해당 모형의 가중치가 결정된다. 이진분류에만 쓸 수 있으며, y 값은 1 혹은 -1이다. y = -1 \\,\\,\\,\\text{or}\\,\\,\\, 1 C_m(x_i) = \\text{sign}(\\alpha_1k_1(x_i) + \\cdots + \\alpha_mk_m(x_i))1) 에이다부스트에이다부스트(adaboost)는 적응부스트(adaptive + boost)에서 나온 이름이다. 에이다부스트에서는 위원회에 추가할 개별모형 $k_m$ 을 선별하는 방법으로, 학습데이터 집합의 i번째 데이터에 가중치 $w_i$ 를 주고 분류모형이 틀리게 예측한 데이터의 가중치를 합한 값을 손실함수 L로 사용한다. 이 손실함수값을 최소화하는 모형을 $k_m$ 으로 선택한다. 쉽게 설명하면, 1부터 N까지의 트레이닝 데이터에 대해 새로운 개별모형 $k_m$이 분류를 해서 1 혹은 -1의 답을 낸다. 그 답이 정답이라면 0점, 오답이라면 1점을 부여한다. 즉, 틀리면 벌점 1점을 받는 벌점제도와 같다. 각 데이터에 대해 얻어진 이 벌점의 가중합을 최소화하는 모델을 찾아내는 것이다. L_m = \\sum_{i=1}^N w_{m,i}I(k_m(x_i)\\neq y_i)위 손실함수 $L_m$에서 $I$ 가 벌점에 해당한다. 즉 0 혹은 1값을 갖는 지시함수 역할을 한다. 그리고 $w_{m,i}$ 은 모델마다, 또 데이터마다 주어지는 가중치로, 특정 로직에 의해 이미 결정된 수치이다. 따라서 손실함수 $L$은 예측이 틀렸을 경우에만 해당 데이터에 주어진 가중치에 1이 곱해져 더하는, 즉 틀린 문제에 대한 가중치의 합이 된다. 이렇게 손실함수값을 최소화하는 개별모형 $k_m$ 이 선택된 후에는 개별 모형의 출력값에 대한 가중치 $\\alpha_m$ 을 결정해야 한다. 이 값을 계산하려면 먼저 다음 식이 필요하다. \\epsilon_m = \\dfrac{\\Sigma^N_{i=1} w_{m,i}I(k_m(x_i)\\neq y_i)}{\\Sigma^N_{i=1}w_{m,i}}$\\epsilon _m$ 은 벌점을 0-1사이로 정규화한 점수이다. 분모는 모든 데이터 예측을 다 틀렸을 때 계산된 벌점, 분자는 실제 틀린 문제에 대한 벌점을 의미한다. 데이터에 대한 가중치 $w_{m,i}$는 맨 처음 위원회에 모델이 1개일 경우 모든 데이터에 대해 같은 값을 갖지만, 위원회 멤버가 증가하면서 값이 바뀐다. 가중치 값은 지수함수를 사용해 맞춘 문제는 작게, 틀린 문제는 크게 확대(boosting)된다. 즉, 그 전에 적용한 모형이 정답을 맞추지 못한 데이터는 가중치가 커지고 맞춘 데이터들의 가중치는 작아져서 다음 추가된 모형은 가중치가 커진 데이터에 중점을 두고 분류를 하게 된다. w_{m,i} = w_{m-1,i}\\exp(-y_iC_{m-1}) = \\begin{cases}w_{m-1,i}e^{-1} && \\text{if}\\,\\, C_{m-1} = y_i\\\\ w_{m-1,i}e && \\text{if} \\,\\, C_{m-1} \\neq y_i \\end{cases}결국 에이다부스팅은 아래와 같이 전체 모형집단에 대한 손실함수를 최소화하는 모형집단을 찾아나가는 과정이라고 볼 수 있다. L_m = \\sum^N_{i=1} \\exp(-y_iC_m(x_i))이에 따라 유도된 가중치 $\\alpha_m$ 의 공식은 다음과 같다. \\alpha_m = \\frac{1}{2}\\log\\left(\\frac{1-\\epsilon_m}{\\epsilon_m}\\right)다음은 scikit-learn의 ensemble 서브패키지가 제공하는 AdaBoostClassifier 클래스를 사용하여 분류 예측을 하는 예이다. 약분류기로는 깊이가 1인 단순한 의사결정나무를 채택하였다. 각 단계의 분류 모형에 대한 가중치 값과 분류 모형의 분류 결과를 시각화하면 다음과 같다. 데이터의 가중치는 스캐터플롯의 점의 크기로 표현하였다. 단계가 진행될 수록 가중치값의 변화가 커지는 것을 볼 수 있다. 2) 그레디언트 부스트그레디언트 부스트(gradient boost) 모형은 변분법(calculus of variations)을 사용한 모형이다. 손실 범함수(loss functional) $ L(y, C_{m-1})$를 최소화하는 개별 분류모형 $k_m$ 을 찾는다. 이론적으로 가장 최적의 $k_m$은 범함수의 미분이다. C_m = C_{m-1} - \\alpha_m \\dfrac{\\delta L(y,C_{m-1})}{\\delta C_{m-1}} = C_{m-1} + \\alpha_m k_m결국 그레디언트 부스트는 범함수를 최적화하는 과정이다. 앞에서는 기존의 데이터에서 가중치만 바꿔서 최적의 $k_m$ 을 선택했다면 여기서는 범함수의 그레디언트와 가장 비슷한 $k_m$ 을 찾는다. 그레디언트 부스트모형에서는 다음과 같은 과정을 반복해 개별모형과 그 가중치를 계산한다. $-\\frac{\\delta L(y,C_m)}{\\delta C_m}$ 을 목표값으로 개별 멤버 모형 $k_m$ 을 찾는다. $\\left(y - (C_{m-1} + \\alpha_m k_m)\\right)^2$ 를 최소화하는 스텝사이즈 $\\alpha_m$ 을 찾는다. $C_m = C_{m-1} + \\alpha_m k_m$ 최종 모형을 갱신한다. 만약 손실범함수가 오차제곱형태라면 , L(y, C_{m-1}) = \\frac{1}{2}(y-C_{m-1})^2범함수의 미분은 실제 목푯값 y와 $C_{m-1}$ 과의 차이, 즉 잔차(residual)가 된다. -\\frac{dL(y,C_m)}{dC_m} = y - C_{m-1}이 값과 가장 비슷한 다음 모델을 찾는 것이 그레디언트부스팅 방법이 된다. scikit learn의 ensemble 에서는 그레이디언트부스팅방법을 위해 GradientBoostingClassifier 를 제공하지만, 그보다 그레디언트 부스팅만을 전문으로 구현해놓은 라이브러리들을 사용하는 것이 더 좋다. XGBoost 라이브러리 :scikit learn에 비해 빠르다. Light GBM (gradient boosting machine) 라이브러리 : xgboost보다 더 빨라서 많이 쓰인다. 그래디언트 부스팅모델에 들어가게 되는 인수는 함수이므로 decision tree classifier가 아니라 decision tree regressor이다. 따라서 개별 모형들은 0 또는 1의 클래스가 아니라 각각 다른 높이를 지닌 계단식 함수값을 출력한다. 그걸 다 합쳤을 때 최종결과에서 바이너리 클래스로 분류하게 되는 것이다. XGBoost 라이브러리 1234import xgboostmodel_xgb = xgboost.XGBClassifier(n_estimators=100, max_depth=1, random_state=0)model_xgb.fit(X_train, y_train) LightGBM 라이브러리 1234import lightgbmmodel_lgbm = lightgbm.LGBMClassifier(n_estimators=100, max_depth=1, random_state=0)model_lgbm.fit(X, y)"}],"posts":[{"title":"t-test","slug":"t-test","date":"2019-11-12T04:48:51.000Z","updated":"2019-11-12T04:52:54.607Z","comments":true,"path":"2019/11/12/t-test/","link":"","permalink":"https://jyujin39.github.io/2019/11/12/t-test/","excerpt":"","text":"t-testt-test는 데이터집단의 평균값(기댓값)을 조사하는 통계검정 방법이다. 하나의 데이터 집단에 대해 평균값을 조사하는 단일표본(One-sample) t-test와, 두 개의 데이터 집단에 대해 평균값이 같은지 다른지를 조사하는 독립표본(Independent-two-sample) t-test, 그리고 두 데이터집단의 표본데이터가 서로 1대1 대응하는 경우 두 집단의 평균값이 같은지를 확인하는 대응표본(Paired-two-sample) t-test가 있다. 여기서는 독립표본 t-test만을 살펴볼 것이다. 독립표본 t-test가 필요한 경우로 다음과 같은 상황을 예로 들 수 있다. ‘A반 남학생과 B반 남학생의 키는 비슷할까?’ 이 때 두 집단의 평균키가 통계적으로 유의미한 수준에서 비슷하면 두 집단의 키가 같다고 말할 수 있는데 이 통계검증방법이 t-test이다. t-test를 하기 앞서 갖추어야 할 조건이 있다. t-test의 조건 관측치가 정규분포를 따라야 한다. 두 집단은 서로 독립이어야 한다. 관측치데이터는 연속형이거나 등간격 척도여야 한다. 파이썬에서의 정규성 검정t-test의 첫 번째 조건, 데이터가 정규분포를 따르는지를 확인하는 검정을 정규성검정(normality test)이라고 한다. 정규성검정 방법은 다양하게 있는데, 대표적으로 콜모고로프-스미르노프 검정, 샤피로-윌크 검정 등이 있다. numpy를 이용해 정규분포를 따르는 표본 100개를 임의로 생성한 후 scipy를 이용해 샤피로-윌크 검정을 해보자. 12345import numpy as npimport scipy as spdata = np.random.normal(size=100)sp.stats.shapiro(data) (0.9859086871147156, 0.368507872306824) 코드를 실행하면 위와 같이 2개의 수치가 나오는데, 오른쪽에 있는 값이 p-value에 해당한다. p-value가 유의수준(0.05)보다 작으면 귀무가설을 기각하고, 크면 귀무가설을 채택한다. 여기서 귀무가설은 ‘데이터가 정규분포를 따른다’ 이고, p-value가 0.36이 나왔기 때문에 귀무가설을 기각할 수 없어 위 데이터는 정규분포를 따른다고 얘기할 수 있게 된다. 이렇게 정규성 검정을 통해 데이터의 정규성이 확인되면 t-test를 진행할 수 있다.","categories":[{"name":"Statistics","slug":"Statistics","permalink":"https://jyujin39.github.io/categories/Statistics/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"t-test","slug":"t-test","permalink":"https://jyujin39.github.io/tags/t-test/"},{"name":"statistics","slug":"statistics","permalink":"https://jyujin39.github.io/tags/statistics/"}]},{"title":"파이썬 코드를 정돈하기 위한 패턴","slug":"파이썬-코드를-정돈하기-위한-패턴","date":"2019-06-14T05:37:00.000Z","updated":"2019-06-14T05:37:48.000Z","comments":true,"path":"2019/06/14/파이썬-코드를-정돈하기-위한-패턴/","link":"","permalink":"https://jyujin39.github.io/2019/06/14/파이썬-코드를-정돈하기-위한-패턴/","excerpt":"","text":"2장. 파이썬 코드를 정돈하기 위한 패턴2.1 assert : 단언문어떤 조건을 테스트하는 디버깅 보조도구. 단언조건이 참이면 아무 일도 일어나지 않고, 거짓이면 AssertionError를 발생시킨다 12345def apply_discount(product, discount): price = int(product['price'] * (1.0 - discount)) assert 0 &lt;= price &lt;= product['price'], 'price out of range' return price 12shoes = &#123;'name':'Fancy Shoes', 'price':14900&#125;apply_discount(shoes, 0.25) 1apply_discount(shoes, 2.0) Traceback 을 통해 에러가 발생한 코드가 몇 번째 줄인지, 즉 에러의 근본원인을 금방 찾을 수 있기 때문에 디버깅이 쉬워진다. * 주의할 점: assert문의 첫 번째 인자로 튜플을 전달하게 되면, 튜플이 비어있지 않은 이상 파이썬에서 항상 참이기 때문에 어떤 경우에도 에러가 발생되지 않는다 1assert(1==2, 'this should fail') 1assert 1==2, 'this works' 2.2 보기 좋은 쉼표 배치리스트, 딕셔너리, 세트 등을 선언할 때 쉼표마다 행을 나누면 보기도 좋고 나중에 수정하기도 쉽다. 12345names = [ 'Alice', 'Bob', 'Jane', #마지막 행에도 쉼표를 붙여준다] 파이썬은 ‘문자열 리터럴 결합’을 하기 때문에 쉼표를 쓰지 않고 행을 나눠 문자열을 쓰는 경우 그 문자열이 하나로 합쳐지게 된다. 이 기능은 긴 문자열을 백슬래시를 쓰지 않고 쓰는 것에 유용하게 사용할 수 있다. 12345string = ('This is a super long string constant' 'spread out across multiple lines.' 'And look, no backslash characters needed!')string 2.3 with 문with문은 기능을 추상화하고 재사용할 수 있게 하여 리소스 관리패턴을 단순화해준다. with문을 사용해 파일을 열면 프로그램이 context를 벗어났을 때 파일이 자동으로 닫힌다. 12with open('file.txt', 'w') as f: f.write('hello') 이렇게 파일을 열면 내부적으로 아래와 같이 작동하기 때문에 f.write() 를 호출할 때 오류가 나더라도 오류를 발생시킨 후 파일을 닫는 것이 보장된다. 12345f = open('file.txt', 'w')try: f.write('hello')finally: f.close() 여기서 잠깐! try…finally 그리고 try…except가 어떻게 작동하는지 비교해보자. try는 무조건 finally 혹은 except가 따라와야 함을 알 수 있다. try$\\cdots$ finally try 다음에 finally를 쓰면, try에 있는 코드에 오류가 있을 때 그 오류가 출력된 후 다음 코드로 넘어가 finally 에 있는 코드가 실행된다. 1234try: [].find('a')finally: print('done') try$\\cdots$ except try 에 있는 코드에 오류가 있으면 if 문의 조건이 맞지 않을 때 else로 넘어가는 것처럼 바로 except 문으로 넘어가 해당 코드만이 실행된다. 1234try: [].find('a')except: print('done') try 문 이후에 아무것도 쓰지 않았을 경우 try 문의 코드에 오류가 있지만 try 문이 완전히 종료되지 않았기 때문에 다음 코드로 넘어가지만 기대했던finally 나 except 가 등장하지 않자 다음 코드에서 오류가 난다. 123try: [].find('a')print('done') try 없이 오류가 나는 코드를 실행시키는 경우 try 에 사용했을 때는 다음코드로 넘어갔지만 그냥 써주자 아예 해당 코드에서 오류가 나면서 다음줄로 넘어가지 못한다. 12[].find('a')print('done') 'python tricks the book' 책을 보고 정리한 내용입니다.:","categories":[{"name":"Python","slug":"Python","permalink":"https://jyujin39.github.io/categories/Python/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"coding","slug":"coding","permalink":"https://jyujin39.github.io/tags/coding/"},{"name":"python","slug":"python","permalink":"https://jyujin39.github.io/tags/python/"}]},{"title":"Stacks: Balanced Brackets","slug":"Stacks-Balanced-Brackets","date":"2019-05-18T08:25:18.000Z","updated":"2019-05-18T08:34:56.000Z","comments":true,"path":"2019/05/18/Stacks-Balanced-Brackets/","link":"","permalink":"https://jyujin39.github.io/2019/05/18/Stacks-Balanced-Brackets/","excerpt":"","text":"Stacks: Balanced BracketsA bracket is considered to be any one of the following characters: (, ), {, }, [, or ]. Two brackets are considered to be a matched pair if the an opening bracket (i.e., (, [, or {) occurs to the left of a closing bracket (i.e., ), ], or }) of the exact same type. There are three types of matched pairs of brackets: [], {}, and (). A matching pair of brackets is not balanced if the set of brackets it encloses are not matched. For example, {[(])} is not balanced because the contents in between { and } are not balanced. The pair of square brackets encloses a single, unbalanced opening bracket, (, and the pair of parentheses encloses a single, unbalanced closing square bracket, ]. Some examples of balanced brackets are []{}(), [({})]{}() and ({(){}[]})[]. By this logic, we say a sequence of brackets is considered to be balanced if the following conditions are met: It contains no unmatched brackets. The subset of brackets enclosed within the confines of a matched pair of brackets is also a matched pair of brackets. Given strings of brackets, determine whether each sequence of brackets is balanced. If a string is balanced, print YES on a new line; otherwise, print NO on a new line. Input FormatThe first line contains a single integer, $n$, denoting the number of strings. Each line $i$ of the $n$ subsequent lines consists of a single string, $s$, denoting a sequence of brackets. Constraints $1 \\le n \\le 10^3$ $1 \\le length(s) \\le 10^3$, where $length(s)$ is the length of the sequence. Each character in the sequence will be a bracket (i.e., {, }, (, ), [, and ]). Output FormatFor each string, print whether or not the string of brackets is balanced on a new line. If the brackets are balanced, print YES; otherwise, print NO. Sample Input12343&#123;[()]&#125;&#123;[(])&#125;&#123;&#123;[[(())]]&#125;&#125; Sample Output123YESNOYES My Answer Code12345678910111213141516171819def is_matched(expression): if len(expression) % 2 == 1: return False open_brackets = ['&#123;', '(', '['] closing_brackets = ['&#125;', ')', ']'] bracket_sets = dict(zip(open_brackets, closing_brackets)) open_b = [] for i in range(len(expression)): if expression[i] in open_brackets: open_b.append(expression[i]) else: if bracket_sets[open_b.pop()] != expression[i]: return False return True Test Code12345678t = int(input().strip())for _ in range(t): expression = input().strip() if is_matched(expression) == True: print(\"YES\") else: print(\"NO\") 1234567 3 (&#123;[]&#125;)YES &#123;[&#125;]NO &#123;[(((())))]&#125;YES","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"Algorithm test","slug":"Coding-drills/Algorithm-test","permalink":"https://jyujin39.github.io/categories/Coding-drills/Algorithm-test/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"algorithm","slug":"algorithm","permalink":"https://jyujin39.github.io/tags/algorithm/"},{"name":"coding","slug":"coding","permalink":"https://jyujin39.github.io/tags/coding/"}]},{"title":"Hash Tables: Ransom Note","slug":"Hash-Tables-Ransom-Note","date":"2019-05-16T13:26:54.000Z","updated":"2019-05-16T13:34:05.000Z","comments":true,"path":"2019/05/16/Hash-Tables-Ransom-Note/","link":"","permalink":"https://jyujin39.github.io/2019/05/16/Hash-Tables-Ransom-Note/","excerpt":"","text":"Hash Tables: Ransom NoteA kidnapper wrote a ransom note but is worried it will be traced back to him. He found a magazine and wants to know if he can cut out whole words from it and use them to create an untraceable replica of his ransom note. The words in his note are case-sensitive and he must use whole words available in the magazine, meaning he cannot use substrings or concatenation to create the words he needs. Given the words in the magazine and the words in the ransom note, print Yes if he can replicate his ransom note exactly using whole words from the magazine; otherwise, print No. Input FormatThe first line contains two space-separated integers describing the respective values of $m$ (the number of words in the magazine) and $n$ (the number of words in the ransom note). The second line contains $m$ space-separated strings denoting the words present in the magazine.The third line contains $n$ space-separated strings denoting the words present in the ransom note. Constraints $1 \\le m, n \\le 30000$ $1 \\le$ length of my any word $\\le 5$ Each word consists of English alphabetic letters (i.e., a to z and A to Z ). The words in the note and magazine are case-sensitive. Output FormatPrint Yes if he can use the magazine to create an untraceable replica of his ransom note; otherwise, print No. Sample Input 01236 4give me one grand today nightgive one grand today Sample Output 01Yes Sample Input 11236 5two times three is not fourtwo times two is four Sample Output 11No My Answer Code1234567891011from collections import Counterdef ransom_note(magazine, ransom): mag_counter = Counter(magazine) rans_counter = Counter(ransom) if rans_counter - mag_counter: return 'No' return 'Yes' Test Code Test code 1 12magazine = input().strip().split(' ')ransom = input().strip().split(' ') 12two times three is not fourtwo times two is four 1ransom_note(magazine, ransom) 1&apos;No&apos; Test code 2 12magazine = input().strip().split(' ')ransom = input().strip().split(' ') 12give me one grand today nightgive one grand today 1ransom_note(magazine, ransom) 1&apos;Yes&apos;","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"algorithm test","slug":"Coding-drills/algorithm-test","permalink":"https://jyujin39.github.io/categories/Coding-drills/algorithm-test/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"algorithm","slug":"algorithm","permalink":"https://jyujin39.github.io/tags/algorithm/"},{"name":"coding","slug":"coding","permalink":"https://jyujin39.github.io/tags/coding/"}]},{"title":"Strings: Making Anagrams","slug":"Strings-Making-Anagrams","date":"2019-05-15T05:32:48.000Z","updated":"2019-05-15T05:35:38.000Z","comments":true,"path":"2019/05/15/Strings-Making-Anagrams/","link":"","permalink":"https://jyujin39.github.io/2019/05/15/Strings-Making-Anagrams/","excerpt":"","text":"Strings: Making AnagramsAlice is taking a cryptography class and finding anagrams to be very useful. We consider two strings to be anagrams of each other if the first string’s letters can be rearranged to form the second string. In other words, both strings must contain the same exact letters in the same exact frequency For example, bacdc and dcbac are anagrams, but bacdc and dcbad are not. Alice decides on an encryption scheme involving two large strings where encryption is dependent on the minimum number of character deletions required to make the two strings anagrams. Can you help her find this number? Given two strings, $a$ and $b$, that may or may not be of the same length, determine the minimum number of character deletions required to make $a$ and $b$ anagrams. Any characters can be deleted from either of the strings. Input Format The first line contains a single string, $a$. The second line contains a single string, $b$. Constraints $1 \\le |a|, |b| \\le 10^4$ It is guaranteed that $a$ and $b$ consist of lowercase English alphabetic letters (i.e., $a$ through $z$). Output FormatPrint a single integer denoting the number of characters you must delete to make the two strings anagrams of each other. Sample Inputcde abc Sample Output4 ExplanationWe delete the following characters from our two strings to turn them into anagrams of each other:Remove d and e from cde to get c.Remove a and b from abc to get c.We must delete 4 characters to make both strings anagrams, so we print 4 on a new line. My Answer Code123456789101112131415161718192021222324def number_needed(a, b): def make_dict(string): dic = &#123;&#125; for char in string: if char in dic: dic[char] += 1 else: dic[char] = 1 return dic dic_a = make_dict(a) dic_b = make_dict(b) common_chars = list(dic_a.keys() &amp; dic_b.keys()) if not common_chars: return 'anagrams cannot be made out of these set of strings' stay_char = 0 for char in common_chars: stay_char += min(dic_a[char], dic_b[char]) return len(a) + len(b) - (stay_char * 2) Testing123a = 'cde'b = 'abc'number_needed(a, b) 14 123a = 'a'b = 'c'number_needed(a, b) 1&apos;anagrams cannot be made out of these set of strings&apos; 123a = 'bacdc'b = 'dcacb'number_needed(a, b) 10","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"algorithm test","slug":"Coding-drills/algorithm-test","permalink":"https://jyujin39.github.io/categories/Coding-drills/algorithm-test/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"algorithm","slug":"algorithm","permalink":"https://jyujin39.github.io/tags/algorithm/"},{"name":"coding","slug":"coding","permalink":"https://jyujin39.github.io/tags/coding/"}]},{"title":"Regex - [.*] 와 [.*?] 의 차이","slug":"Regex-와-의-차이","date":"2019-05-14T12:49:44.000Z","updated":"2019-05-14T12:55:03.000Z","comments":true,"path":"2019/05/14/Regex-와-의-차이/","link":"","permalink":"https://jyujin39.github.io/2019/05/14/Regex-와-의-차이/","excerpt":"","text":"Regex - [.*] 와 [.*?] 의 차이문서에서 [ ] 안에 들어있는 문자열을 괄호와 함께 모두 지워버려야 하는 상황이 생겼다. Regex 를 어떻게 쓰면 이 문제를 해결할 수 있을까? 우선 예시 문장을 하나 만들어 보았다. 1sent = \"Hello, this is an example sentence [for trying out regex grammar]. We are going to find [all of the phrases in the square bracket] including [this one] and [8#kd91?/*] and also just blank [].\" 결과로는 [for trying out regex grammar], [all of the phrases in the square bracket], [this one], [8#kd91?/*], 그리고 []까지 총 5개의 대괄호문자열이 삭제되고 나머지 문자열만이 남아있어야 한다. 우선 삭제하려는 문자열은 처음과 끝에 ‘[‘ 와 ‘]’를 무조건 포함해야 한다. 따라서 regex 문법에 따라 () 를 사용해주어야 한다. 대괄호는 regex 에서 사용했을 때 그 안에 들어있는 어떤 문자든 포함하는 경우 라는 특수한 의미를 갖는 regex 문법 기호이다. 그렇기 때문에 실제 대괄호를 문자열로써 인식해 찾아내야 하는 이와 같은 경우 \\ 로 그 문법에서 탈출시켜주어야 한다. \\[ \\] 와 같이 쓰면 된다. 이제 그 안에 어떤 문법을 작성해주느냐가 관건인데, 어떤 문자열이 한 번 이상 나와야 한다는 의미의 . 와 0번 이상 나와야 한다는 의미의 * 를 함께 사용해주면 다음과 같은 결과가 나온다. 바로 지워버리지 않고 실제로 regex가 어떤 문자열들을 찾아내는지 확인하기 위해 findall 를 찍어본다. 1re.findall('(\\[.*])', sent) 1[&apos;[for trying out regex grammar]. We are going to find [all of the phrases in the square bracket] including [this one] and [8#kd91?/*] and also just blank []&apos;] 그러자 위과 같이 하나의 결과값을 뱉어낸다. 자세히 보면 맨 문장에서 가장 처음 등장한 [ 와 가장 마지막에 등장한 ] 만을 대괄호로 인식하고, 그 안에 들어있는 문자열 전체를 통으로 뽑아내고 있음을 알 수 있다. 즉, 그 안에 있는 괄호 하나하나를 인식하지 못하는 것이다. Greedy match vs. Non-greedy match그 이유는 바로 . 과 * 는 기본적으로 greedy match를 수행하는 기호이기 때문이다. 그 의미인즉슨, 열어주는 대괄호 [ 를 처음 찾은 이후, 문서의 맨 끝으로 가서 뒤에서부터 역으로 닫아주는 대괄호 ] 를 찾게 된다는 뜻이다. 그런데 여기서 ? 를 써주게 되면, 앞에서부터 차근차근 찾아나가면서 매칭을 시켜주기 때문에 다음과 같이 찾고자 하는 모든 5개의 괄호문을 찾아낼 수 있다. 1re.findall('(\\[.*?\\])', sent) 12345[&apos;[for trying out regex grammar]&apos;, &apos;[all of the phrases in the square bracket]&apos;, &apos;[this one]&apos;, &apos;[8#kd91?/*]&apos;, &apos;[]&apos;] ? 는 greedy match에서 탈출시켜주는, 즉 non-greedy match를 가능하게 하는 역할을 하기 때문이다.","categories":[{"name":"Python","slug":"Python","permalink":"https://jyujin39.github.io/categories/Python/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"coding","slug":"coding","permalink":"https://jyujin39.github.io/tags/coding/"},{"name":"regex","slug":"regex","permalink":"https://jyujin39.github.io/tags/regex/"}]},{"title":"Gradient Vanishing","slug":"Gradient-Vanishing","date":"2019-04-09T06:47:34.000Z","updated":"2019-04-09T06:50:08.000Z","comments":true,"path":"2019/04/09/Gradient-Vanishing/","link":"","permalink":"https://jyujin39.github.io/2019/04/09/Gradient-Vanishing/","excerpt":"","text":"gradient vanishing problem신경망에서는 SGD(Stochastic Gradient Descent) 방법을 사용해 모델을 훈련시킨다. gradient의 Back Propagation을 통해 weight 값을 업데이트하며 오차가 작아지도록 훈련하게 된다. 신경망에 층을 많이 추가할수록 더 많은 데이터셋을 다룰 수 있는 복잡한 모델을 만들 수 있지만, 층이 많아지면 역전파 시에 그래디언트들이 점점 소실되는 문제가 발생한다. 한 가중치 값의 그래디언트가 처음부터 너무 작으면 input 층에 가까워질수록 점점 더 작아져서 거의 사라져버리는 경우이다. 이를 ‘Vanishing Gradient’ 문제라고 한다. 반대로 그래디언트값이 업데이트되면서 무한히 커져서 explode되는 경우도 발생하는데, 이는 ‘Exploding Gradient’ 문제라고 한다. Sigmoid Function시그모이드 함수는 모든 값을 0과 1사이로 만들어주기 때문에 classification 문제에서 유용하게 쓰일 수 있다. 하지만 시그모이드 함수의 그래디언트 값은 최대 0.25에 불과하고, 양쪽에서 거의 0에 수렴한다. 따라서 sigmoid 함수를 activation함수로 하는 layer가 여러 개 있다면, 그래디언트 역전파 시 0.25도 안 되는 그래디언트 값과 0에서 1 사이의 weight 초기값들이 곱해져나가면서 값이 점점 더 작아진다. ReLU Function0과 x 값의 max 함수 형태인 ReLU의 그래디언트값은 다음과 같이 값이 0보다 클 때는 1, 0보다 작을 때는 0이 된다. 이에 따라 ReLU에서는 그래디언트가 점점 작아져 소실되는 문제는 발생하지 않는다. 다만, input값이 0보다 작을 때는 그래디언트 값이 아예 0이 되어(‘die’) 해당 weight는 업데이트가 전혀 되지 못하고 학습이 이루어지지 않게 된다. 하지만 input값을 0과 1사이로 normalize 한 후 모델 학습을 진행하면 이러한 문제의 발생을 막을 수 있고, 오히려 sparse한 데이터의 경우 그래디언트가 죽어서 학습되지 않는 것이 장점으로 작용할 수도 있다. ReLU 및 Leaky ReLU에도 단점이 있다. input 값이 0보다 클 때에는 그 값을 그대로 출력하는 활성화함수이기 때문에, 층을 거치면서 출력값이 explode할 수 있다. 또한, 그래디언트 값이 1이라도 weight 값이 곱해지기 때문에 그래디언트 소실 문제가 발생할 확률이 없는 것은 아니다.","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://jyujin39.github.io/categories/Machine-Learning/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"서포트 벡터 머신(SVM)","slug":"post","date":"2019-03-31T08:39:41.000Z","updated":"2019-11-12T04:51:28.436Z","comments":true,"path":"2019/03/31/post/","link":"","permalink":"https://jyujin39.github.io/2019/03/31/post/","excerpt":"","text":"서포트 벡터 머신(SVM)서포트 벡터 머신(Support Vector Machine, SVM)은 선형, 비선형, 분류, 회귀 등 다목적으로 사용할 수 있는 머신러닝 모델이다. 복잡한 분류문제에 특히 잘 맞으며 작거나 중간크기의 데이터셋에 적합하다. 1. 선형 SVM 분류선형 SVM 분류기는 클래스들 사이에 결정경계선을 긋되, 그 선이 모든 클래스로부터 최대한 멀리 떨어져있을 수 있도록 한다. 따라서 라지 마진 분류(large margin classification) 라고도 한다. 이 경계선을 결정짓는 것은 각 클래스에서 해당 선으로부터 가장 가까운 샘플이다. 이 샘플을 서포트 벡터(support vector)라고 한다. SVM은 특성의 스케일에 매우 민감해서, 사이킷런의 StandardScaler 와 같은 스케일 도구를 통해 특성을 스케일링하면 결정경계가 훨씬 좋아질 수 있다. 모든 샘플이 결정경계선에서 떨어진 곳에 잘 분류되는 것을 ‘하드 마진 분류’라고 한다. 하드마진 분류는 데이터가 선형적으로 구분 가능할 때만 작동하고, 이상치가 존재하는 경우에도 하드마진을 찾을 수 없다. 이런 문제를 피하기 위해 이상치로 인해 발생하는 마진 오류(margin violation)를 어느정도 허용하면서도 결정경계선과 서포트 벡터 간의 거리를 최대한 멀게 하는 유연한 모델을 소프트 마진 분류(soft margin classification)라고 한다. 사이킷런이 제공하는 SVM모델에서는 하이퍼파라미터 C를 통해 이 균형을 조절할 수 있다. C값을 줄이면 마진이 넓어지지만 마진 오류도 커지고, C를 키우면 마진오류가 줄어들지만 마진 폭도 좁아진다. SVM 모델이 과대적합처럼 보인다면 이 C값을 감소시켜 모델을 규제해 일반화시키는 것이 좋다. 다음은 사이킷런에서 선형 SVM 분류모델을 구현하는 코드이다. 12345678from sklearn.pipeline import Pipelinefrom sklearn.preprocessing import StandardScalerfrom sklearn.svm import LinearSVCsvm_clf = Pipeline([ (\"scaler\", StandardScaler()), (\"linear_svc\", LinearSVC(C=1, loss='hinge')),]) 2. 비선형 SVM 분류선형적으로 분류할 수 없는 비선형 데이터셋을 분류하는 하나의 방법은 데이터에 다항식 특성과 같은 특성을 더 추가하여 선형적으로 구분할 수 있게 만드는 것이다. 사이킷런의 PolynomialFeatures 변환기와 StandardScaler, LinearSVC 를 연결해 파이프라인을 구축하여 다항 특성을 사용한 선형 SVM분류모델을 구현할 수 있다. 1234567from sklearn.preprocessing import PolynomialFeaturespolynomial_svm_clf = Pipeline([ ('poly_features', PolynomialFeatures(degree=3)), ('scaler, StandardScaler()), ('svm_clf', LinearSVC(C=10, loss='hinge', max_iter=2000))]) 여기서 손실함수로 사용된 힌지 손실(hinge loss)함수는 $\\max(0, 1-t)$ 의 식을 갖는다. 2-1. 다항식 커널다항식 특성을 추가하는 것은 간단하기도 하고 SVM을 비롯한 모든 머신러닝 알고리즘에서 잘 작동한다. 하지만 낮은 차수의 다항식은 복잡한 데이터셋을 잘 표현하지 못하고, 높은 차수의 다항식은 너무 많은 특성을 추가하게 되어 모델을 느리게 만든다. SVM에서는 커널 트릭(kernel trick) 이라는 수학적 장치를 통해 실제로는 특성을 추가하지 않으면서 다항식특성을 많이 추가하는 것과 같은 효과를 얻을 수 있다. 아래는 3차 다항식 커널을 사용한 SVM모델을 구현하는 코드이다. 12345from sklearn.svm import SVCpoly_kernel_svm_clf = Pipeline([ ('scaler', StandardScaler()), ('svm_clf', SVC(kernel='poly', degree=3, coef0=1, C=5))]) 모델이 과대적합이라면 차수를 줄이고, 과소적합이라면 차수를 늘려야 한다. 위 코드에서 인수 coef는 모델이 차수에 얼마나 영향을 받을지 조절하는 상수항이다. 차수가 높아질수록 1보다 작은 값과 1보다 큰 값의 차이가 크게 벌어지므로 이 상수항 값을 적절히 지정함으로써 고차항의 영향을 줄일 수 있다. 2-2. 유사도 특성 추가다항식 특성 방식 이외에 비선형 특성을 다루는 또 다른 기법은 각 샘플이 특정 랜드마크와 얼마나 닮았는지 측정하는 유사도 함수(similarity function)로 계산한 특성을 추가하는 것이다. 유사도 함수로는 다음과 같은 가우시안 RBF(Radial Basis Function)을 주로 사용한다. \\phi_\\gamma(\\bold{x}, l) = \\exp\\big(-\\gamma \\mid\\mid \\bold{x} - l \\mid\\mid^2\\big)이 함수의 값은 샘플 $x$가 랜드마크 $l$로부터 얼마나 멀리 떨어졌느냐에 따라 0에서 1까지의 값을 가지며 종모양으로 나타난다. 이 함수를 통해 계산된 값을 데이터로 대체하면 선형으로 분리할 수 없었던 1차원상의 데이터셋을 선형분리할 수 있게 된다. 랜드마크를 선택하는 방식은 데이터셋에 있는 모든 샘플 위치에 랜드마크를 설정하는 것이다. 이렇게 하면 차원이 매우 커져서 변환된 데이터셋을 선형분리할 수 있게 되지만 특성이 너무 많이 만들어지게 되는 단점이 있다. 2-3. 가우시안 RBF 커널이 유사도 특성 방식도 커널 트릭을 통해 실제로 유사도 특성을 많이 추가하지 않으면서 추가하는 것과 같은 결과를 낼 수 있다. SVC 모델에 가우시안 RBF 커널을 적용하는 코드는 다음과 같다. 1234rbf_kernel_svm_clf = Pipeline([ ('scaler', StandardScaler()), ('svm_clf', SVC(kernel='rbf', gamma=5, C=0.001))]) 여기서 gamma 인수를 증가시키면 유사도함수의 종모양이 좁아지게 되어 각 샘플의 영향 범위가 작아진다. 즉, 결정경계가 좀 더 불규칙해지고 각 샘플에 따라 구불구불해진다. 반대로 작은 gamma값은 넓은 종모양을 만들어 샘플이 넓은 범위에 영향을 주기 때문에 결정경계가 더 부드러워진다. 결국 하이퍼파라미터 $\\gamma$ 값이 규제의 역할을 하는 것이다. 모델이 과대적합일 경우 감소시키고, 과소적합일 경우 증가시켜야 한다. 여러 가지 커널 중 어떤 것을 사용해야 할까?항상 선형 커널을 가장 먼저 시도해보아야 한다. 훈련세트가 너무 크지 않다면 가우시안 RBF 커널이 대부분 잘 작동한다. 3. SVM 회귀SVM 알고리즘은 선형, 비선형 분류 뿐 아니라 회귀에도 사용할 수 있다. SVM 회귀는 분류에서의 목표와 반대로, 제한된 마진오류 안에서 가능한 한 많은 샘플이 좁은 선형 공간에 들어갈 수 있도록 학습한다. 그 공간의 폭, 즉 마진은 하이퍼파라미터 $\\epsilon$ 으로 조절한다. 사이킷런의 LinearSVR 을 이용해 선형 SVM 회귀모델을 구현해보면 다음과 같다. 123from sklearn.svm import LinearSVRsvm_reg = LinearSVR(eplilon=1.5) 비선형 회귀모델을 만들 때는 커널 SVM모델을 사용한다. 다음은 2차 다항식 형태의 데이터셋을 훈련하기 위한 비선형 SVM 모델을 구현하는 코드이다. 12from sklearn.svm import SVRsvm_poly_reg = SVR(kernel=&apos;poly&apos;, gamma=&apos;auto&apos;, degree=2, C=100, epsilon=0.1) 4. SVM 이론결정함수선형 SVM 분류 모델은 결정함수 $\\bold{w}^T \\cdot \\bold{x} + b = w_1x_1 + \\cdots + w_nx_n + b$ 를 계산해서 새로운 샘플 $\\bold{x}$ 의 클래스를 예측한다. 이 값이 0보다 크면 클래스 1, 그렇지 않으면 0에 해당하는 것이다. \\hat{y} = \\begin{cases} 0 && \\bold{w}^T\\cdot\\bold{x} + b < 0 \\text{일 때}\\\\ 1 && \\bold{w}^T\\cdot\\bold{x} + b \\geq 0 \\text{일 때}\\end{cases}이 분류모델에서 결정경계선은 결정함수 값이 0인 점들로 이루어진 직선이 된다. 소프트 마진 선형 SVM 모델을 훈련한다는 것은 특정 마진 오류값을 허용하면서 이 직선으로부터 샘플하이 최대한 멀리 떨어지도록 하는 $\\bold{w}$ 와 $b$ 를 찾는 것이다. 목적함수SVM 분류기의 마진을 최대화하는 것은 결정함수의 가중치벡터 $\\bold{w}$ 의 노름을 최소화하는 것과 같다. 하드마진 선형 SVM 분류기의 목적함수는 다음과 같다. \\text{minimize}_{\\bold{w}, b} \\frac{1}{2} \\bold{w}^T \\cdot \\bold{w}소프트마진 분류기의 목적함수에는 각 샘플에 대해 슬랙변수(slack variable)라는 개념이 추가된다. 이 슬랙변수 $\\zeta^{(i)}$는 i번째 샘플이 마진을 얼마나 위반할지를 결정한다. 여기에 하이퍼파라미터 C를 통해 마진을 크게 하는 것과 슬랙변수를 작게 하는 것 간의 균형을 맞춘다. \\text{minimize}_{w, b, \\zeta} \\frac{1}{2} \\bold{w}^T \\cdot \\bold{w} + C\\sum^m_{i=1}\\zeta^{(i)}","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://jyujin39.github.io/categories/Machine-Learning/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"로지스틱 회귀와 소프트맥스 회귀","slug":"로지스틱-회귀와-소프트맥스-회귀","date":"2019-03-31T08:30:54.000Z","updated":"2019-04-09T06:49:14.000Z","comments":true,"path":"2019/03/31/로지스틱-회귀와-소프트맥스-회귀/","link":"","permalink":"https://jyujin39.github.io/2019/03/31/로지스틱-회귀와-소프트맥스-회귀/","excerpt":"","text":"로지스틱 회귀와 소프트맥스 회귀1. 로지스틱 회귀회귀 알고리즘을 이진 분류에 적용하는 것이 로지스틱 회귀이다. 선형 회귀문제와 같이 입력 특성에 가중치를 곱하고 편향을 더해주지만, 그대로 출력하지 않고 그 값에 로지스틱 함수를 적용한 값을 출력한다. 로지스틱 함수에 속하는 함수들 중 가장 많이 쓰이는 시그모이드 함수의 식은 아래와 같으며, \\sigma (t) = \\frac{1}{1 + \\exp(-t)}이 함수를 씌워 출력한 로지스틱 회귀의 결과값은 0에서 1 사이의 값을 갖는다. \\hat{y} = \\begin{cases} 0 && \\hat{p} < 0.5 \\text{일 때}\\\\ 1 && \\hat{p} \\geq 0.5 \\text{일 때}\\end{cases}로지스틱 회귀의 비용함수는 로그손실함수라고도 불리며 다음과 같이 식으로 쓸 수 있다. J(\\theta) = -\\frac{1}{m} \\sum^m_{i=1} \\big(y^{(i)}\\log(\\hat{p}^{(i)}) + (1 - y^{(i)})\\log(1-\\hat{p}^{(i)})\\big)이 비용함수는 정규방정식같은 특별한 식을 통해 최솟값을 계산해낼 수는 없지만, 볼록함수이므로 경사하강법을 비롯한 최적화 알고리즘을 통해 전역 최솟값을 찾아낼 수 있다. 사이킷런은 `LogisticRegression’이라는 로지스틱 회귀모델을 제공한다. 로지스틱 회귀 또한 규제를 적용할 수 있으며, 기본적으로 사이킷런에서는 L2규제를 사용한다. 규제 강도를 조절하는 하이퍼파라미터는 선형모델에서 사용한 alpha 값의 역수인 C로, C 값이 높을수록 모델의 규제가 줄어든다. 123from sklearn.linear_model import LogisticRegressionlog_reg = LogisticRegression(solver='liblinear') 2. 소프트맥스 회귀로지스틱 회귀를 일반화하여 다중클래스를 지원하도록 일반화한 것이 소프트맥스 회귀 혹은 다항 로지스틱 회귀에 해당한다. 소프트맥스 회귀에서는 샘플들의 각 클래스에 대한 점수 $s_k(\\bold{x})$를 계산하고, 그 점수에 소프트맥스 함수를 씌워 특정 클래스 $k$에 속할 확률 $\\hat{p}_k$를 출력한다. \\hat{p}_k = \\sigma\\big(\\bold{s}(\\bold{x})\\big)_k = \\frac{\\exp\\big(s_k(\\bold{x})\\big)}{\\sum^K_{j=1}\\exp\\big(s_j(\\bold{x})\\big)}그리고 클래스들 중 그 확률값이 가장 높게 나온 클래스를 선택한다. 소프트맥스 회귀의 비용함수로는 주로 크로스 엔트로피를 사용하는데, 이 비용함수 식은 샘플의 타깃 클래스가 아닌 클래스들에 대해서는 항상 값을 0으로 만들기 때문에, 타깃이 아닌 클래스에 대해 낮은 확률을 출력해내도록 최적화하는 데에는 적절하지 못하다. 다만 모델이 타깃 클래스에 대해서 얼마나 높은 확률로 추정해내는지를 측정하는 용도로 사용된다. J(\\Theta) = -\\frac{1}{m} \\sum^m_{i=1}\\sum^K_{k=1} y_k^{(1)}\\log\\big(\\hat{p}_k^{(i)}\\big)여기서 $\\Theta$는 각 클래스가 갖는 파라미터벡터 $\\theta^{(k)}​$를 모은 파라미터 행렬이다. 사이킷런의 Logistic Regression 에서 multi_class 인수를 “multinomial” 로 바꾸면 소프트맥스 회귀를 사용할 수 있다. 소프트맥스 회귀를 사용하려면 solver 매개변수에 “lbfgs” 와 같이 이 회귀를 지원하는 알고리즘을 지정해주어야 한다. 소프트맥스 회귀에서 사용하는 규제는 로지스틱회귀와 마찬가지로 기본적으로 L2 규제이며, 하이퍼파라미터 인수 C 값을 통해 조절할 수 있다. 1softmax_reg = LogisticRegression(multi_class=&apos;multinomial&apos;, solver=&apos;lbfgs&apos;, C=10)","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://jyujin39.github.io/categories/Machine-Learning/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"선형 모델의 과대적합(Overfitting) 감소시키기 - 규제(Regularization)","slug":"선형-모델의-과대적합(Overfitting)-감소시키기-규제(Regularization)","date":"2019-03-31T05:05:54.000Z","updated":"2019-05-16T12:59:52.000Z","comments":true,"path":"2019/03/31/선형-모델의-과대적합(Overfitting)-감소시키기-규제(Regularization)/","link":"","permalink":"https://jyujin39.github.io/2019/03/31/선형-모델의-과대적합(Overfitting)-감소시키기-규제(Regularization)/","excerpt":"","text":"선형 모델의 과대적합(Overfitting) 감소시키기: 규제(Regularization)모델의 자유도를 줄이면 훈련데이터에 과대적합되는 것을 방지할 수 있다. 예를 들어 다항회귀 모델에서는 다항식의 차수를 감소시키는 것이다. 선형회귀 모델에서는 보통 모델의 가중치를 제한하는 방법을 사용한다. 이 방법으로는 크게 다음 세 가지가 있다. 1. 릿지(Ridge) 회귀릿지 회귀는 비용함수(MSE)에 다음과 같은 규제항을 사용한다. \\alpha \\sum^n_{i=1}\\theta_i^2이 규제항이 추가된 비용함수는 이제 가중치들의 제곱합(L2 Norm)이 최대한 작아지도록 모델을 규제하며, 하이퍼파라미터 $\\alpha$의 크기는 규제의 정도를 결정한다. $\\alpha=0$ 이면 전혀 규제를 하지 않는 것과 같고, $\\alpha$가 커질수록 가중치들은 점점 0에 가까워진다. 릿지회귀를 사용하는 경우 규제항은 훈련하는 동안에만 비용함수에 추가되고, 훈련이 끝난 후 실제 테스트 세트에서 모델의 성능은 규제가 없는 성능지표로 평가하게 된다. 훈련에 쓰이는 비용함수는 최적화를 위해 미분과정을 거치게 되는데, 이 미분을 간단하게 하기 위해 보통 릿지 회귀에서는 다음과 같이 규제항에 $\\frac{1}{2}$ 를 곱한 비용함수를 사용한다. J(\\theta) = \\text{MSE}(\\theta) + \\alpha \\frac{1}{2}\\sum^n_{i=1}\\theta_i^2예를 들어 다항회귀에 릿지 규제를 사용하게 되면, $\\alpha$ 를 증가시킬수록 모델의 형태가 직선에 가까워진다. 2. 라쏘(Lasso) 회귀라쏘 회귀는 가중치들의 L2 노름을 규제한 릿지와 달리, 비용함수에 가중치들의 L1노름에 대한 규제항을 추가한 식을 사용한다. J(\\theta) = \\text{MSE} + \\alpha \\sum^n_{i=1} |\\theta_i|라쏘 회귀의 중요한 특징은, 덜 중요한 특성들의 가중치를 0으로 만드려고 한다는 점이다. 즉, 라쏘 회귀는 자동으로 특성 선택을 하고 희소 모델(sparse model)을 만든다. 라쏘 회귀의 비용함수에서 사용하는 가중치들의 L1노름 $|\\theta_i|$ 은 V자 형의 함수이기 때문에 $\\theta_i$가 0일 때 미분이 불가능하다. 따라서 경사하강법으로 최적화할 때는 다음과 같은 서브그래디언트 벡터 g를 사용한다. g(\\theta, J) = \\nabla_\\theta \\text{MSE}(\\theta) + \\alpha \\begin{pmatrix} \\text{sign}(\\theta_1)\\\\ \\text{sign}(\\theta_2)\\\\ \\vdots \\\\ \\text{sign}(\\theta_n) \\end{pmatrix} \\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\text{여기서 sign}(\\theta_i) = \\begin{cases} -1 && \\theta_i < 0 \\text{일 때}\\\\ 0 && \\theta_i = 0\\text{일 때}\\\\ 1 && \\theta_i > 0 \\text{일 때} \\end{cases}3. 엘라스틱 넷(Elastic Net) 회귀릿지와 라쏘를 절충한 모델인 엘라스틱 넷의 규제항은 단순히 릿지와 회귀의 규제항을 더해서 사용한다. 둘의 혼합 정도는 비율 파라미터 $r$ 을 0과 1 사이로 조절해 결정하며, $r=0$이면 릿지회귀, $r=1$이면 라쏘 회귀와 같게 된다. J(\\theta) = \\text{MSE}(\\theta) + r\\alpha \\sum_{i=1}^n|\\theta_i| + \\frac{1-r}{2} \\alpha\\sum_{i=2}^n\\theta_i^2릿지, 라쏘, 엘라스틱 넷을 각각 언제 사용해야 할까?일반적으로 선형회귀에서는 릿지를 기본으로 사용하지만, 데이터에서 실제로 쓰이는 특성이 몇개 뿐이라고 의심되면 라쏘나 엘라스틱 넷을 사용하는 것이 좋다. 이 두 모델은 모두 불필요한 특성들의 가중치를 0으로 만들어주기 때문이다. 특성 수가 훈련샘플 수보다 많거나 특성 몇 개가 서로 강하게 연관되어 있을 때는 보통 라쏘가 문제를 일으킬 수 있기 때문에 엘라스틱 넷을 사용하는 것이 선호된다. scikit-learn은 이 세 가지 규제모델을 모두 제공한다. 아래는 예시 코드이다. 12345from sklearn.linear_model import Ridge, Lasso, ElasticNetridge_reg = Ridge(alpha=1, solver='sag') # sag : 확률적 평균 경사 하강법lasso_reg = Lasso(alpha=0.1)elastic_net_reg = ElasticNet(alpha=0.1, I1_ratio=0.5) # I1_ratio : 혼합 비율 r 4. 조기 종료(early stopping)경사 하강법과 같은 반복적인 학습 알고리즘을 규제하기 위해, 검증 에러가 최솟값에 도달하면 바로 훈련을 중단하는 방법이다. 에포크가 진행됨에 따라 훈련세트와 검증세트에 대한 로스 값이 점차 감소하다가 어느 순간이 지나면 검증에러 값이 상승하게 되는데, 이 때가 모델이 훈련데이터에 과대적합되기 시작하는 순간이다. 이 때 즉시 훈련을 멈추는 것이 바로 조기 종료이다. 다음은 조기종료를 구현하는 코드이다. 1234567891011121314151617181920212223242526272829from sklearn.pipeline import Pipelinefrom sklearn.preprocessing import PolynomialFeatures, StandardScalerfrom sklearn.linear_model import SGDRegressorfrom sklearn.metrics import mean_squared_errorfrom sklearn.base import clone# 데이터 준비poly_scaler = Pipeline([ ('poly_features', PolynomialFeatures(degree=90, include_bias=False)), ('std_scaler', StandardScaler())])X_train_poly_scaled = poly_scaler.fit_transform(X_train)X_val_poly_scaled = poly_scaler.transform(X_val)sgd_reg = SGDRegressor(n_iter=1, warm_start=True, penalty=None, learning_rate='constant', eta0=0.0005)minimum_val_error = float('inf')best_epoch = Nonebest_model = Nonefor epoch in range(1000): sgd_reg.fit(X_train_poly_scaled, y_train) y_val_predict = sgd_reg.predict(X_val_poly_scaled) val_error = mean_squared_error(y_val, y_val_predict) if val_error &lt; minimum_val_error: minimum_val_error = val_error best_epoch = epoch best_model = clone(sgd_reg) SGD 회귀모델을 생성할 때 warm_start 인수를 True로 설정하면, 아래 구현한 for 문에서 fit() 메서드가 호출될 때마다 처음부터 훈련을 다시 시작하지 않고 이전 모델 파라미터에서 훈련을 이어나간다.","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://jyujin39.github.io/categories/Machine-Learning/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"인공지능을 위한 수학","slug":"인공지능을-위한-수학","date":"2019-03-23T05:26:11.000Z","updated":"2019-05-16T13:32:07.000Z","comments":true,"path":"2019/03/23/인공지능을-위한-수학/","link":"","permalink":"https://jyujin39.github.io/2019/03/23/인공지능을-위한-수학/","excerpt":"","text":"","categories":[{"name":"Books","slug":"Books","permalink":"https://jyujin39.github.io/categories/Books/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"파이썬 라이브러리를 활용한 머신러닝","slug":"파이썬-라이브러리를-활용한-머신러닝","date":"2019-03-23T05:25:48.000Z","updated":"2019-05-16T13:32:37.000Z","comments":true,"path":"2019/03/23/파이썬-라이브러리를-활용한-머신러닝/","link":"","permalink":"https://jyujin39.github.io/2019/03/23/파이썬-라이브러리를-활용한-머신러닝/","excerpt":"","text":"","categories":[{"name":"Books","slug":"Books","permalink":"https://jyujin39.github.io/categories/Books/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"텐서플로와 머신러닝으로 시작하는 자연어 처리","slug":"텐서플로와-머신러닝으로-시작하는-자연어-처리","date":"2019-03-23T05:25:20.000Z","updated":"2019-05-16T13:32:30.000Z","comments":true,"path":"2019/03/23/텐서플로와-머신러닝으로-시작하는-자연어-처리/","link":"","permalink":"https://jyujin39.github.io/2019/03/23/텐서플로와-머신러닝으로-시작하는-자연어-처리/","excerpt":"","text":"","categories":[{"name":"Books","slug":"Books","permalink":"https://jyujin39.github.io/categories/Books/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"케라스 창시자에게 배우는 딥러닝","slug":"케라스-창시자에게-배우는-딥러닝","date":"2019-03-23T05:22:20.000Z","updated":"2019-05-16T13:32:23.000Z","comments":true,"path":"2019/03/23/케라스-창시자에게-배우는-딥러닝/","link":"","permalink":"https://jyujin39.github.io/2019/03/23/케라스-창시자에게-배우는-딥러닝/","excerpt":"","text":"","categories":[{"name":"Books","slug":"Books","permalink":"https://jyujin39.github.io/categories/Books/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"핸즈온 머신러닝(Hands on ㄴachine Learning with Scikit-Learn & TensorFlow)","slug":"핸즈온-머신러닝-Hands-on-Machine-Learning-with-Scikit-Learn-TensorFlow","date":"2019-03-23T05:21:25.000Z","updated":"2019-05-16T13:32:43.000Z","comments":true,"path":"2019/03/23/핸즈온-머신러닝-Hands-on-Machine-Learning-with-Scikit-Learn-TensorFlow/","link":"","permalink":"https://jyujin39.github.io/2019/03/23/핸즈온-머신러닝-Hands-on-Machine-Learning-with-Scikit-Learn-TensorFlow/","excerpt":"","text":"","categories":[{"name":"Books","slug":"Books","permalink":"https://jyujin39.github.io/categories/Books/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"선형회귀 비용함수(MSE)를 최소화하는 하이퍼파라미터 탐색(모델 훈련) 방법","slug":"선형회귀-비용함수-MSE-를-최소화하는-하이퍼파라미터-탐색-모델-훈련-방법","date":"2019-03-23T05:05:54.000Z","updated":"2019-03-31T10:54:25.000Z","comments":true,"path":"2019/03/23/선형회귀-비용함수-MSE-를-최소화하는-하이퍼파라미터-탐색-모델-훈련-방법/","link":"","permalink":"https://jyujin39.github.io/2019/03/23/선형회귀-비용함수-MSE-를-최소화하는-하이퍼파라미터-탐색-모델-훈련-방법/","excerpt":"","text":"선형회귀 - 비용함수(MSE)를 최소화하는 하이퍼파라미터 탐색(모델 훈련) 방법1. 정규방정식 \\hat{\\theta} = \\big(\\bold{X}^T\\cdot \\bold{X}\\big)^{-1}\\cdot \\bold{X}^T\\cdot \\bold{y} 장점 단점 샘플 개수 $m$에 대해 계산복잡도가 낮다. $O(m)$ 특성 개수 $n$에 대해 계산복잡도가 높다. $O(n^{2.4})$ ~ $O(n^3)$ 파라미터 값을 바로 도출해낸다. 2. 경사 하강법(GD, Gradient Descent)경사 하강법의 기본 아이디어는 비용함수를 최소화하기 위해 반복해서 파라미터를 조정해가는 것이다. 처음 파라미터 값은 무작위 초기화(random initialization)한 임의의 값으로 설정된다. 경사하강법은 정규방정식과 달리 특성개수에 민감하지 않다. 따라서 특성 개수가 많은 데이터의 경우 경사하강법을 쓰는 것이 좋다. 2-1. 배치 경사 하강법 (Batch Gradient Descent)배치 경사 하강법은 모든 파라미터 $\\theta_j$에 대해 비용함수의 그래디언트를 계산한다(편미분). 이 계산을 한번에 할 수 있는 식은 다음과 같다. \\nabla_\\theta\\text{MSE}(\\theta) = \\begin{pmatrix} \\frac{\\partial}{\\partial\\theta_0}\\text{MSE}(\\theta)\\\\ \\frac{\\partial}{\\partial\\theta_1}\\text{MSE}(\\theta)\\\\ \\vdots\\\\ \\frac{\\partial}{\\partial\\theta_n}\\text{MSE}(\\theta)\\\\ \\end{pmatrix} = \\frac{2}{m}\\bold{X}^T\\cdot (\\bold{X} \\cdot \\theta - \\bold{y}) 경사하강법의 스텝 \\theta^{(\\text{next step})} = \\theta - \\eta \\nabla_\\theta \\text{MSE}(\\theta) 적절한 스텝 사이즈, 즉 학습률을 정하려면 그리드 탐색을 사용한다. 이 때 탐색을 반복하는 횟수를 제한해야 하는데, 처음에 횟수를 아주 크게 지정한 후 그래디언트 벡터가 아주 작아져 어떤 허용오차값에 도달하면 알고리즘을 중지하는 방식으로 하게 된다. 2-2. 확률적 경사 하강법 (Stochastic Gradient Descent)배치 경사 하강법의 문제점은, 매 스텝에서 전체 훈련세트를 사용해 그래디언트를 계산하므로 훈련세트가 커지면 속도가 느려진다는 점이다. SGD 방법은 매 스텝에서 하나의 샘플만을 사용해 그래디언트를 계산하는 방법이다. 배치 경사 하강법은 시간이 걸리더라도 꾸준히 전역최솟값에 도달해나갈 수 있다. 확률적 경사하강법은 샘플링의 무작위성으로 인해 배치경사하강법보다 훨씬 불안정하게 최솟값을 찾아나가기 때문에 전역최솟값에 도달하기 더 힘들 수 있다. 다만 같은 이유로 지역최솟값에서는 벗어나기가 쉽게 된다. 따라서 비용함수가 convex하지 않고 복잡한 형태일 경우에는 배치경사하강법보다 전역최솟값을 찾을 가능성이 높아진다. 2-3. 미니배치 경사 하강법 (Mini-batch Gradient Descent)미니배치 경사하강법은 각 스텝에서 미니배치라고 불리는 임의의 샘플 세트에 대해 그래디언트를 계산한다. 미니배치 사이즈를 어느 정도 크게 하면 SGD보다 덜 불규칙하게 움직일 것이기 때문에 최솟값에 더 가까이 도달하게 될 것이다. 하지만 반대로 지역최솟값에서 빠져나오기는 더 힘들게 된다.","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://jyujin39.github.io/categories/Machine-Learning/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"올바른 괄호","slug":"올바른-괄호","date":"2019-02-01T09:50:29.000Z","updated":"2019-02-01T09:58:41.000Z","comments":true,"path":"2019/02/01/올바른-괄호/","link":"","permalink":"https://jyujin39.github.io/2019/02/01/올바른-괄호/","excerpt":"","text":"올바른 괄호올바른 괄호란 두 개의 괄호 ‘(‘ 와 ‘)’ 만으로 구성되어 있고, 괄호가 올바르게 짝지어진 문자열입니다. 괄호가 올바르게 짝지어졌다는 것은 ‘(‘ 문자로 열렸으면 반드시 짝지어서 ‘)’ 문자로 닫혀야 합니다. 예를들어 “()()” 또는 “(())()” 는 올바른 괄호입니다. “)()(“ 또는 “(()(“ 는 올바르지 않은 괄호입니다. &#39;(&#39; 또는 &#39;)&#39; 로만 이루어진 문자열 s가 주어졌을 때, 문자열 s가 올바른 괄호이면 true를 return 하고, 올바르지 않은 괄호이면 false를 return하는 solution 함수를 완성해 주세요. 제한사항 문자열 s의 길이 : 100,000 이하의 자연수 문자열 s는 ‘(‘ 또는 ‘)’ 로만 이루어져 있습니다. 입출력 예 s answer ()() true (())() true )()( false (()( false 나의 풀이 첫 번째 풀이 1234def solution(s): while '()' in s: s = ''.join(s.split('()')) return not bool(s) 정답은 다 맞추지만 시간초과로 통과되지 못했다. 두 번째 풀이 1234567891011121314def solution(s): cnt = 0 for bracket in s: if bracket == '(': cnt += 1 continue cnt -= 1 if cnt &lt; 0: return False if cnt == 0: return True return False 시간효율성까지 통과했다. 마지막 코드 수정 123456789101112def solution(s): cnt = 0 for bracket in s: if bracket == '(': cnt += 1 continue cnt -= 1 if cnt &lt; 0: return False return cnt == 0 다른사람의 풀이를 본 후 맨 마지막에 if문을 굳이 쓰지 않고도 return 한줄로 구현할 수 있음을 깨닫고 수정하였다.","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"Programmers","slug":"Coding-drills/Programmers","permalink":"https://jyujin39.github.io/categories/Coding-drills/Programmers/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"algorithm","slug":"algorithm","permalink":"https://jyujin39.github.io/tags/algorithm/"},{"name":"coding","slug":"coding","permalink":"https://jyujin39.github.io/tags/coding/"}]},{"title":"124 나라의 숫자","slug":"124-나라의-숫자","date":"2019-01-31T06:12:55.000Z","updated":"2019-01-31T06:17:13.000Z","comments":true,"path":"2019/01/31/124-나라의-숫자/","link":"","permalink":"https://jyujin39.github.io/2019/01/31/124-나라의-숫자/","excerpt":"","text":"124 나라의 숫자124 나라가 있습니다. 124 나라에서는 10진법이 아닌 다음과 같은 자신들만의 규칙으로 수를 표현합니다. 124 나라에는 자연수만 존재합니다. 124 나라에는 모든 수를 표현할 때 1, 2, 4만 사용합니다. 예를 들어서 124 나라에서 사용하는 숫자는 다음과 같이 변환됩니다. 10진법 124 나라 10진법 124 나라 1 1 6 14 2 2 7 21 3 4 8 22 4 11 9 24 5 12 10 41 자연수 n이 매개변수로 주어질 때, n을 124 나라에서 사용하는 숫자로 바꾼 값을 return 하도록 solution 함수를 완성해 주세요. 제한사항 n은 500,000,000이하의 자연수 입니다. 입출력 예 n result 1 1 2 2 3 4 4 11 나의 풀이123456789101112131415161718192021222324252627282930313233def solution(n): i = 1 while n &gt;= 0: if n &lt; 3**i: i -= 1 break n -= 3**i i += 1 if n == 0: return '4'*i from collections import Counter result = Counter(range(1, i+2)) while i &gt;= 0: if n &lt;= 3**i: i -= 1 else: n -= 3**i result[i+1] += 1 ans = '' for key in result.keys(): if result[key] == 1: ans += '1' elif result[key] == 2: ans += '2' else: ans += '4' return ans[::-1]","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"Programmers","slug":"Coding-drills/Programmers","permalink":"https://jyujin39.github.io/categories/Coding-drills/Programmers/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"algorithm","slug":"algorithm","permalink":"https://jyujin39.github.io/tags/algorithm/"},{"name":"coding","slug":"coding","permalink":"https://jyujin39.github.io/tags/coding/"}]},{"title":"채점하기","slug":"채점하기","date":"2019-01-26T11:43:03.000Z","updated":"2019-01-26T11:50:39.000Z","comments":true,"path":"2019/01/26/채점하기/","link":"","permalink":"https://jyujin39.github.io/2019/01/26/채점하기/","excerpt":"","text":"채점하기매주 금요일 알고리즘 테스트 결과를 채점하기 귀찮아졌습니다. 그래서 직접하지 않고, 수강생분들에게 공부가 된다는 사탕발림으로 서로의 시험결과를 채점하게 하려고합니다. 단, 양심적으로 진행하기 위해서 그 누구도 자신의 시험을 채점하지 않는다고 할때. 채점할 수 있는 경우의 수를 구하는 함수를 구하세요. n=1일때 0개 n=2일때 1개 그리고 n&gt;=3일때 (n-1) * ( (n-1)명이서 서로 채점하는 경우의 수 + (n-2)명이서 서로 채점하는 경우의 수)) 라는 특징을 따른다고 합니다. 조건 n은 1 이상 1000이하 나의 풀이12345def solution(n): if n &lt;= 2: return n-1 else: return (n-1) * (solution(n-1) + solution(n-2)) recursion(재귀) 함수를 이용해 구현했는데 n이 일정 수 이상으로 커지면 시간복잡도가 매우 커진다. 개선한 풀이 데코레이션 함수 이용 12345678910111213141516def deco(func): m = &#123;&#125; # 계산결과를 저장하는 메모리 변수로 딕셔너리 선언 def inner(n): if not m.get(n): result = func(n) m[n] = result # m 의 키값에 n이 존재하면 새로 계산하지 않고 바로 밸류값을 리턴해준다. return m[n] return inner# 데코레이터 함수 호출 - soultion함수에 위 deco함수의 기능이 들어간다.@decodef solution(n): if n &lt;= 2: return n-1 return (n-1) * (solution(n-1) + solution(n-2)) n에 1000을 넣어도 빠르게 계산이 이루어진다.","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"algorithm test","slug":"Coding-drills/algorithm-test","permalink":"https://jyujin39.github.io/categories/Coding-drills/algorithm-test/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"algorithm","slug":"algorithm","permalink":"https://jyujin39.github.io/tags/algorithm/"},{"name":"coding","slug":"coding","permalink":"https://jyujin39.github.io/tags/coding/"}]},{"title":"동전 줍기","slug":"동전-줍기","date":"2019-01-26T11:23:41.000Z","updated":"2019-01-26T11:42:29.000Z","comments":true,"path":"2019/01/26/동전-줍기/","link":"","permalink":"https://jyujin39.github.io/2019/01/26/동전-줍기/","excerpt":"","text":"동전 줍기길에 떨어져 있는 많은 동전들의 위치와 갯수를 의미하는 리스트 A가 있습니다. 당신은 길위에 동전을 수집하려고 합니다. 출발하는 위치 k와 이동가능한 거리를 m이 주어질때,가장 많은 동전을 획득하려고하면 몇개를 획득할 수 있는지 알려주는 함수를 만드세요. 예를 들어 리스트 A와 k, m이 아래와 같을때 123A = [2, 3, 7, 5, 1, 3, 9]k = 4m = 6 가장 많은 동전을 주울 수 있는 방법은 아래와 같고 4번째에서 출발 - 1개 획득 왼쪽으로 이동 - 5개 획득 (1번이동) 왼쪽으로 이동 - 7개 획득 (2번이동) 오른쪽으로 이동 - 0개 획득 (3번이동) 오른쪽으로 이동 - 0개 획득 (4번이동) 오른쪽으로 이동 - 3개 획득 (5번이동) 오른쪽으로 이동 - 9개 획득 (6번이동) 총1+5+7+3+9 = 25개의 버섯을 주울 수 있다. 25를 리턴하는 함수 solution을 생성하세요. 조건 A의 길이는 1 이상, 100000 이하이다. k와 m은 0 이상 100000 이하이다. 풀이12345678910111213141516171819202122232425262728293031323334353637383940414243444546def solution(A, k, m): import math # 누적합 리스트 미리 구하기 pre_sum = [0] for num in A: pre_sum.append(pre_sum[-1] + num) # 줍게 되는 동전 개수 값들을 담을 리스트 선언 coin_count = [] # 방향전환을 무조건 한다고 가정할 때, 한쪽 방향으로의 의미있는 이동의 최대값은 m/2의 반올림 # 오른쪽으로 먼저 이동하는 경우 for i in range(math.ceil(m/2)): # 오른쪽으로 갈 수 있는 최대값 right = min(len(A)-k-1, m-i) # 오른쪽으로만 m만큼을 모두 이동하는 경우 if right == m: coin_count.append(pre_sum[k+1+right] - pre_sum[k]) break # 오른쪽으로 right만큼 갔을 때 왼쪽으로 이동하게 되는 칸 수 left = max(0, m - right*2) # 이 때 주운 동전의 개수를 리스트에 넣는다 coin_count.append(pre_sum[k+1+right] - pre_sum[k-left]) # 왼쪽으로 먼저 이동하는 경우 for i in range(math.ceil(m/2)): left = max(0, m-i) if left == m: coin_count.append(pre_sum[k+1] - pre_sum[k-left]) break right = min(len(A)-k-1, m - left*2) coin_count.append(pre_sum[k+1+right] - pre_sum[k-left]) # 주울 수 있는 동전의 최대 개수 리턴 return max(coin_count) 처음에는 시간 내에 풀지 못함 누적합 개념과 math.ceil(m/2) 아이디어를 알고 나서 해결 우측으로 먼저 갈 때와 좌측으로 먼저 갈 때 패턴이 유사한데 두 개의 개별 코드로 구현했기 때문에 두 패턴을 모두 담아낼 수 있는 하나의 코드를 생각해볼 것","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"algorithm test","slug":"Coding-drills/algorithm-test","permalink":"https://jyujin39.github.io/categories/Coding-drills/algorithm-test/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"algorithm","slug":"algorithm","permalink":"https://jyujin39.github.io/tags/algorithm/"},{"name":"coding","slug":"coding","permalink":"https://jyujin39.github.io/tags/coding/"}]},{"title":"[1차] 뉴스 클러스터링","slug":"1차-뉴스-클러스터링","date":"2019-01-24T06:51:04.000Z","updated":"2019-01-24T06:52:18.000Z","comments":true,"path":"2019/01/24/1차-뉴스-클러스터링/","link":"","permalink":"https://jyujin39.github.io/2019/01/24/1차-뉴스-클러스터링/","excerpt":"","text":"2017 KAKAO BLIND RECRUITMENT [1차] 뉴스 클러스터링여러 언론사에서 쏟아지는 뉴스, 특히 속보성 뉴스를 보면 비슷비슷한 제목의 기사가 많아 정작 필요한 기사를 찾기가 어렵다. Daum 뉴스의 개발 업무를 맡게 된 신입사원 튜브는 사용자들이 편리하게 다양한 뉴스를 찾아볼 수 있도록 문제점을 개선하는 업무를 맡게 되었다. 개발의 방향을 잡기 위해 튜브는 우선 최근 화제가 되고 있는 카카오 신입 개발자 공채 관련 기사를 검색해보았다. 카카오 첫 공채..’블라인드’ 방식 채용카카오, 합병 후 첫 공채.. 블라인드 전형으로 개발자 채용카카오, 블라인드 전형으로 신입 개발자 공채카카오 공채, 신입 개발자 코딩 능력만 본다카카오, 신입 공채.. 코딩 실력만 본다카카오 코딩 능력만으로 2018 신입 개발자 뽑는다기사의 제목을 기준으로 블라인드 전형에 주목하는 기사와 코딩 테스트에 주목하는 기사로 나뉘는 걸 발견했다. 튜브는 이들을 각각 묶어서 보여주면 카카오 공채 관련 기사를 찾아보는 사용자에게 유용할 듯싶었다. 유사한 기사를 묶는 기준을 정하기 위해서 논문과 자료를 조사하던 튜브는 자카드 유사도라는 방법을 찾아냈다. 자카드 유사도는 집합 간의 유사도를 검사하는 여러 방법 중의 하나로 알려져 있다. 두 집합 A, B 사이의 자카드 유사도 J(A, B)는 두 집합의 교집합 크기를 두 집합의 합집합 크기로 나눈 값으로 정의된다. 예를 들어 집합 A = {1, 2, 3}, 집합 B = {2, 3, 4}라고 할 때, 교집합 A ∩ B = {2, 3}, 합집합 A ∪ B = {1, 2, 3, 4}이 되므로, 집합 A, B 사이의 자카드 유사도 J(A, B) = 2/4 = 0.5가 된다. 집합 A와 집합 B가 모두 공집합일 경우에는 나눗셈이 정의되지 않으니 따로 J(A, B) = 1로 정의한다. 자카드 유사도는 원소의 중복을 허용하는 다중집합에 대해서 확장할 수 있다. 다중집합 A는 원소 1을 3개 가지고 있고, 다중집합 B는 원소 1을 5개 가지고 있다고 하자. 이 다중집합의 교집합 A ∩ B는 원소 1을 min(3, 5)인 3개, 합집합 A ∪ B는 원소 1을 max(3, 5)인 5개 가지게 된다. 다중집합 A = {1, 1, 2, 2, 3}, 다중집합 B = {1, 2, 2, 4, 5}라고 하면, 교집합 A ∩ B = {1, 2, 2}, 합집합 A ∪ B = {1, 1, 2, 2, 3, 4, 5}가 되므로, 자카드 유사도 J(A, B) = 3/7, 약 0.42가 된다. 이를 이용하여 문자열 사이의 유사도를 계산하는데 이용할 수 있다. 문자열 FRANCE와 FRENCH가 주어졌을 때, 이를 두 글자씩 끊어서 다중집합을 만들 수 있다. 각각 {FR, RA, AN, NC, CE}, {FR, RE, EN, NC, CH}가 되며, 교집합은 {FR, NC}, 합집합은 {FR, RA, AN, NC, CE, RE, EN, CH}가 되므로, 두 문자열 사이의 자카드 유사도 J(“FRANCE”, “FRENCH”) = 2/8 = 0.25가 된다. 입력 형식 입력으로는 str1과 str2의 두 문자열이 들어온다. 각 문자열의 길이는 2 이상, 1,000 이하이다. 입력으로 들어온 문자열은 두 글자씩 끊어서 다중집합의 원소로 만든다. 이때 영문자로 된 글자 쌍만 유효하고, 기타 공백이나 숫자, 특수 문자가 들어있는 경우는 그 글자 쌍을 버린다. 예를 들어 ab+가 입력으로 들어오면, ab만 다중집합의 원소로 삼고, b+는 버린다. 다중집합 원소 사이를 비교할 때, 대문자와 소문자의 차이는 무시한다. AB와 Ab, ab는 같은 원소로 취급한다. 출력 형식 입력으로 들어온 두 문자열의 자카드 유사도를 출력한다. 유사도 값은 0에서 1 사이의 실수이므로, 이를 다루기 쉽도록 65536을 곱한 후에 소수점 아래를 버리고 정수부만 출력한다. 예제 입출력 str1 str2 answer FRANCE french 16384 handshake shake hands 65536 aa1+aa2 AAAA12 43690 E=M*C^2 e=m*c^2 65536 나의 풀이1234567891011121314151617181920def solution(s1, s2): set_s1 = [s1[i]+s1[i+1] for i in range(len(s1)-1)] set_s2 = [s2[i]+s2[i+1] for i in range(len(s2)-1)] set_s1 = [s.lower() for s in set_s1 if s.isalpha()] set_s2 = [s.lower() for s in set_s2 if s.isalpha()] total = set_s1 + set_s2 commons = set([common for common in set(total) if total.count(common) &gt; 1]) numerator = 0 for common in commons: numerator += min(set_s1.count(common), set_s2.count(common)) denominator = len(total) - numerator if denominator == 0: return 65536 return int(numerator / denominator * 65536)","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"Programmers","slug":"Coding-drills/Programmers","permalink":"https://jyujin39.github.io/categories/Coding-drills/Programmers/"},{"name":"2017 KAKAO BLIND RECRUITMENT","slug":"Coding-drills/Programmers/2017-KAKAO-BLIND-RECRUITMENT","permalink":"https://jyujin39.github.io/categories/Coding-drills/Programmers/2017-KAKAO-BLIND-RECRUITMENT/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"},{"name":"algorithm","slug":"algorithm","permalink":"https://jyujin39.github.io/tags/algorithm/"},{"name":"coding","slug":"coding","permalink":"https://jyujin39.github.io/tags/coding/"}]},{"title":"문자열 조합","slug":"문자열-조합","date":"2019-01-21T07:08:04.000Z","updated":"2019-01-21T07:17:43.000Z","comments":true,"path":"2019/01/21/문자열-조합/","link":"","permalink":"https://jyujin39.github.io/2019/01/21/문자열-조합/","excerpt":"","text":"문자열 조합중복이 없는 문자로 이루어진 길이가 N인 문자열을 S를 받고, 그 길이보다 같거나 작은 정수 M을 받아서 문자열 S에 포함된 문자의 조합을 생성하세요. 예제 s m return ‘ABCD’ 2 [‘AB’, ‘AC’, ‘AD’, ‘BC’, ‘BD’, ‘CD’] 조건 AB와 BA는 같기 때문에 동시에 포함될 수 없다. 둘중 s에서 먼저나오는 문자가 앞에오는 결과를 포함시키도록 해야함 AB, BA인 경우 AB에 앞에오는 문자 A가 먼저 등장하기때문에 BA가 아닌 AB를 포함 나의 풀이123456def solution(s, n): import itertools result = [] for i in itertools.combinations(s, n): result.append(''.join(i)) return result 12%%timesolution('ABCDE',2) 파이썬에서 기본으로 제공하는 모듈인 itertools 를 활용하면 조합 문제를 너무도 간단하게 풀 수 있다. 조합을 하고자 하는 iterable과 조합을 이룰 개수 n을 인수로 넣으면 $_\\text{len(iterable)}C_n$ 개의 조합이 모두 출력된다.","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"algorithm test","slug":"Coding-drills/algorithm-test","permalink":"https://jyujin39.github.io/categories/Coding-drills/algorithm-test/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"마지막 인덱스 찾기","slug":"마지막-인덱스-찾기","date":"2019-01-19T09:13:42.000Z","updated":"2019-01-19T09:35:17.000Z","comments":true,"path":"2019/01/19/마지막-인덱스-찾기/","link":"","permalink":"https://jyujin39.github.io/2019/01/19/마지막-인덱스-찾기/","excerpt":"","text":"마지막 인덱스 찾기1부터 M까지 숫자가 들어있는 길이가 N인 리스트에서, 각 숫자가 마지막으로 등장하는 index를 순차적으로 담은 리스트를 리턴하세요. 예제 m data return 3 [1, 2, 3, 1, 2, 3, 1] [6, 4, 5] 설명 1이 등장한 index는 0과 3과 6, 그 중 가장 마지막에 등장한 index는 6 2가 등장한 index는 1과 4, 그 중 마지막은 4 3이 등장한 index는 2와 5, 그 중 마지막은 5 조건 M은 2보다 크고 10,000보다 작은 숫자 N은 1보다 크고 100,000보다 작은 숫자 나의 풀이 테스트 코드 1234from random import randintm = 9999n = 99999data = [randint(1, m) for _ in range(N)] 랜덤함수를 이용해 주어진 조건 하에서 최악의 경우에 해당하는 테스트데이터를 만들어본다. 첫 번째 풀이 12345678def solution(m, n, data): result = [0] * m for i in range(1, n+1): if 0 not in result: break elif result[data[n-i]-1] == 0: result[data[n-i]-1] = n - i return result 12%%times = solution(m, n, data) data의 뒤에서부터 포문을 돌며 처음으로 나오는 숫자의 인덱스를 미리 만들어둔 result 리스트의 해당 인덱스 위치에 넣어주었다. data의 맨 앞까지 포문이 돌기 전에 result가 인덱스로 꽉 차면 break해주는 코드도 추가해주었다. 그런데 시간복잡도가 1초가 넘어가기 때문에 효율성측면에서 코드개선이 필요했다. 다른 사람의 풀이 123456def solution(m, n, data): data = data[::-1] result = [] for i in range(1, m+1): result.append(n-1 - data.index(i)) return result data를 미리 뒤집어 정렬한 리스트로 만들고, 데이터의 첫 번째 원소부터 시작해 list의 index 메서드를 사용해 인덱스를 뽑았다. 보기에 훨씬 간단하고 직관적이지만 시간복잡도는 비슷했다. 개선한 풀이 12345678910def solution(m, n, data): result = [0] * m zero_count = m for i in range(1, n+1): if zero_count == 0: break elif result[data[n-i]-1] == 0: result[data[n-i]-1] = n - i zero_count -= 1 return result 12%%times = solution(m, n, data) 포문을 처음부터 끝까지 돌 필요가 없는 경우 중간에 끊어줌으로서 시간을 단축시키기 위해 break를 사용했었다. 그런데 break에 걸어준 조건이 리스트를 처음부터 끝까지 훑어야만 확인할 수 있는 조건이었기 때문에 포문이 한 번 돌 때마다 리스트를 한 번 돌게 되어 오히려 시간복잡도를 늘리는 원인이 되었다. 따라서 break를 거는 if 문의 조건을 단순 계산으로 바꿔줌으로써 시간복잡도를 현저히 줄일 수 있었다.","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"algorithm test","slug":"Coding-drills/algorithm-test","permalink":"https://jyujin39.github.io/categories/Coding-drills/algorithm-test/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"Number Palindrome","slug":"Number-Palindrome","date":"2019-01-18T07:35:01.000Z","updated":"2019-01-18T07:38:22.000Z","comments":true,"path":"2019/01/18/Number-Palindrome/","link":"","permalink":"https://jyujin39.github.io/2019/01/18/Number-Palindrome/","excerpt":"","text":"NumberPalindrome0 에서 $10^n$ 사이의 정수 $10^n-1$ 개 중에서, 그냥 보았을때, 그리고 역순으로 뒤집어서 보았을때 같은 숫자를 카운트 하는 함수를 작성하세요. 테스트 예제 n Return 1 10 0부터 $10^1$, 즉 10까지 숫자중 회문이 성립하는 순자의 갯수를 카운트 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 이 성립 10을 리턴 조건 n은 1부터 1000까지 정수중 하나 뒤집어도 같은 정수란 3, 44, 12321 과 같은 정수들을 뜻합니다. 나의 풀이12345def solution(n): pal_count = 10 for i in range(2, n+1): pal_count += 9 * (10 ** ((i - 1) // 2)) return pal_count 다른 풀이1234def solution(n): if n == 1: return 10 return solution(n-1) + 9 * (10 ** ((n-1)//2)) 나의 풀이와 거의 유사하지만 재귀함수를 사용한 풀이이다. 시간복잡도도 거의 동일하다.","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"algorithm test","slug":"Coding-drills/algorithm-test","permalink":"https://jyujin39.github.io/categories/Coding-drills/algorithm-test/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"누적합","slug":"누적합","date":"2019-01-18T06:35:25.000Z","updated":"2019-01-18T07:11:08.000Z","comments":true,"path":"2019/01/18/누적합/","link":"","permalink":"https://jyujin39.github.io/2019/01/18/누적합/","excerpt":"","text":"누적합길이가 N인 리스트에서 누적합을 구해서 리턴하는 함수를 구하세요. 1부터 N까지 숫자로 이뤄진 길이가 N인 리스트와, 구하려는 누적합의 시작하는 지점과 끝나는 지점을 담은 M개의 쿼리 데이터를 받습니다. 테스트 예제 data queries return [10, 20, 30, 40, 50] [[1, 3], [2, 4], [3, 5], [1, 5], [4, 4]] [60, 90, 120, 150 40] 예제 설명 1번째부터 3번째까지의 누적합 : 60 2번째부터 4번째까지의 누적합 : 90 3번째부터 5번째까지의 누적합 : 120 1번째부터 5번째까지의 누적합 : 150 4번째부터 4번째까지의 누적합 : 40 조건 N은 data의 길이, data요소의 최대값 1&lt;=N&lt;=100000 M은 queries의 길이 1&lt;=M&lt;=10000 나의 풀이123456# 테스트 코드from random import randintN = 100000M = 10000data = [randint(1, N) for _ in range(N)]queries = [sorted([randint(1, N), randint(1, N)]) for _ in range(M)] 첫 번째 풀이 1234567891011def solution(data, queries): sums = [] for i, j in queries: sum = 0 if i == j: sums.append(data[i-1]) continue for k in range(i, j+1): sum += data[k-1] sums.append(sum) return sums 12%%timesolution(data, queries) ​ \\cdots For 루프 안에서 슬라이싱이나 sum 함수를 사용하지 않으려고 코드를 짜다보니 오히려 시간복잡도가 어마어마하게 커졌다. 이 문제는 prefix_sum 알고리즘의 대표적이고 가장 기본적인 문제로, 그 알고리즘을 이용해 풀이를 개선해보았다. Prefix_sum 알고리즘을 이용해 개선한 풀이 12345678910def solution(data, queries): sums = [0] sum = 0 for i in range(len(data)): sum += data[i] sums.append(sum) result = [] for start, end in queries: result.append(sums[end] - sums[start-1]) return result 12%%timesolution(data, queries) ​ 우선 data의 누적합을 미리 다 계산해 그 누적합들을 담은 리스트를 포문 안에서 사용한다. ​ 더 큰 누적합에서 앞 누적합을 빼줌으로써 쿼리에서 요구하는 누적합을 계산해낸다. ​ 그 결과 시간복잡도가 현저히 떨어졌음을 알 수 있다!","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"algorithm test","slug":"Coding-drills/algorithm-test","permalink":"https://jyujin39.github.io/categories/Coding-drills/algorithm-test/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"예산","slug":"예산","date":"2019-01-17T09:56:59.000Z","updated":"2019-01-17T10:13:00.000Z","comments":true,"path":"2019/01/17/예산/","link":"","permalink":"https://jyujin39.github.io/2019/01/17/예산/","excerpt":"","text":"예산S사에서는 각 부서에 필요한 물품을 지원해 주기 위해 부서별로 물품을 구매하는데 필요한 금액을 조사했습니다. 그러나, 전체 예산이 정해져 있기 때문에 모든 부서의 물품을 구매해 줄 수는 없습니다. 그래서 최대한 많은 부서의 물품을 구매해 줄 수 있도록 하려고 합니다. 물품을 구매해 줄 때는 각 부서가 신청한 금액만큼을 모두 지원해 줘야 합니다. 예를 들어 1,000원을 신청한 부서에는 정확히 1,000원을 지원해야 하며, 1,000원보다 적은 금액을 지원해 줄 수는 없습니다. 부서별로 신청한 금액이 들어있는 배열 d와 예산 budget이 매개변수로 주어질 때, 최대 몇 개의 부서에 물품을 지원해 줄 수 있는지 return 하도록 solution 함수를 완성해주세요. 제한사항 d는 부서별로 신청한 금액이 들어있는 배열이며, 길이(전체 부서의 개수)는 1 이상 100 이하입니다. d의 각 원소는 부서별로 신청한 금액을 나타내며, 부서별 신청 금액은 1 이상 100,000 이하의 자연수입니다. budget은 예산을 나타내며, 1 이상 10,000,000 이하의 자연수입니다. 물품을 구매해 줄 수 있는 부서 개수의 최댓값을 return 하세요. 입출력 예 d budget result [1,3,2,5,4] 9 3 [2,2,3,3] 10 4 입출력 예 설명입출력 예 #1 각 부서에서 [1원, 3원, 2원, 5원, 4원]만큼의 금액을 신청했습니다. 만약에, 1원, 2원, 4원을 신청한 부서의 물품을 구매해주면 예산 9원에서 7원이 소비되어 2원이 남습니다. 항상 정확히 신청한 금액만큼 지원해 줘야 하므로 남은 2원으로 나머지 부서를 지원해 주지 않습니다. 위 방법 외에 3개 부서를 지원해 줄 방법들은 다음과 같습니다. 1원, 2원, 3원을 신청한 부서의 물품을 구매해주려면 6원이 필요합니다. 1원, 2원, 5원을 신청한 부서의 물품을 구매해주려면 8원이 필요합니다. 1원, 3원, 4원을 신청한 부서의 물품을 구매해주려면 8원이 필요합니다. 1원, 3원, 5원을 신청한 부서의 물품을 구매해주려면 9원이 필요합니다. 3개 부서보다 더 많은 부서의 물품을 구매해 줄 수는 없으므로 최대 3개 부서의 물품을 구매해 줄 수 있습니다. 입출력 예 #2 모든 부서의 물품을 구매해주면 10원이 됩니다. 따라서 최대 4개 부서의 물품을 구매해 줄 수 있습니다. 나의 풀이 원래 풀이 12345678def solution(d, budget): if sum(d) &lt;= budget: return len(d) i=1 while i &lt;= len(d): if sum(sorted(d)[:-i]) &lt;= budget: return len(d)-i i += 1 ★ 단 1개의 부서에도 예산을 지원해줄 수 없는 경우를 생각하여 while문에 &lt;가 아닌 &lt;= 를 써 주는 것이 핵심! 수정한 풀이 1234567891011def solution(d, budget): total = sum(d) d = sorted(d) if total &lt;= budget: return len(d) i=1 while i &lt;= len(d): total -= d[-i] if total &lt;= budget: return len(d)-i i += 1 while문 안에서 sum 과 리스트 슬라이싱을 반복하는 것이 시간적으로 효율성이 떨어지므로, sum은 while문 바깥에서 한 번만 해주고, 슬라이싱 대신 인덱싱을 하는 방향으로 코드를 수정하였다.","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"Programmers","slug":"Coding-drills/Programmers","permalink":"https://jyujin39.github.io/categories/Coding-drills/Programmers/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"문자열 내 마음대로 정렬하기","slug":"문자열-내-마음대로-정렬하기","date":"2019-01-17T05:30:40.000Z","updated":"2019-01-17T05:33:02.000Z","comments":true,"path":"2019/01/17/문자열-내-마음대로-정렬하기/","link":"","permalink":"https://jyujin39.github.io/2019/01/17/문자열-내-마음대로-정렬하기/","excerpt":"","text":"문자열 내 마음대로 정렬하기문자열로 구성된 리스트 strings와, 정수 n이 주어졌을 때, 각 문자열의 인덱스 n번째 글자를 기준으로 오름차순 정렬하려 합니다. 예를 들어 strings가 [sun, bed, car]이고 n이 1이면 각 단어의 인덱스 1의 문자 u, e, a로 strings를 정렬합니다. 제한 조건 strings는 길이 1 이상, 50이하인 배열입니다. strings의 원소는 소문자 알파벳으로 이루어져 있습니다. strings의 원소는 길이 1 이상, 100이하인 문자열입니다. 모든 strings의 원소의 길이는 n보다 큽니다. 인덱스 1의 문자가 같은 문자열이 여럿 일 경우, 사전순으로 앞선 문자열이 앞쪽에 위치합니다. 입출력 예 strings n return [sun, bed, car] 1 [car, bed, sun] [abce, abcd, cdx] 2 [abcd, abce, cdx] 입출력 예 설명입출력 예 1sun, bed, car의 1번째 인덱스 값은 각각 u, e, a 입니다. 이를 기준으로 strings를 정렬하면 [car, bed, sun] 입니다. 입출력 예 2abce와 abcd, cdx의 2번째 인덱스 값은 c, c, x입니다. 따라서 정렬 후에는 cdx가 가장 뒤에 위치합니다. abce와 abcd는 사전순으로 정렬하면 abcd가 우선하므로, 답은 [abcd, abce, cdx] 입니다. 나의 풀이12def solution(strings, n): return sorted(sorted(strings), key=lambda x : x[n]) ★ sorted의 key 인수를 활용하는 것이 핵심!","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"Programmers","slug":"Coding-drills/Programmers","permalink":"https://jyujin39.github.io/categories/Coding-drills/Programmers/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"Network Inference","slug":"Network-Inference","date":"2019-01-15T14:28:04.000Z","updated":"2019-01-15T14:40:04.000Z","comments":true,"path":"2019/01/15/Network-Inference/","link":"","permalink":"https://jyujin39.github.io/2019/01/15/Network-Inference/","excerpt":"","text":"네트워크 추론확률모형에서 일부 확률변수의 값이 주어졌을 때 다른 값들을 알아내는 것을 추론(inference)이라고 한다. 조건부 확률분포함수 $p(X_{\\text{unknown}}|\\{X\\}_{\\text{known}})$ 을 알면 일부 확률변수의 값 $\\{X\\}_\\text{known}$이 주어졌을 때 다른 확률변수 $X_\\text{unknown}$ 의 확률 $p(X_\\text{unknown})$ 을 알 수 있으므로, 추론은 조건부확률분포함수를 알아내는 것과 같다. 앞서 사용했던 예를 다시 들어보자. 확률변수 A, B, C가 각각 어떤 학생의 건강상태, 공부시간, 시험성적을 나타낸 것이고 모두 0, 1, 2(하,중,상)의 세 가지 값을 가진다. 이 확률변수를 아래 코드를 통해 그래프 확률모형으로 구현한 후 그것을 기반으로 다음 문제를 풀어 보자. 12345678910111213from pgmpy.factors.discrete import TabularCPDfrom pgmpy.models import BayesianModelP_A = TabularCPD('A', 3, [[0.1, 0.6, 0.3]])P_B_I_A = TabularCPD('B', 3, np.array([[0.6, 0.2, 0.2], [0.3, 0.5, 0.2], [0.1, 0.3, 0.6]]), evidence=['A'], evidence_card=[3])P_C_I_B = TabularCPD('C', 3, np.array([[0.8, 0.1, 0.1], [0.1, 0.8, 0.1], [0.1, 0.1, 0.8]]), evidence=['B'], evidence_card=[3]) model = BayesianModel([('A', 'B'), ('B', 'C')])model.add_cpds(P_A, P_B_I_A, P_C_I_B) 이 학생의 시험성적은 어떤 확률분포를 가지는가? 어떤 성적을 맞을 확률이 가장 높은가? 이 학생의 건강상태가 상(2)이었다면 어떤 성적을 맞을 확률이 가장 높은가? 이 학생은 공부 시간이 적었지만(0) 시험성적이 좋았다(2). 이 학생의 건강상태는 어땠을까? 1번 문제는 무조건부 확률분포함수 $P(C)$ 를 찾는 문제이다. 2번 문제는 조건부 확률분포함수 $P(C|A=2)$ 를 찾는 것이고, 3번 문제는 조건부 확률분포함수 $P(A|B=0, C=2)$ 를 찾는 문제이다. 베이지안 네트워크나 마코프 네트워크같은 그래프 확률모형에서 추론을 할 때는 변수제거(variable elimination) 신뢰전파(belief propagation) 방법을 사용한다. 이 방법들은 모두 Exact inference 에 해당한다. 1) 변수제거값을 알고 있는 확률변수 혹은 무조건부 확률변수분포를 알고있는 확률변수부터 네트워크를 따라 차례대로 확률분포를 계산하는 방식을 변수제거(VE:Variable Elimination) 방법이라고 한다. 위에서 예로 든 모형에서 특정 확률변수의 무조건부 확률분포를 구하는 방법을 알아보자. 우선 C의 분포함수를 알 때 B의 분포함수는 다음처럼 구한다. \\begin{eqnarray} P(B=0) &=& \\sum_A P(B=0|A)P(A)\\\\ &=& P(B=0|A=0)P(A=0) + P(B=0|A=1) + P(B=0|A=2)P(A=2) \\end{eqnarray}$B=1, B=2$ 인 경우에도 같은 방법으로 계산한다. 이번에는 C의 분포함수를 계산해보자. P(C) = \\sum _{A,B} P(C|B)P(B|A)P(A)여기서 $\\sum_{A,B}$ 는 A와 B가 가질 수 있는 모든 경우의 조합을 뜻한다. \\sum_{A,B} = \\sum_A \\sum_B따라서 아래와 같이 $P(C=0)$을 구할 수 있다. \\begin{eqnarray} P(C=0) &=& P(C=0|B=0)P(B=0|A=0)P(A=0) + P(C=0|B=0)P(B=0|A=1)P(A=1) \\\\ & &+ P(C=0|B=0)P(B=0|A=2)P(A=2) + P(C=0|B=1)P(B=1|A=0)P(A=0)\\\\ & & + P(C=0|B=1)P(B=1|A=1)P(A=1) + P(C=0|B=1)P(B=1|A=2)P(A=2) \\\\ & & + P(C=0|B=2)P(B=2|A=0)P(A=0) + P(C=0|B=2)P(B=2|A=1)P(A=1) \\\\ & &+ P(C=0|B=2)P(B=2|A=2)P(A=2)\\\\ &=& P(C=0|B=0) P(B=0) + P(C=0|B=1) P(B=1) + P(C=0|B=2) P(B=2) \\\\ \\end{eqnarray}즉, 확률변수 B의 분포가 이미 계산된 상태라면 C의 분포에 대해 확률변수 A의 영향은 없어진다. P(C) = \\sum_B P(C|B)P(B)pgmpy에서는 VariableElimination클래스를 사용해 변수제거법을 적용할 수 있다. 객체를 생성할 때 인수로 네트워크모형을 넣어 생성하고, query 메서드를 사용해 추론을 진행한다. 메서드에 들어가는 인수는 확률분포를 구하려는 확률변수의 리스트에 해당하는 variable_list 와 알고 있는 확률변수 값의 딕셔너리형태인 evidence 가 있다. 아무런 조건이 없을 경우 시험성적의 확률분포는 다음과 같다. 1234from pgmpy.inference import VariableEliminationinfer = VariableElimination(model)print(infer.query([\"C\"])[\"C\"]) 만약 건강 상태가 좋았으면 evidence={&#39;A&#39;:2} 인수를 적용한다. 이 때는 좋은 성적을 받을 가능성이 가장 높아진다. 1print(infer.query([\"C\"], evidence=&#123;\"A\": 2&#125;)[\"C\"]) 시험성적과 공부시간의 정보가 주어진다면 다음처럼 건강상태를 유추할 수도 있다. 1print(infer.query([\"A\"], evidence=&#123;\"B\": 0, \"C\": 2&#125;)[\"A\"]) 몬티 홀 문제변수제거방법을 이용해 몬티 홀 문제를 풀어보자. 0, 1, 2로 표시된 3개의 문 중에 자동차가 있는 문을 나타내는 확률변수는 C, 참가자가 고른 문은 P, 진행자가 여는 문을 H라고 하자. 세 문 중에 자동차가 있는 문과 참가자가 고르는 문의 확률은 동일하게 1/3이다. 1234from pgmpy.factors.discrete import TabularCPDcpd_c = TabularCPD('C', 3, [[0.33, 0.33, 0.33]])print(cpd_c) 12cpd_p = TabularCPD('P', 3, [[0.33, 0.33, 0.33]])print(cpd_p) 하지만 진행자가 여는 문은 자동차가 있는 문의 위치와 참가자가 선택한 문에 따라서 달라진다. 12345cpd_h = TabularCPD('H', 3, [[0, 0, 0, 0, 0.5, 1, 0, 1, 0.5], [0.5, 0, 1, 0, 0, 0, 1, 0, 0.5], [0.5, 1, 0, 1, 0.5, 0, 0, 0, 0 ]], evidence=['C', 'P'], evidence_card=[3, 3])print(cpd_h) 위를 베이지안네트워크 확률모형으로 만들어보자. 진행자의 선택 H는 자동차의 위치 C와 참가자의 선택 P의 영향을 동시에 받는 머리-머리 결합이다. 1234567891011from pgmpy.models import BayesianModelfrom IPython.core.display import Imagefrom networkx.drawing.nx_pydot import to_pydotmodel_monty = BayesianModel([('C', 'H'), ('P', 'H')])model_monty.add_cpds(cpd_c, cpd_p, cpd_h)d = to_pydot(model_monty)d.set_dpi(300)d.set_margin(0.2)Image(d.create_png(), width=400) 그리고 변수제거방법을 사용해 H를 추론해보자. 123from pgmpy.inference import VariableEliminationinfer = VariableElimination(model_monty) 참가자가 0번 문을 선택하는 경우 진행자는 1번 혹은 2번 문을 연다. 이 때 진행자가 1번 문을 연다면 차가 2번 문에 있을 확률이 0번 문에 있을 확률의 2배임을 아래와 같이 확인할 수 있다. 12posterior_c = infer.query(['C'], evidence=&#123;'P': 0, 'H': 1&#125;)print(posterior_c['C']) 참가자가 0번 문을 선택했을 때 진행자가 2번 문을 연다면, 차가 1번 문에 있을 확률이 0번문에 있을 확률의 2배이다. 12posterior_c = infer.query(['C'], evidence=&#123;'P': 1, 'H': 2&#125;)print(posterior_c['C']) 따라서 참가자는 항상 선택을 바꾸는 것이 확률적으로 유리하다. 2) 신뢰전파신뢰전파(BE;Belief Propagation) 방법은 메시지 전달(message passing)방법이라고도 한다. 여기에서는 선형 사슬(linear chain)형태의 마코프 네트워크를 예로 들어 설명하겠지만, 일반적인 네트워크에서도 성립한다. $X_1, \\cdots , X_n$ 의 $N$ 개 확률변수가 선형사슬로 연결된 마코프 네트워크의 결합확률분포는 다음과 같다. p(X_1, \\cdots, X_N) = \\frac{1}{Z}\\psi(X_1,X_2)\\psi(X_2,X_3)\\cdots\\psi(X_{N-1},X_{N})사슬 중간에 있는 $X_n$ 의 확률분포를 구하려면 전체확률의법칙에 따라 $X_n$ 을 제외한 나머지 확률변수들이 가질 수 있는 모든 경우의 확률을 더하면 된다. \\begin{eqnarray} p(X_n) &=& \\sum_{X_1} \\cdots \\sum_{X_{n-1}}\\sum_{X_{n+1}}\\cdots \\sum_{X_N}p(X_1,\\cdots,X_N)\\\\ &=& \\frac{1}{Z}\\sum_{X_1}\\cdots\\sum_{X_{n-1}}\\sum_{X_{n+1}}\\cdots \\sum_{X_N}\\psi(X_1,X_2)\\psi(X_2,X_3)\\cdots\\psi(X_{N-1},X_N) \\end{eqnarray}pgmpy에서는 BeliefPropagation 클래스를 사용해 변수제거법을 적용할 수 있다. 사용법은 VariableElimination 과 같다.","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"체육복","slug":"체육복","date":"2019-01-15T08:57:05.000Z","updated":"2019-01-15T08:58:58.000Z","comments":true,"path":"2019/01/15/체육복/","link":"","permalink":"https://jyujin39.github.io/2019/01/15/체육복/","excerpt":"","text":"체육복오늘은 체육수업이 있는 날입니다. 그런데 점심시간에 도둑이 들어 몇몇 학생의 체육복이 도난을 당했습니다. 다행히 일부 학생들이 여벌의 체육복을 가져왔습니다. 학생들의 번호는 체격 순으로 매겨져 있기 때문에 바로 앞번호의 학생이나 바로 뒷번호의 학생에게만 체육복을 빌려주려고 합니다. 예를 들어, 4번 학생은 3번 학생이나 5번 학생에게만 체육복을 빌려줄 수 있습니다. 당연히 체육복을 2벌 가져온 학생의 체육복이 도난을 당했다면, 여벌의 체육복을 빌려줄 수 없습니다. 체육복이 없으면 체육수업을 들을 수 없기 때문에 체육복을 적절히 빌려 최대한 많은 학생이 체육수업을 듣고 싶습니다. 전체 학생의 수 n, 체육복을 도난당한 학생들의 번호가 담긴 배열 lost, 여벌의 체육복을 가져온 학생들의 번호가 담긴 배열 reserve가 매개변수로 주어질 때, 체육수업을 들을 수 있는 학생의 최댓값을 return 하도록 solution 함수를 작성해주세요. 제한사항 전체 학생의 수는 2명 이상 30명 이하입니다. 체육복을 도난당한 학생의 수는 2명 이상 n명 이하이고 중복되는 번호는 없습니다. 여벌의 체육복을 가져온 학생의 수는 1명 이상 n명 이하이고 중복되는 번호는 없습니다. 입출력 예 n lost reserve return 5 [2, 4] [1, 3, 5] 5 5 [2, 4] [3] 4 입출력 예 설명예제 #11번 학생이 2번 학생에게 체육복을 빌려주고, 3번 학생이나 5번 학생이 4번 학생에게 체육복을 빌려주면 학생 5명이 체육수업을 들을 수 있습니다. 예제 #23번 학생이 2번 학생이나 4번 학생에게 체육복을 빌려주면 학생 4명이 체육수업을 들을 수 있습니다. 나의 풀이12345678910111213def solution(n, lost, reserve): reserve_new = [i for i in reserve if i not in lost] lost_new = [i for i in lost if i not in reserve] for i in reserve_new: if i-1 in lost_new: lost_new.remove(i-1) continue if i+1 in lost_new: lost_new.remove(i+1) return n - len(lost_new)","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"Programmers","slug":"Coding-drills/Programmers","permalink":"https://jyujin39.github.io/categories/Coding-drills/Programmers/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"K번째 수","slug":"K번째-수","date":"2019-01-14T07:47:34.000Z","updated":"2019-01-14T17:10:13.000Z","comments":true,"path":"2019/01/14/K번째-수/","link":"","permalink":"https://jyujin39.github.io/2019/01/14/K번째-수/","excerpt":"","text":"K번째수배열 array의 i번째 숫자부터 j번째 숫자까지 자르고 정렬했을 때, k번째에 있는 수를 구하려 합니다. 예를 들어 array가 [1, 5, 2, 6, 3, 7, 4], i = 2, j = 5, k = 3이라면 array의 2번째부터 5번째까지 자르면 [5, 2, 6, 3]입니다. 1에서 나온 배열을 정렬하면 [2, 3, 5, 6]입니다. 2에서 나온 배열의 3번째 숫자는 5입니다. 배열 array, [i, j, k]를 원소로 가진 2차원 배열 commands가 매개변수로 주어질 때, commands의 모든 원소에 대해 앞서 설명한 연산을 적용했을 때 나온 결과를 배열에 담아 return 하도록 solution 함수를 작성해주세요. 제한사항 array의 길이는 1 이상 100 이하입니다. array의 각 원소는 1 이상 100 이하입니다. commands의 길이는 1 이상 50 이하입니다. commands의 각 원소는 길이가 3입니다. 나의 풀이1234def solution(array, commands): for i, j, k in commands: result.append(sorted(array[i-1:j])[k-1]) return result","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"Programmers","slug":"Coding-drills/Programmers","permalink":"https://jyujin39.github.io/categories/Coding-drills/Programmers/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"Graphical Probability Model","slug":"Graphical-Probability-Model","date":"2019-01-13T13:57:19.000Z","updated":"2019-01-13T14:01:06.000Z","comments":true,"path":"2019/01/13/Graphical-Probability-Model/","link":"","permalink":"https://jyujin39.github.io/2019/01/13/Graphical-Probability-Model/","excerpt":"","text":"그래프 확률모형여러 확률변수의 결합확률분포를 구해야 하는 경우를 생각하자. 예를 들어 A, B, C 3개의 확률변수가 있고, 각 확률변수는 모두 0, 1, 2 세 가지의 값만 가질 수 있는 범주형 확률변수이다. 이ㅍ때 A, B, C 의 결합확률분포는 다음과 같이 나타낼 수 있다. 이 때 우리가 알아야 하는 모수는 총 $3^3 -1 = 26$ 개다. A B C P(A, B, C) 0 0 0 P(A=0,B=0,C=0) 0 0 1 P(A=0,B=0,C=1) 0 0 2 P(A=0,B=0,C=2) 0 1 0 P(A=0,B=1,C=0) 0 1 1 P(A=0,B=1,C=1) 0 1 2 P(A=0,B=1,C=2) 0 2 0 P(A=0,B=2,C=0) 0 2 1 P(A=0,B=2,C=1) 0 2 2 P(A=0,B=2,C=2) 1 0 0 P(A=1,B=0,C=0) 1 0 1 P(A=1,B=0,C=1) 1 0 2 P(A=1,B=0,C=2) 1 1 0 P(A=1,B=1,C=0) 1 1 1 P(A=1,B=1,C=1) 1 1 2 P(A=1,B=1,C=2) 1 2 0 P(A=1,B=2,C=0) 1 2 1 P(A=1,B=2,C=1) 1 2 2 P(A=1,B=2,C=2) 2 0 0 P(A=2,B=0,C=0) 2 0 1 P(A=2,B=0,C=1) 2 0 2 P(A=2,B=0,C=2) 2 1 0 P(A=2,B=1,C=0) 2 1 1 P(A=2,B=1,C=1) 2 1 2 P(A=2,B=1,C=2) 2 2 0 P(A=2,B=2,C=0) 2 2 1 P(A=2,B=2,C=1) 2 2 2 P(A=2,B=2,C=2) 베이지안 네트워크 모형그런데 현실에서는 모든 확률변수가 서로 영향을 미치는 복잡한 경우보다, 특정한 몇 개의 확률분포들이 서로 영향을 미치는 경우가 많다. 예를 들어 확률변수 A, B, C가 각각 어떤 학생의 A : 건강 상태 B : 공부 시간 C : 시험 성적 을 나타낸 것이라고 하자. A, B, C는 $\\{0, 1, 2\\}$ 값을 가질 수 있고, 각각 하, 중 상을 의미한다. 건강상태 A는 공부시간 B에 영향을 미치고, 공부시간 B는 시험 성적 C에 영향을 미친다고 볼 수 있다. 하지만 건강 상태 A는 C와는 직접적인 관계가 없다. 이렇게 다수의 확률변수 중 특정 확률변수끼리 가지는 관계를 그래프로 표현한 것을 그래프 확률모형(Graphical Probability model)이라고 하고, 그래프 확률모형 중에서도 이렇게 인과관계가 확실하여 방향성 그래프로 나타낼 수 있는 것을 베이지안 네트워크 모형(Bayesian Network model)이라고 한다. A, B, C를 베이지안 네트워크모형으로 그리면 다음과 같다. 1234567891011import networkx as nxfrom IPython.core.display import Imagefrom networkx.drawing.nx_pydot import to_pydotg1 = nx.DiGraph()g1.add_path([\"A\", \"B\", \"C\"])d1 = to_pydot(g1)d1.set_dpi(300)d1.set_rankdir(\"LR\")d1.set_margin(0.2)Image(d1.create_png(), width=600) 이 그래프는 사이클(혹은 루프)이 없는 방향성 그래프, DAG(Directed Acyclic Graph) 모형에 해당한다. 방향성 그래프 모델에서는 원인과 결과가 되는 두 확률변수의 관계를 조건부 확률분포로 표현한다. 위 모델의 경우 A와 B의 관계를 $P(B|A)$ 로 나타내고, B와 C의 관계를 $P(C|B)$ 로 나타낸다. 그리고 전체 확률변수들간의 관계는 이러한 조건부 확률분포를 결합하여 아래와 같이 나타낸다. P(A, B, C) = P(A)P(B|A)P(C|B)B의 분포는 A의 값에 따라 달라지고, C의 분포는 B의 값에 따라 달라진다. 다만 유의할 점은, A와 C 사이에 직접적인 인과관계는 없지만 상관관계는 있을 수 있다는 점이다. 예를 들어 A-B, B-C간의 관계가 모두 양의 상관관계이면, A가 커졌을 때 B가 커지고 B가 커지면 C도 커지므로 결국 A와 C 사이에도 양의 상관관계가 성립한다. 결합확률분포를 이루는 요소들을 각각 표로 나타내면 다음과 같다. A P(A) A=0 P(A=0) A=1 P(A=1) A=2 P(A=2) B P(B\\ A=0) P(B\\ A=1) P(B\\ A=2) B=0 P(B=0\\ A=0) P(B=0\\ A=1) P(B=0\\ A=2) B=1 P(B=1\\ A=0) P(B=1\\ A=1) P(B=1\\ A=2) B=2 P(B=2\\ A=0) P(B=2\\ A=1) P(B=2\\ A=2) C P(C\\ B=0) P(C\\ B=1) P(C\\ B=2) C=0 P(C=0\\ B=0) P(C=0\\ B=1) P(C=0\\ B=2) C=1 P(C=1\\ B=0) P(C=1\\ B=1) P(C=1\\ B=2) C=2 P(C=2\\ B=0) P(C=2\\ B=1) P(C=2\\ B=2) 이 경우 우리가 알아야 하는 모수의 수는 총 14개로, 조건부확률을 사용하지 않았을 때보다 크게 감소한다. pgmpy 패키지를 이용해 앞의 예제를 파이썬으로 구현해보자. 조건부확률 $P(A), P(B|A), P(C|B)$ 는 TabularCPD 클래스로 다음처럼 구현할 수 있다. 우선 A의 확률분포는 $P(A=0)=0.1, P(A=1)=0.6, P(A=2)=0.3$ 라고 하자. 1234from pgmpy.factors.discrete import TabularCPDP_A = TabularCPD('A', 3, [[0.1, 0.6, 0.3]])print(P_A) 이제 $P(B|A)$를 시각화해보자. 건강 상태가 나쁘면(A=0), 공부시간이 적거나(B=0), 보통이거나(B=1), 많을(B=2) 확률은 각각 50%, 30%, 20%라고 하자. 건강 상태가 보통이면(A=1), 공부시간이 적거나(B=0), 보통이거나(B=1), 많을(B=2) 확률은 각각 20%, 60%, 20%이다. 건강 상태가 좋으면(A=2), 공부시간이 적거나(B=0), 보통이거나(B=1), 많을(B=2) 확률은 각각 20%, 30%, 50%이다. 1234P_B_I_A = TabularCPD('B', 3, np.array([[0.5, 0.3, 0.3], [0.3, 0.6, 0.2], [0.2, 0.1, 0.5]]), evidence=['A'], evidence_card=[3])print(P_B_I_A) 마지막으로 $P(C|B)$를 시각화해보자. 공부시간이 적으면(B=0), 성적이 나쁘거나(C=0), 보통이거나(C=1), 좋을(C=2) 확률은 각각 80%, 10%, 10%이다. 공부시간이 보통이면(B=1), 성적이 나쁘거나(C=0), 보통이거나(C=1), 좋을(C=2) 확률은 각각 10%, 80%, 10%이다. 공부시간이 많으면(B=2), 성적이 나쁘거나(C=0), 보통이거나(C=1), 좋을(C=2) 확률은 각각 10%, 10%, 80%이다. 1234P_C_I_B = TabularCPD('C', 3, np.array([[0.8, 0.1, 0.1], [0.1, 0.8, 0.1], [0.1, 0.1, 0.8]]), evidence=['B'], evidence_card=[3])print(P_C_I_B) 이 조건부 확률들을 결합하여 하나의 베이지안 네트워크로 만들려면 BayesianModel 클래스를 사용한다. 생성자에는 노드를 연결한 그래프 정보를 넣고 add_cpds 메서드로 조건부확률을 추가할 수 있다. graphviz와 pydot을 이용해 네트워크모형을 시각화까지 해보면 아래와 같은 그래프가 나온다. 위에서 설정한 조건부확률분포가 모두 담겨있는 그래프이다. 123456789101112from pgmpy.models import BayesianModelfrom IPython.core.display import Imagefrom networkx.drawing.nx_pydot import to_pydotmodel = BayesianModel([('A', 'B'), ('B', 'C')])model.add_cpds(P_A, P_B_I_A, P_C_I_B)d = to_pydot(model)d.set_dpi(300)d.set_margin(0.2)d.set_rankdir(\"LR\")Image(d.create_png(), width=600) 이제 이 모형으로부터 여러가지 추론을 할 수 있다. 예를 들어 전체 결합확률분포함수를 찾고 그 함수로부터 A, B, C의 marginal 확률분포를 계산하면 A, B, C 의 어떤 값이 가장 확률이 높은지 알 수 있다. VariableElimination 클래스를 이용해 분석해보면 여기서 시험성적이 가장 좋을 확률, 그러니까 $P(C=2)$는 26.1%이다. 1234from pgmpy.inference import VariableEliminationinference = VariableElimination(model)result = inference.query(variables=[\"C\"])print(result[\"C\"]) 베이지안 네트워크의 결합확률분포베이지안 네트워크 모형을 만들기 위해서는 대상이 되는 확률변수를 노드로 생성하고, 인과관계가 있는 노드끼리 방향성이 있는 간선으로 연결해 그래프를 만들어주어야 한다. 이렇게 네트워크가 생성되면 확률변수들의 결합확률분포가 다음처럼 주어진다. P(X_1, \\cdots, X_N) = \\prod^N_{i=1}P(X_i|Pa(X_i))여기서 $Pa(X_i)$ 는 $X_i$ 의 부모노드이다. 예를 들어 $X_1, \\cdots, X_6$ 의 관계가 위 그래프와 같다면 이 확률변수들의 결합확률분포는 다음과 같다. P(X_1, X_2, X_3, X_4, X_5, X_6, X_7) \\\\ = P(X_1) P(X_2) P(X_3 | X_2) P(X_4| X_2, X_3) P(X_5|X_4) P(X_6|X_4) P(X_7|X_2)조건부 독립베이지안 네트워크를 만들 때 중요한 것은 확률변수간의 조건부독립 관계가 그래프에 나타나있어야 한다는 점이다. 조건부 독립(conditional independence)은 일반적인 독립과 달리 조건이 되는 확률변수가 존재해야 한다. 일반적으로 A, B 가 독립이 되는 정의는 $P(A, B)=P(A)P(B)$ 지만, 조건부 독립은 C라는 확률변수가 조건이 되어 아래와 같이 정의된다. P(A, B|C) = P(A|C)P(B|C)즉, C에 대한 조건부 결합확률분포가 조건부확률분포의 곱으로 나타난다. A, B가 C에 대해 조건부 독립이면 다음 식도 만족한다. P(A|B, C) = P(A|C)\\\\ P(B|A,C) = P(B|C)주의할 점은 조건부 독립과 (무조건부)독립은 다르고, 서로 관계가 없다는 점이다. 즉, 두 확률변수가 독립이라고 해서 항상 조건부 독립이 되는 것도 아니고, 조건부 독립이라고 해서 꼭 독립이 되는 것도 아니다. P(A,B) = P(A)P(B)\\;\\; \\bcancel{\\implies} \\;\\; P(A,B|C) = P(A|C)P(B|C) \\\\ P(A,B|C) = P(A|C)P(B|C) \\;\\; \\bcancel{\\implies} \\;\\; P(A,B) = P(A)P(B)방향성 분리방향성 분리(d-separation, directed separation) 정리는 방향성 그래프 모형에서 어떤 두 노드(확률변수)가 조건부 독립인지 아닌지 알아보는 방법이다. 다음과 같은 세 가지 간선(edge)결합을 알아야 한다. 꼬리-꼬리 결합 머리-꼬리 결합 머리-머리 결합 1) 꼬리-꼬리 결합우선 확률변수 A, B가 공통의 부모 C를 가지는 경우를 보자. 이 때 C에는 간선(화살표)의 꼬리가 두 개 붙어있게 되므로 C는 꼬리-꼬리(tail-to-tail) 결합이다. 이 때 A와 B는 독립은 아니지만 조건부 독립이다. P(A, B|C) = \\frac{P(A,B,C)}{P(C)} = \\frac{P(A|C)P(B|C)P(C)}{P(C)} = P(A|C)P(B|C)이런 상태를 “C가 A와 B 사이를 막고 있다(block)”고 한다. 2) 머리-꼬리 결합다음으로는 인과관계인 확률변수 A와 B 사이에 C가 끼어있는 경우이다. 이 때 노드 C의 왼쪽에는 간선의 머리가, 오른쪽에는 간선의 꼬리가 붙어있기 때문에 머리-꼬리(head-to-tail)결합이라고 한다. 이 경우에도 마찬가지로 A와 B는 독립은 아니지만 조건부 독립이 성립하며, C가 A와 B 사이를 막고 있는 경우이다. 3) 머리-머리 결합마지막으로 두 확률변수 A, B를 부모로 갖는 노드 C가 있다고 하자. 이러한 구조는 V-구조라고도 하며 C에 붙는 두 간선 모두 머리가 오기 때문에 머리-머리(head-to-head) 결합이라고 한다. 이 경우는 앞의 두 경우와 달리 A와 B가 (무조건부)독립이다. P(A,B,C) = P(A)P(B)P(C|A,B)\\\\ P(A,B) = \\sum_cP(A)P(B)P(C|A,B) = P(A)P(B)하지만 A와 B는 조건부 독립은 아니다. 예를 들어 A가 늦잠을 자는 것을 나타내는 확률변수, B가 길이 막히는 것을 나타내는 확률변수, C가 지각하는 것을 나타내는 확률변수라고 할 때, 늦잠을 자는 것과 길이 막히는 것은 서로 독립이다. 그런데 일단 지각이 발생한 상황에서는 A와 B는 서로 독립이 아니며, 이 경우에는 반-상관관계를 갖는다. 즉, 늦잠을 자지 않았다면 길이 막혔을 가능성이 높아지고, 길이 막히지 않았다면 늦잠을 잤을 확률이 높아진다. 이러한 것을 explaining-out이라고 한다. 이는 C가 A,B의 바로 아래 자식이 아니라 아래 그림처럼 D를 거친 후손(descendent)인 경우에도 성립한다. 위 상황들을 정리한 것이 방향성분리(d-separation) 정리 이다. 이 정리에 따르면 A와 B가 C에 대해서 조건부 독립인 경우는 다음 조건이 만족될 때이다. C가 A, B 사이의 경로에 있는 꼬리-꼬리 혹은 머리-꼬리 결합이다. C가 A, B 사이의 경로에 있는 머리-머리 결합 혹은 그 자손이 아니어야 한다. 마코프 네트워크확률변수간의 인과관계가 순환(cycle)관계를 이루어서 방향성이 있는 베이지안네트워크로 구현할 수 없는 경우도 있다. 이 때는 무방향성 그래프인 마코프 네트워크(Markov network)를 사용한다. 3 x 3 이미지의 경우를 예로 들 수 있다. 마코프 네트워크는 클리크(clique)로 구성되는데, 클리크를 구성하는 확률변수의 분포는 포텐셜 함수(potential function) 혹은 팩터(factor)로 나타낼 수 있다. 팩터는 결합확률분포에 양의 상수를 곱한 함수로, 결합확률분포에 비례하지만 모든 확률을 더해서 1이 되어야 한다는 조건이 빠진다. 마코프 네트워크의 확률분포마코프 네트워크의 결합확률분포는 마코프 네트워크를 구성하는 모든 클리크의 팩터의 곱으로 나타난다. P(X) = \\frac{1}{Z(X)}\\prod_{\\{c\\}}\\psi_C(X_C) $C$ : 클리크 $X_C$ : 클리크 안의 확률변수 $\\psi_C$ : 클리크의 팩터함수 $\\{C\\}$ : 모든 클리크의 집합 $Z$ : 파티션 함수 위 그래프의 경우 9개의 확률변수의 결합확률분포를 다음처럼 나타낼 수 있다. P(X_{11}, \\cdots,X_{33}) = \\frac{1}{Z}\\prod \\psi(X_{11},X_{12})\\psi(X_{11},X_{21})\\psi(X_{12},X_{13}) \\cdots \\\\ \\psi(X_{23},X_{33})\\psi(X_{32},X_{33})에너지 함수팩터함수는 다음과 같은 형태로 표시할 수 있다. \\psi(X) = \\exp(-E(X))이 식에서 $E(X)$ 를 에너지함수(energe function) 라고 한다. X의 확률이 높을수록 에너지함수의 값은 작아진다. 예를 들어 0, 1만을 값으로 갖는 베르누이 확률변수 $X_1, X_2$ 가 다음과 같은 에너지함수로 표현되는 경우, E(X_1,X_2) = -3(2X_1 - 1)(2X_2-1)팩터함수의 값을 구하면 다음과 같다. \\psi(X_1=1,X_2=1) = e^3\\\\ \\psi(X_1=0,X_2=0) = e^3\\\\ \\psi(X_1=1,X_2=0) = e^{-3}\\\\ \\psi(X_1=0,X_2=1) = e^{-3}여기서 알 수 있는 점은 $X_1,X_2$ 둘 다 같은 값을 가질 확률은 서로 다른 값을 가질 확률에 비해 높다는 것이다. 즉, 서로 양의 상관관계를 갖는다. pgmpy의 DiscreteFactor 클래스를 이용해 위 그래프의 팩터함수를 구현할 수 있다. 예를 들어 X_{11}, X_{12} 의 팩터함수가 $X_{12} = 0$ $X_{12} = 1$ $X_{11}=0$ 10 1 $X_{11}=1$ 1 10 이면 다음처럼 구현한다. 12345from pgmpy.factors.discrete import DiscreteFactorfactor = DiscreteFactor(['X11', 'X12'], cardinality=[2, 2], values=[[10, 1], [1, 10]])model.add_factors(factor) 이미지 완성마코프 네트워크의 예로 다음과 같은 두 종류의 5 x 5 이미지 데이터가 있다고 하자. 12345678910111213141516171819202122n_char = 2images = np.zeros((n_char, 5, 5))idx = []idx.append(np.array([ (0, 1), (0, 2), (0, 3), (1, 0), (1, 4), (2, 0), (2, 2), (2, 4), (3, 0), (3, 4), (4, 1), (4, 2), (4, 3), ]))idx.append(np.array([ (0, 0), (0, 4), (1, 1), (1, 3), (2, 2), (3, 1), (3, 3), (4, 0), (4, 4),]))for k, idx in enumerate(idx): for i, j in idx: images[k, i, j] = 1plt.figure(figsize=(6, 2))for i in range(n_char): plt.subplot(1, n_char, i + 1) plt.imshow(images[i], cmap=plt.cm.bone_r) plt.grid(False) plt.xticks(()) plt.yticks(()) plt.title(i) 이 두 네트워크모형의 팩터함수를 다음과 같이 학습시킨다. 12345678910111213141516171819from pgmpy.models import MarkovModelfrom pgmpy.factors.discrete import DiscreteFactordef get_factor(v1, v2, idx1, idx2): p00 = p01 = p10 = p11 = 0 for k in range(num_images): if images[k, idx1[0], idx1[1]] == 0 and images[k, idx2[0], idx2[1]] == 0: p00 += 1 if images[k, idx1[0], idx1[1]] == 0 and images[k, idx2[0], idx2[1]] == 1: p01 += 1 if images[k, idx1[0], idx1[1]] == 1 and images[k, idx2[0], idx2[1]] == 0: p10 += 1 if images[k, idx1[0], idx1[1]] == 1 and images[k, idx2[0], idx2[1]] == 1: p11 += 1 factor = DiscreteFactor([v1, v2], cardinality=[2, 2], values=[[p00, p01], [p10, p11]]) return factormodel = MarkovModel() $X_{11}$ 과 $X_{12}$ 의 결합확률 팩터를 보면 다음과 같다. 1234567891011121314151617181920num_images = images.shape[0]n1 = images.shape[1]n2 = images.shape[2]for i in range(n1): for j in range(n2): if j &lt; n2 - 1: v1 = \"X&#123;&#125;&#123;&#125;\".format(i + 1, (j + 1)) v2 = \"X&#123;&#125;&#123;&#125;\".format(i + 1, (j + 2)) model.add_edge(v1, v2) factor = get_factor(v1, v2, (i, j), (i, j + 1)) model.add_factors(factor) if i &lt; n1 - 1: v1 = \"X&#123;&#125;&#123;&#125;\".format(i + 1, (j + 1)) v2 = \"X&#123;&#125;&#123;&#125;\".format(i + 2, (j + 1)) model.add_edge(v1, v2) factor = get_factor(v1, v2, (i, j), (i + 1, j)) model.add_factors(factor) f = model.get_factors()[0]print(f)","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"graph","slug":"graph","date":"2019-01-13T10:50:08.000Z","updated":"2019-01-13T10:55:42.000Z","comments":true,"path":"2019/01/13/graph/","link":"","permalink":"https://jyujin39.github.io/2019/01/13/graph/","excerpt":"","text":"그래프그래프(graph)는 다음 그림처럼 노드(node 혹은 vertex)와 노드들을 잇는 간선(edge)으로 이루어진 구조를 말한다. 수학적으로 그래프 $G$ 는 노드집합 $V$ 와 간선집합 $E$ 로 구성된다. G = (V, E)간선은 두 개의 노드로 이루어진, 순서가 있는 쌍(ordered pair)이다. E \\subseteq V \\times V위에서 그린 그래프는 4개의 노드 집합과 6개의 간선 집합을 갖는다. V = \\{0, 1, 2, 3\\}\\\\ E = \\{(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)\\}방향성 그래프와 비방향성 그래프만약 간선 $(a, b)$와 $(b, a)$가 있을 때, 이 두 간선을 다른 것으로 본다면 방향이 있는 방향성 그래프(directed graph), 같은 것으로 본다면 방향이 없는 비방향성 그래프(undirected graph)이다. 그래프를 시각화할 때 방향성은 화살표로 표시한다. NetworkX 패키지NetworkX는 그래프를 다루기 위한 파이썬 패키지이다. 비방향성 그래프를 만드는 클래스 Graph 와, 방향성 그래프를 만드는 클래스DiGraph 를 제공한다. 123# !pip3 install networkximport networkx as nxg1 = nx.DiGraph() 위에서 g1이라는 방향성 그래프를 생성하였다. 노드를 추가하려면 add_node 메서드를 사용한다. 노드에는 숫자나 문자열을 사용할 수 있으며, nodes 메서드로 추가된 노드들을 확인할 수 있다. 1234g1.add_node(\"a\")g1.add_node(1)g1.add_node(2)g1.nodes() 간선을 추가할 때는add_edge 메서드를 사용한다. 간선을 이을 두 노드를 인수로 사용한다. 그래프에 포함된 간선은 edges 메서드로 확인할 수 있다. 123g1.add_edge(1, 'a')g1.add_edge(1, 2)g1.edges() Graphviz 프로그램과 pydot 패키지를 설치하면 이를 시각화할 수 있다. 12345678from IPython.core.display import Imagefrom networkx.drawing.nx_pydot import to_pydotd1 = to_pydot(g1)d1.set_dpi(300)d1.set_rankdir(\"LR\")d1.set_margin(1)Image(d1.create_png(), width=300) 노드 집합 $V$ 와 간선 집합 $E$ 를 갖는 그래프 $G$ 에 포함된 노드의 개수를 그래프의 크기(cardinality)라고 한다. $|G|$ 또는 $|V|$ 로 나타내며, 간선의 개수는 $|E|$ 로 나타낸다. NetworkX 패키지에서는 각각 len , number_of_nodes, number_of_edges 메서드로 계산할 수 있다. 1len(g1), g1.number_of_nodes(), g1.number_of_edges() 만약 두 노드 $a, b$ 를 포함하는 간선 $(a,b)$ 가 $E$ 안에 존재하면 두 노드는 인접(adjacent)하다고 하며, 인접한 두 노드를 서로 이웃(neighbor)이라고 한다. (a, b) \\in ENetworkX 패키지 Graph 클래스의 neighbors 메서드는 인수로 받은 노드에 인접한 노드를 생성하므로 인접성을 확인하는 데 사용할 수 있다. 12for n in g1.neighbors(1): print(n) 12 in g1.neighbors(1), 1 in g1.neighbors(2), 'a' in g1.neighbors(2), 'a' in g1.neighbors(1) 만약 어떤 노드에서 출발해 자기 자신으로 바로 돌아오는 간선이 있다면 셀프 루프(self loop)라고 한다. 다음 그래프에서는 노드2에 셀프루프가 있는 것이다. 12345678910111213g2 = nx.Graph()g2.add_node(1)g2.add_node(2)g2.add_node(3)g2.add_edge(1, 2)g2.add_edge(2, 2)g2.add_edge(2, 3)np.random.seed(0)d2 = to_pydot(g2)d2.set_dpi(600)d2.set_rankdir(\"LR\")Image(d2.create_png(), width=600) 워크, 트레일, 패스어떤 노드를 출발해서 다른 노드로 도달하기 위한 인접한 노드의 순서열을 워크(walk)라고 하고, 워크 중에서 동일한 노드를 두 번 이상 지나지 않는 워크를 트레일(trail), 시작과 끝 노드를 제외하고 동일한 노드를 두 번 이상 지나지 않는 워크를 패스(path)라고 한다. 패스 중에서 시작점과 끝점이 동일한 패스를 사이클(cycle)이라고 하며, 사이클이 하나도 없는 그래프를 어사이클릭 그래프(acyclic graph)라고 한다. 12345678910111213141516171819g3 = nx.DiGraph()g3.add_node(\"a\")g3.add_node(\"b\")g3.add_node(\"c\")g3.add_node(\"d\")g3.add_node(\"e\")g3.add_node(\"f\")g3.add_edge(\"a\", \"b\")g3.add_edge(\"c\", \"a\")g3.add_edge(\"b\", \"c\")g3.add_edge(\"c\", \"d\")g3.add_edge(\"d\", \"e\")g3.add_edge(\"e\", \"c\")d3 = to_pydot(g3)d3.set_dpi(600)d3.set_rankdir(\"LR\")d3.set_margin(0.5)Image(d3.create_png(), width=800) 위 그래프 $g3$에서 워크, 트레일, 패스, 사이클을 찾아보자. $a- b-c-a-b-c-d-e-c$ 는 $a$ 에서 $c$ 로 가는 워크이다. 하지만 트레일이나 패스는 아니다. $a-b-c-d-e$ 는 트레일이다. $a-b-c-d-e-c$ 는 패스지만 트레일은 아니다. $a-b-c-a$ 는 사이클이다. has_path 명령으로 두 노드간에 패스가 존재하는지 알 수 있다. 패스가 존재하면 shortest_path 명령으로 가장 짧은 패스를 구할 수 있다. 1nx.has_path(g3, 'a', 'b'), nx.has_path(g3, 'a', 'e'), nx.has_path(g3, 'a', 'f') 1nx.shortest_path(g3, 'a', 'e') 클리크 클리크(clique) : 모든 노드끼리 간선이 존재하는 무방향성 그래프의 노드 집합 최대 클리크(maximal clique) : 클리크에 포함된 노드에 인접한 다른 노드를 추가하면 클리크가 아니게 되는 것 1234567891011121314151617181920g4 = nx.Graph()g4.add_node(\"a\")g4.add_node(\"b\")g4.add_node(\"c\")g4.add_node(\"d\")g4.add_node(\"e\")g4.add_node(\"f\")g4.add_edge(\"a\", \"b\")g4.add_edge(\"a\", \"c\")g4.add_edge(\"b\", \"c\")g4.add_edge(\"b\", \"d\")g4.add_edge(\"c\", \"d\")g4.add_edge(\"d\", \"e\")g4.add_edge(\"d\", \"f\")g4.add_edge(\"e\", \"f\")d4 = to_pydot(g4)d4.set_dpi(600)d4.set_rankdir(\"LR\")Image(d4.create_png(), width=800) 위 그래프에서 클리크를 찾아보려면 enumerate_all_cliques, 최대 클리크를 찾아보려면 find_cliques 명령을 사용하면 된다. 1[c for c in nx.enumerate_all_cliques(g4)] 1[c for c in nx.find_cliques(g4)] 특정 노드가 포함된 클리크를 찾아보려면 해당 노드를 인수로 설정하여 cliques_containing_node 명령을 사용하면 된다. 1nx.cliques_containing_node(g4, ['a']) 1nx.cliques_containing_node(g4, ['a','b'])","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"모의고사","slug":"모의고사","date":"2019-01-12T11:42:20.000Z","updated":"2019-01-12T23:20:23.000Z","comments":true,"path":"2019/01/12/모의고사/","link":"","permalink":"https://jyujin39.github.io/2019/01/12/모의고사/","excerpt":"","text":"모의고사문제 설명수포자는 수학을 포기한 사람의 준말입니다. 수포자 삼인방은 모의고사에 수학 문제를 전부 찍으려 합니다. 수포자는 1번 문제부터 마지막 문제까지 다음과 같이 찍습니다. 1번 수포자가 찍는 방식: 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, … 2번 수포자가 찍는 방식: 2, 1, 2, 3, 2, 4, 2, 5, 2, 1, 2, 3, 2, 4, 2, 5, … 3번 수포자가 찍는 방식: 3, 3, 1, 1, 2, 2, 4, 4, 5, 5, 3, 3, 1, 1, 2, 2, 4, 4, 5, 5, … 1번 문제부터 마지막 문제까지의 정답이 순서대로 들은 배열 answers가 주어졌을 때, 가장 많은 문제를 맞힌 사람이 누구인지 배열에 담아 return 하도록 solution 함수를 작성해주세요. 제한 조건 시험은 최대 10,000 문제로 구성되어있습니다. 문제의 정답은 1, 2, 3, 4, 5중 하나입니다. 가장 높은 점수를 받은 사람이 여럿일 경우, return하는 값을 오름차순 정렬해주세요. 나의 풀이123456789101112131415161718192021222324252627282930313233def solution(answers): import collections # collections 모듈 이용 cntr = collections.Counter ans_1 = [1,2,3,4,5] ans_2 = [2,1,2,3,2,4,2,5] ans_3 = [3,3,1,1,2,2,4,4,5,5] m = len(answers) // len(ans_1) # 몫 n = len(answers) % len(ans_1) # 나머지 ans_1 = (ans_1*m) + (ans_1[:n]) m = len(answers) // len(ans_2) n = len(answers) % len(ans_2) ans_2 = (ans_2*m) + (ans_2[:n]) m = len(answers) // len(ans_3) n = len(answers) % len(ans_3) ans_3 = (ans_3*m) + (ans_3[:n]) scores = cntr() for i in range(1, len(answers)+1): if answers[i-1] == ans_1[i-1]: scores[1] += 1 if answers[i-1] == ans_2[i-1]: scores[2] += 1 if answers[i-1] == ans_3[i-1]: scores[3] += 1 return sorted([i for i in scores.keys() if scores[i] == max(scores.values())])","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"Programmers","slug":"Coding-drills/Programmers","permalink":"https://jyujin39.github.io/categories/Coding-drills/Programmers/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"완주하지 못한 선수","slug":"완주하지-못한-선수","date":"2019-01-12T04:24:32.000Z","updated":"2019-01-12T23:20:31.000Z","comments":true,"path":"2019/01/12/완주하지-못한-선수/","link":"","permalink":"https://jyujin39.github.io/2019/01/12/완주하지-못한-선수/","excerpt":"","text":"완주하지 못한 선수문제 설명수많은 마라톤 선수들이 마라톤에 참여하였습니다. 단 한 명의 선수를 제외하고는 모든 선수가 마라톤을 완주하였습니다. 마라톤에 참여한 선수들의 이름이 담긴 배열 participant와 완주한 선수들의 이름이 담긴 배열 completion이 주어질 때, 완주하지 못한 선수의 이름을 return 하도록 solution 함수를 작성해주세요. 제한사항 마라톤 경기에 참여한 선수의 수는 1명 이상 100,000명 이하입니다. completion의 길이는 participant의 길이보다 1 작습니다. 참가자의 이름은 1개 이상 20개 이하의 알파벳 소문자로 이루어져 있습니다. 참가자 중에는 동명이인이 있을 수 있습니다. 나의 풀이1234567# # testset_1# participant = ['seungwoo', 'yujin', 'milk', 'babo']# completion = ['seungwoo','yujin', 'milk']# testset_2participant = ['milk','milk','yujin']completion = ['milk','yujin'] 첫 번째 풀이 12345678910def solution(participant, completion): i = 0 participant.sort() completion.sort() while participant[i] == completion[i]: i += 1 if i &gt;= len(completion): break return participant[-1] return participant[i] 1solution(participant, completion) ‘milk’ 두 번째 풀이 123456789101112def solution(participant, completion): dic = &#123;&#125; for name in participant: if name in dic: dic[name] += 1 else: dic[name] = 1 for name in completion: dic[name] -= 1 return list(dic.keys())[list(dic.values()).index(1)] 1solution(participant, completion) ‘milk’","categories":[{"name":"Coding drills","slug":"Coding-drills","permalink":"https://jyujin39.github.io/categories/Coding-drills/"},{"name":"Programmers","slug":"Coding-drills/Programmers","permalink":"https://jyujin39.github.io/categories/Coding-drills/Programmers/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"Clustering Methods","slug":"Clustering-Methods","date":"2019-01-11T08:03:15.000Z","updated":"2019-01-11T10:53:48.000Z","comments":true,"path":"2019/01/11/Clustering-Methods/","link":"","permalink":"https://jyujin39.github.io/2019/01/11/Clustering-Methods/","excerpt":"","text":"클러스터링 방법1. K-Means 클러스터링앞서 언급했던 5가지 클러스터링 방법 중 첫번째로 소개할 K-Means 클러스터링 알고리즘은 가장 단순하고 빠른 클러스터링 알고리즘 중 하나다. 이 클러스터링 방법에서는 아래 목적함수 값이 최소화될 때까지 클러스터의 중심(centroid) 위치와 각 데이터가 소속될 클러스터를 반복해서 찾는다. 목적함수 값을 inertia 라고도 한다. J = \\sum^K_{k=1}\\sum_{i\\in C} d(x_i, \\mu_k) $K$ : 클러스터의 개수 $C_k$ : $k$ 번째 클러스터에 속하는 데이터 집합 $\\mu_k$ : $k$ 번째 클러스터의 중심 위치 $d(x_i,\\mu_k)$ : 두 데이터 $x_i, \\mu_k$ 사이의 거리 혹은 비유사도 유클리드 거리를 사용할 경우: d(x_i,\\mu_k) = ||x_i - \\mu_k ||^2 K-Means 클러스터링 방법의 세부 알고리즘은 다음과 같다. 임의 중심값 $\\mu_k$ 를 고른다. 보통 데이터 샘플 중에서 $K$개를 선택한다. 중심값에서 각 데이터까지의 거리를 계산한다. 각 데이터에서 가장 가까운 중심을 선택하여 클러스터를 갱신한다. 다시 만들어진 클러스터에 대해 중심을 다시 계산하고 위 과정을 반복한다. Scikit-learn의 cluster 서브패키지는 K-Means 클러스터링을 위한 KMeans 클래스를 제공하고, 다음과 같은 인수를 받는다. n_clusters : 클러스터의 개수 init : 초기화 방법. random 이면 무작위, k-means++이면 K-Means++ 방법. 또는 각 데이터의 클러스터 라벨 n_init : 초기 중심값 시도 횟수. 디폴트는 10. 횟수만큼의 무작위 중심값 중 가장 좋은 값을 선택함 max_iter : 최대 반복 횟수 random_state : 시드값 다음은 make_blobs 명령으로 만든 데이터를 2개의 클러스터로 K-means클러스터링 하는 과정이다. 마커의 모양은 클러스터를 나타내며, 크기가 큰 마커가 중심값이다. 각 단계에서 중심값은 전 단계의 클러스터의 평균으로 다시 계산된다. 1234567891011121314151617181920212223242526from sklearn.datasets import make_blobsfrom sklearn.cluster import KMeansX, _ = make_blobs(n_samples=20, random_state=4)def plot_KMeans(n): model = KMeans(n_clusters=2, init=\"random\", n_init=1, max_iter=n, random_state=8).fit(X) c0, c1 = model.cluster_centers_ plt.scatter(X[model.labels_ == 0, 0], X[model.labels_ == 0, 1], marker='v', facecolor='r', edgecolors='k') plt.scatter(X[model.labels_ == 1, 0], X[model.labels_ == 1, 1], marker='^', facecolor='y', edgecolors='k') plt.scatter(c0[0], c0[1], marker='v', c=\"r\", s=200) plt.scatter(c1[0], c1[1], marker='^', c=\"y\", s=200) plt.grid(False) plt.title(\"iteration=&#123;&#125;, score=&#123;:5.2f&#125;\".format(n, model.score(X)))plt.figure(figsize=(8, 8))plt.subplot(321)plot_KMeans(1)plt.subplot(322)plot_KMeans(2)plt.subplot(323)plot_KMeans(3)plt.subplot(324)plot_KMeans(4)plt.tight_layout()plt.show() K-Means++K-Means++ 알고리즘은 KMeans 클러스터링 클래스의 인수로 설정할 수 있는, 초기 중심값을 설정하기 위한 알고리즘이다. 랜덤하게 초기중심값을 설정했을 때 클러스터링 성능이 떨어지는 점을 보완하기 위한 방법이 된다. 다음과 같은 방법을 통해 되도록 서로 멀리 떨어진 중심값 집합을 찾아낸다. 중심값을 저장할 집합 $M$ 을 준비한다. 일단 하나의 중심 $\\mu_0$ 를 랜덤하게 선택해 $M$ 에 넣는다. $M$ 에 속하지 않는 모든 샘플 $x_i$ 에 대해 거리 $d(M, x_i)$를 계산한다. $M$ 안에 현재까지 들어있는 모든 중심값 $\\mu_k$ 중 해당 데이터 $x_i$ 와 가장 가까운 중심값과의 거리에 해당한다. $d(M, x_i)$에 비례하는 확률로 다음 중심 $\\mu$ 를 선택한다. $k$개의 중심이 선택될 때까지 위 과정을 반복한다. $k$ 개의 중심값에 대해 K-Means 알고리즘을 사용해 클러스터링을 진행한다. 다음은 K-Means++ 알고리즘을 사용해 MNist Digit 이미지를 클러스터링한 결과이다. 1234567891011121314151617181920212223242526272829from sklearn.datasets import load_digitsdigits = load_digits()model = KMeans(init=\"k-means++\", n_clusters=10, random_state=0)model.fit(digits.data)y_pred = model.labels_def show_digits(images, labels): f = plt.figure(figsize=(8, 2)) i = 0 while (i &lt; 10 and i &lt; images.shape[0]): ax = f.add_subplot(1, 10, i + 1) ax.imshow(images[i], cmap=plt.cm.bone) ax.grid(False) ax.set_title(labels[i]) ax.xaxis.set_ticks([]) ax.yaxis.set_ticks([]) plt.tight_layout() i += 1 def show_cluster(images, y_pred, cluster_number): images = images[y_pred == cluster_number] y_pred = y_pred[y_pred == cluster_number] show_digits(images, y_pred) for i in range(10): show_cluster(digits.images, y_pred, i) 연습 문제붓꽃 데이터를 K=3인 K-Means 클러스터링하여 adjusted Rand index, adjusted mutual information, 실루엣 계수를 각각 계산하라. 2. DBSCAN 클러스터링K-Means 클러스터링 방법은 단순하고 강력한 방법이지만 클러스터의 모양이 원형이 아닌 경우에는 잘 동작하지 않으며 클러스터의 개수를 사용자가 지정해주어야 한다는 단점이 있다. DBSCAN(Density-Based Spatial Clustering of Applications with Noise) 방법은 데이터가 밀집한 정도를 이용하기 때문에 클러스터의 형태에 구애받지 않으며 클러스터의 개수도 지정해줄 필요가 없다. 이 방법에서는 초기데이터로부터 근접한 데이터를 찾아나가는 방식으로 클러스터를 확장한다. 이 때 사용되는 사용자 인수는 다음과 같다. epsilon $\\epsilon$ : 이웃(neighborhood)을 정의하기 위한 거리(이웃 영역의 반지름) 최소 데이터 개수(minimum points) : 밀집지역을 정의하기 위해 필요한 이웃의 개수 만약 어떤 데이터에서 $\\epsilon$ 거리 반경 안에 있는, 즉 해당 데이터의 이웃 영역 안에 최소 데이터개수(MinPts) 이상의 데이터가 있으면, 그 데이터는 핵심 데이터(core point)이다. 이 핵심 데이터의 이웃 영역 안에 있는 데이터들을 핵심데이터와 연결된 고밀도 데이터(density-reachable points)라고 한다. 고밀도 데이터의 이웃영역 안에 있는 데이터 또한 연결된 고밀도 데이터가 된다. 고밀도 데이터에 더이상 이웃이 없으면, 그 고밀도 데이터는 경계데이터(border data)라고 하며, 연결은 끝난다. 아무 데이터에도 연결되지 않은 데이터를 아웃라이어(outlier) 라고 한다. scikit-learn의 cluster 서브패키지에서 제공하는 DBSCAN 클래스를 이용하면 다음과 같은 인수를 지정해 클러스터링을 할 수 잇다. eps : 이웃을 정의하기 위한 거리 $\\epsilon$ core_sample_indices_ : 핵심 데이터의 인덱스 다음은 make_circles 명령과 make_moons 명령으로 만든 동심원, 초승달 데이터를 DBSCAN 방법으로 클러스터링한 결과를 나타낸 것이다. 마커의 모양은 클러스터를 나타내고, 마커의 크기가 큰 데이터가 핵심데이터, x 표시된 데이터는 아웃라이어다. 3. 계층적 클러스터링계층적 클러스터링(Hierarchical Clustering)은 하나의 데이터샘플을 하나의 클러스터로 보고 가장 유사도가 높은 클러스터끼리 합치면서 클러스터의 개수를 줄여가는 방법이다. 클러스터간 거리 측정클러스터간의 비유사도 혹은 거리를 측정하는 방법에는 다음과 같은 것들이 있다. 비귀납적 방법 centroid single complete average 귀납적 방법 median weighted Ward 비귀납적 방법1) centroid두 클러스터 $u, v$의 중심점(centroid) $c_u, c_v$를 정의한 다음 두 중심점의 거리를 클러스터간 거리로 정의한다. d(u, v) = ||c_u-c_v||^22) single클러스터 $u$ 의 모든 데이터 $i$와 클러스터 $v$ 의 모든 데이터 $j$ 의 모든 조합에 대해 거리를 측정해 그 중 최소값 클러스터간 거리로 정의한다. 최소거리(Nearest Point) 방법이라고도 한다. d(u, v) = \\min(dist(u[i], v[j]))3) complete클러스터 $u$ 의 모든 데이터 $i$와 클러스터 $v$ 의 모든 데이터 $j$ 의 모든 조합에 대해 거리를 측정해 그 평균을 클러스터간 거리로 정의한다. $|u|$ 와 $|v|$ 는 각각 두 클러스터의 원소의 개수를 의미한다. d(u,v) = \\sum_{ij} \\frac{d(u[i],v[j])}{|u||v|}귀납적 방법귀납적 방법에 속하는 아래 방법들은 Agglomerative Clustering에서 사용할 수 있는 방법들이다. 1) mediancentroid 방법의 변형으로, 만약 클러스터 $u$가 클러스터 $s$ 와 $t$ 의 결합으로 생겨난 클러스터라면 $u$ 클러스터의 중심점은 새로 계산하지 않고 원래 두 클러스터의 중심점의 평균으로 사용한다. 2) weighted만약 클러스터 $u$가 클러스터 $s$ 와 $t$ 의 결합으로 생겨난 클러스터라면 $u$ 클러스터와 $v$ 클러스터간의 거리는 $v$에서 원래 두 클러스터까지의 거리의 평균으로 정의한다. d(u, v) = (dist(s,v)+dist(t,v))/23) Ward만약 클러스터 $u$가 클러스터 $s$ 와 $t$ 의 결합으로 생겨난 클러스터라면 $u$ 클러스터와 $v$ 클러스터간의 거리는 $v$ 에서 $s, t$ 각각까지의 거리의 가중평균에서 $s$ 와 $t$ 간 거리를 보정한 값으로 정의한다. d(u,v)\\\\ = \\sqrt{\\frac{|v|+|s|}{|v|+|s|+|t|}d(v,s)^2+\\frac{|v|+|t|}{|v|+|s|+|t|}d(v,t)^2 - \\frac{|v|}{|v|+|s|+|t|}d(s,t)^2}SciPy의 계층적 클러스터링파이썬으로 계층적 클러스터링을 하려면 SciPy 패키지의 linkage 명령을 사용하거나 scikit-learn 패키지의 AgglomerativeClustering 클래스를 사용한다. Scipy패키지는 클러스터링 결과를 tree형태로 시각화해주는 dendogram 명령도 지원한다. MNIST digit 이미지 중 20개를 무작위로 골라 계층적 클러스터링을 적용해보자. 1234567891011121314151617from sklearn.datasets import load_digitsdigits = load_digits()n_image = 20np.random.seed(0)idx = np.random.choice(range(len(digits.images)), n_image)X = digits.data[idx]images = digits.images[idx]plt.figure(figsize=(12, 1))for i in range(n_image): plt.subplot(1, n_image, i + 1) plt.imshow(images[i], cmap=plt.cm.bone) plt.grid(False) plt.xticks(()) plt.yticks(()) plt.title(i) 1234567891011121314151617181920212223242526from scipy.cluster.hierarchy import linkage, dendrogramZ = linkage(X, 'ward') # 귀납적 방법 중 'Ward'를 적용한 계층적 클러스터링 실시from matplotlib.offsetbox import OffsetImage, AnnotationBboxplt.figure(figsize=(10, 4))ax = plt.subplot()ddata = dendrogram(Z)dcoord = np.array(ddata[\"dcoord\"])icoord = np.array(ddata[\"icoord\"])leaves = np.array(ddata[\"leaves\"])idx = np.argsort(dcoord[:, 2])dcoord = dcoord[idx, :]icoord = icoord[idx, :]idx = np.argsort(Z[:, :2].ravel())label_pos = icoord[:, 1:3].ravel()[idx][:20]for i in range(20): imagebox = OffsetImage(images[i], cmap=plt.cm.bone_r, interpolation=\"bilinear\", zoom=3) ab = AnnotationBbox(imagebox, (label_pos[i], 0), box_alignment=(0.5, -0.1), bboxprops=&#123;\"edgecolor\" : \"none\"&#125;) ax.add_artist(ab)plt.show() 4. Affinity Propagation모든 데이터가 특정한 기준에 따라 자신을 대표할 대표 데이터를 선택한다. 만약 스스로가 자기 자신을 대표하게 되면, 그 데이터가 클러스터의 중심이 된다. responsibility $r(i, k)$ $k$번째 데이터가 $i$ 번째 데이터의 대표가 되어야 한다는 근거 availability $a(i, k)$ $i$ 번째 데이터가 $k$ 번째 데이터를 대표로 선택해야 한다는 근거 다음 수식을 $r,a$ 값이 수렴할 때까지 반복 r(i, k) \\leftarrow s(i,k) - \\max_{k'\\neq k}(a(i,k')+ s(i,k')) a(i,k) \\leftarrow \\min(0, r(k,k) + \\sum_{i'\\neq i,k}r(i',k))여기에서 $s(i,k)$ 는 다음과 같이 음의 거리로 정의되는 유사도이다. s(i,k) = -||x_i - x_k||^2특히 $s(k,k)$ 는 특정한 음수값으로 사용자가 지정해주게 되는데, 이 값에 따라 클러스터의 개수가 달라지는 하이퍼 모수가 된다. $s(k,k)$값이 크면 자기 자신에 대한 유사도가 커져서 클러스터 수가 증가한다. 위 알고리즘으로 계산하는 $r, a$ 가 더 이상 변화하지 않고 수렴하면 게산이 종료되고, 종료 시점에서 $r(k,k) + a(k,k) &gt; 0$ 인 데이터가 클러스터의 중심이 된다. 123456789101112131415161718192021222324from sklearn.datasets.samples_generator import make_blobsfrom sklearn.cluster import AffinityPropagationfrom sklearn.metrics import *from itertools import cyclecenters = [[1, 1], [-1, -1], [1, -1]]X, labels_true = make_blobs(n_samples=300, centers=centers, cluster_std=0.5, random_state=0)model = AffinityPropagation(preference=-50).fit(X)cluster_centers_indices = model.cluster_centers_indices_labels = model.labels_n_clusters_ = len(cluster_centers_indices)colors = cycle('rgb')for k, col in zip(range(n_clusters_), colors): class_members = labels == k cluster_center = X[cluster_centers_indices[k]] plt.plot(X[class_members, 0], X[class_members, 1], col + '.') for x in X[class_members]: plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col, alpha=0.25) plt.plot(cluster_center[0], cluster_center[1], 'o', mec='k', mew=3, markersize=7)plt.show()","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"Clustering","slug":"Clustering","date":"2019-01-11T02:06:28.000Z","updated":"2019-01-11T05:31:15.000Z","comments":true,"path":"2019/01/11/Clustering/","link":"","permalink":"https://jyujin39.github.io/2019/01/11/Clustering/","excerpt":"","text":"클러스터링주어진 데이터 집합을 유사한 데이터들의 그룹으로 나누는 것을 클러스터링(clustering)이라고 하고, 이렇게 나누어진 유사한 데이터들의 그룹을 클러스터(cluster)라고 한다. 클러스터링은 분류 문제와 달리 특정한 독립변수와 종속변수의 구분도 없고 학습을 위한 목푯값(target value)도 필요로 하지 않는 비지도학습(unsupervised learning)의 일종이다. 클러스터링 방법대부분의 클러스터링 방법들도 예측모형처럼 특정한 목표함수의 값을 최소화 혹은 최대화하긴 하지만, 예측모형과 달리 명확하게 주어진 목표함수가 없기 때문에, 목표함수의 정의 및 최적화 방법이 각기 다른 다양한 클러스터링 방법이 존재한다. 아래 소개하는 방법들이 많이 사용되는 클러스터링 방법이다. K-means DBSCAN Spectral Clustering Affinity Propagation 계층적 클러스터링(Hierarchial Clustering) 클러스터링 방법마다 사용법과 모수 등이 다르다. 예를 들어 K-means, Spectral Clustering 등은 클러스터의 개수를 미리 지정해주어야 하지만, DBSCAN이나 Affinity, Propagation 등은 클러스터의 개수를 지정할 필요가 없다. 다만 다른 종류의 모수값을 지정해줘야 하는데 이 값에 따라 클러스터의 개수가 달라질 수 있다. 다음은 몇 가지 예제 데이터에 이 클러스터링 방법들을 적용한 결과다. 같은색상의 데이터는 같은 클러스터로 분류된 것이다. 각 방법마다 특성이 다르기 때문에 클러스터링 목적과 데이터의 유형에 적합한 방법을 선택해 사용해야 한다. 또한 지정된 모수값에 따라 성능이 달라질 수 있다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263from sklearn.datasets import *from sklearn.cluster import *from sklearn.preprocessing import StandardScalerfrom sklearn.utils.testing import ignore_warningsnp.random.seed(0)n_samples = 1500blobs = make_blobs(n_samples=n_samples, random_state=8)X, y = make_blobs(n_samples=n_samples, random_state=170)anisotropic = (np.dot(X, [[0.6, -0.6], [-0.4, 0.8]]), y)varied = make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=170)noisy_circles = make_circles(n_samples=n_samples, factor=.5, noise=.05)noisy_moons = make_moons(n_samples=n_samples, noise=.05)no_structure = np.random.rand(n_samples, 2), Nonedatasets = &#123; \"같은 크기의 원형\": blobs, \"같은 크기의 타원형\": anisotropic, \"다른 크기의 원형\": varied, \"초승달\": noisy_moons, \"동심원\": noisy_circles, \"비구조화\": no_structure&#125;plt.figure(figsize=(11, 11))plot_num = 1for i, (data_name, (X, y)) in enumerate(datasets.items()): X = StandardScaler().fit_transform(X) two_means = MiniBatchKMeans(n_clusters=3) dbscan = DBSCAN(eps=0.15) spectral = SpectralClustering(n_clusters=3, affinity=\"nearest_neighbors\") ward = AgglomerativeClustering(n_clusters=3) affinity_propagation = AffinityPropagation(damping=0.9, preference=-200) clustering_algorithms = ( ('K-Means', two_means), ('DBSCAN', dbscan), ('Spectral Clustering', spectral), ('Hierarchical Clustering', ward), ('Affinity Propagation', affinity_propagation), ) for j, (name, algorithm) in enumerate(clustering_algorithms): with ignore_warnings(category=UserWarning): algorithm.fit(X) if hasattr(algorithm, 'labels_'): y_pred = algorithm.labels_.astype(np.int) else: y_pred = algorithm.predict(X) plt.subplot(len(datasets), len(clustering_algorithms), plot_num) if i == 0: plt.title(name) if j == 0: plt.ylabel(data_name) colors = plt.cm.tab10(np.arange(20, dtype=int)) plt.scatter(X[:, 0], X[:, 1], s=5, color=colors[y_pred]) plt.xlim(-2.5, 2.5) plt.ylim(-2.5, 2.5) plt.xticks(()) plt.yticks(()) plot_num += 1plt.tight_layout()plt.show() 클러스터링 성능기준클러스터링의 경우 분류문제에 비해 성능기준을 만들기가 어렵다. 원래 데이터가 어떻게 클러스터링되어있는지를 보여주는 정답(groundtruth)이 있는 경우에도 쉽지 않다. 따라서 아래 제시된 예시를 비롯해 다양한 성능기준들이 사용되고 있다. Adjusted Rand Index Adjusted Mutual Information Silhouette Coefficient 1) Adjusted Rand Index(Adjusted) Rand Index를 구하려면, 데이터가 원래 어떻게 클러스터링되어있는지에 대한 정답이 있어야 한다. $N$ 개의 데이터 집합에서 $i, j$ 두 개의 데이터를 선택했을 때 그 두 데이터가 같은 클러스터에 속하면 1, 다른 데이터에 속하면 0이라고 하자. 이 값들을 $N\\times N$ 행렬 $T$ 로 나타내자. T_{ij} = \\begin{cases} 1 && \\text{i와 j가 같은 클러스터}\\\\0 && \\text{i와 j가 다른 클러스터}\\end{cases}예를 들어 $\\{0,1,2,3,4\\}$라는 5개의 데이터 집합에서 $\\{0,1,2\\}$가 한 클러스터, $\\{3,4\\}$가 한 클러스터라면 정답행렬 $T$ 는 아래와 같은 행렬이 된다. 1234567groundtruth = np.array([ [1, 1, 1, 0, 0], [1, 1, 1, 0, 0], [1, 1, 1, 0, 0], [0, 0, 0, 1, 1], [0, 0, 0, 1, 1],]) 이제 해당 데이터 집합에 대해 클러스터링을 진행한 결과를 행렬 $C$ 라고 하자. 클러스터링이 정확하게 이루어졌다면 $C$ 는 정답행렬 $T$ 와 같은 값을 가져야 한다. 만약 클러스터링 결과 $\\{0,1\\}$ 과 $\\{2, 3, 4\\}$ 로 분류되었다면 $C$ 는 아래와 같은 행렬이 된다. 1234567clusters = np.array([ [1, 1, 0, 0, 0], [1, 1, 0, 0, 0], [0, 0, 1, 1, 1], [0, 0, 1, 1, 1], [0, 0, 1, 1, 1],]) 행렬 $T$ 와 $C$ 를 비교하여, 값이 같은 원소의 자리에는 1, 다른 원소의 자리에는 0으로 표시한 행렬을 incidence matrix 라고 하며 $R$ 로 표시한다. 즉, 정답인 경우 1, 틀린 경우 0이 된다. R_{ij} = \\begin{cases}1 && \\text{if}\\,\\,\\, T_{ij} = C_{ij} \\\\ 0 && \\text{if}\\,\\,\\, T_{ij} \\neq C_{ij}\\end{cases}위 예제에서 incidence matrix를 구하면 다음과 같다. 12incidence = 1 * (groundtruth == clusters)incidence Rand Index 는 이 incidence matrix에서 전체 원소 개수 중에 1의 개수 즉 정답인 쌍의 개수의 비율로, 예측문제의 정확도(accuracy)에 해당한다. 12rand_index = np.sum(incidence) / np.prod(incidence.shape)rand_index Rand Index는 0에서 1사이 값을 가지고, 1일 때 가장 성능이 좋은 것이다. 이 rand index 의 문제점은, 무작위로 클러스터링을 한 경우에도 어느 정도 좋은 값이 나올 가능성이 높다는 점이다. 이를 해결하기 위해 무작위 클러스터링에서 생기는 rand index의 기댓값을 원래의 값에서 빼서 기댓값과 분산을 재조정한 것이 Adjusted Rand index이다. Adjusted rand index는 무작위클러스터링의 경우 0이 나올 확률이 높고, 경우에 따라 음수가 나올 수도 있다. adjusted Rand index를 계산하려면 우선 contingency table을 만들어야 한다. contingencey table은 정답과 클러스터링 결과가 같은 데이터의 개수를 나타낸 것이다. 정답이 $r$ 개의 클러스터를 갖고 클러스터링 결과는 $s$ 개의 클러스터를 가진다고 가정할 때, T = \\{T_1, T_2, \\cdots , T_r\\}\\\\ C = \\{C_1, C_2, \\cdots , C_s\\}contingency table은 아래와 같이 그려진다. \\begin{array}{c|cccc|c} T \\; \\backslash \\; C & C_1& C_2& \\ldots& C_s& \\text{소계} \\\\ \\hline T_1& n_{11}& n_{12}& \\ldots& n_{1s}& a_1 \\\\ T_2& n_{21}& n_{22}& \\ldots& n_{2s}& a_2 \\\\ \\vdots& \\vdots& \\vdots& \\ddots& \\vdots& \\vdots \\\\ T_r& n_{r1}& n_{r2}& \\ldots& n_{rs}& a_r \\\\ \\hline \\text{소계}& b_1& b_2& \\ldots& b_s& \\end{array} $n_{ij}$ : 정답에서는 클러스터 $T_i$ 에 속하고 클러스터링 결과에서는 $C_j$ 에 속하는 데이터의 수 $a_i = \\sum^s_{j=1} n_{ij}$ $b_j = \\sum^r_{i=1}n_{ij}$ 여기서 adjusted Rand index값은 아래와 같이 구할 수 있다. \\text{ARI} = \\frac{ \\overbrace{\\sum_{ij} \\binom{n_{ij}}{2}}^\\text{Index} - \\overbrace{[\\sum_i \\binom{a_i}{2} \\sum_j \\binom{b_j}{2}] / \\binom{n}{2}}^\\text{기댓값} }{ \\underbrace{\\frac{1}{2} [\\sum_i \\binom{a_i}{2} + \\sum_j \\binom{b_j}{2}]}_\\text{최댓값} - \\underbrace{[\\sum_i \\binom{a_i}{2} \\sum_j \\binom{b_j}{2}] / \\binom{n}{2}}_\\text{기댓값} }위에서 예로 들었던 타원형 데이터 예제에 대해 여러가지 클러스터링 방법을 적용하였을때 adjusted Rand index 값을 계산해보면 DBSCAN과 Spectral Clustering의 값이 높게 나오는 것을 확인할 수 있다. scikit-learn 패키지의 metrics.cluster 서브패키지는 adjusted_rand_score 명령을 제공한다. 123456789101112from sklearn.metrics.cluster import adjusted_rand_scoreX, y_true = anisotropicX = StandardScaler().fit_transform(X)for name, algorithm in clustering_algorithms: with ignore_warnings(category=UserWarning): algorithm.fit(X) if hasattr(algorithm, 'labels_'): y_pred = algorithm.labels_.astype(np.int) else: y_pred = algorithm.predict(X) print(\"&#123;:25s&#125;: ARI=&#123;:5.3f&#125;\".format(name, adjusted_rand_score(y_true, y_pred))) 2) Adjusted Mutual Informationmutual information은 두 확률변수간의 상호 의존성을 측정한 값이다. 클러스터링 결과가 이산확률변수라고 가정했을 때, 위 경우에서처럼 정답이 r개의 값을 갖는 이산확률변수이고 클러스터링 결과는 s개의 값을 갖는 이산확률변수라고 하자. T = \\{T_1, T_2, \\cdots , T_r\\}\\\\ C = \\{C_1, C_2, \\cdots , C_s\\}전체 데이터 수를 $N$ 이라고 하면 이산확률변수 $T$ 와 $C$ 의 분포는 아래와 같이 추정할 수 있다. P(i) = \\frac{|T_i|}{N} P'(j) = \\frac{|C_j|}{N}​ - $|T_i|$ : 클러스터 $T_i$ 에 속하는 데이터 수 ​ - $|C_j|$ : 클러스터 $C_j$ 에 속하는 데이터 수 이 때 $T$ 와 $C$ 의 결합확률분포는 다음처럼 추정된다. P(i, j) = \\frac{|T_i\\cap C_j|}{N}​ - $|T_i \\cap C_j|$: 클러스터 $T_i$ 와 $C_j$ 모두에 속하는 데이터의 개수 확률변수 $T, C$ 의 mutual information은 아래와 같이 정의된다. M I(T, C) = \\sum^r_{i=1}\\sum^s_{j=1}P(i,j)\\log\\frac{P(i,j)}{P(i)P'(j)}만약 두 확률변수가 서로 독립이면 mutual information의 값은 0이며, 이 값이 mutual information이 가질 수 있는 최소값이다. 두 확률변수간의 의존성이 강할수록 값이 커진다. 그런데 클러스터의 개수가 많아질수록 값이 증가하므로 올바른 비교가 어렵다. 따라서 각 경우에 따른 mutual information 기대값을 빼서 재조정한 것이 adjusted mutual information 이다. 다음은 위에서 예로 들었던 타원형 데이터 예제에 대해 여러가지 클러스터링 방법을 적용했을 때 adjusted mutual information 값을 계산한 결과이다. scikit-learn 패키지의 metrics.cluster 서브패키지는 adjusted_mutual_info_score 명령을 제공한다. 123456789101112from sklearn.metrics.cluster import adjusted_mutual_info_scoreX, y_true = anisotropicX = StandardScaler().fit_transform(X)for name, algorithm in clustering_algorithms: with ignore_warnings(category=UserWarning): algorithm.fit(X) if hasattr(algorithm, 'labels_'): y_pred = algorithm.labels_.astype(np.int) else: y_pred = algorithm.predict(X) print(\"&#123;:25s&#125;: ARI=&#123;:5.3f&#125;\".format(name, adjusted_mutual_info_score(y_true, y_pred))) 3) 실루엣 계수지금까지는 데이터의 클러스터링에 대한 정답을 알고 있는 경우였다. 하지만 이런 정답정보가 없다면 어떻게 클러스터링 결과를 판단할 수 있을까? 실루엣 계수(Silhouette coefficient) 는 이러한 경우에 클러스터링 성능을 판단하기 위한 기준의 하나이다. 우선 모든 데이터쌍 $(i, j)$ 에 대해 거리(distance) 혹은 비유사도(dissimilarity) 를 구한다. 이 결과를 이용해 모든 데이터 $i$ 에 대해 다음 값을 구한다. $a_i$ : $i $ 와 같은 클러스터에 속한 원소들의 평균 거리 $b_i$ : $i$ 와 다른 클러스터 중 가장 가까운 클러스터까지의 평균 거리 이 때 실루엣 계수는 다음과 같이 정의된다. s = \\frac{b-a}{\\max(a,b)}만약 데이터 $i$ 에 대해 같은 클러스터의 데이터가 다른 클러스터의 데이터보다 가깝다면 실루엣 계수는 양수가 된다. 하지만 만약 다른 클러스터의 데이터가 더 가깝다면 실루엣 계수가 음수가 되는데, 이 때는 클러스터링이 잘못된 경우로 보면 된다. 실루엣 계수가 클수록 좋은 클러스터링이라고 볼 수 있다. 실루엣 계수는 클러스터의 개수를 사용자가 정해주어야 하는 경우 큰 도움이 된다. 앞서 예로 들었던 3개의 원형데이터에 대해 KMean 방법으로 클러스터 개수를 바꿔가면서 클러스터링 결과를 살펴보자. Scikit-learn 패키지의 metrics 서브패키지에 제공되는 silhouette_samples명령을 사용한다. 1234567891011121314151617181920212223242526272829303132333435363738394041from sklearn.metrics import silhouette_samplesX = StandardScaler().fit_transform(blobs[0])colors = plt.cm.tab10(np.arange(20, dtype=int))plt.figure(figsize=(6, 8))for i in range(4): model = KMeans(n_clusters=i + 2, random_state=0) cluster_labels = model.fit_predict(X) sample_silhouette_values = silhouette_samples(X, cluster_labels) silhouette_avg = sample_silhouette_values.mean() plt.subplot(4, 2, 2 * i + 1) y_lower = 10 for j in range(i + 2): jth_cluster_silhouette_values = sample_silhouette_values[cluster_labels == j] jth_cluster_silhouette_values.sort() size_cluster_j = jth_cluster_silhouette_values.shape[0] y_upper = y_lower + size_cluster_j plt.fill_betweenx(np.arange(y_lower, y_upper), 0, jth_cluster_silhouette_values, facecolor=colors[j], edgecolor=colors[j]) plt.text(-0.05, y_lower + 0.5 * size_cluster_j, str(j + 1)) plt.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\") plt.xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1]) plt.yticks([]) plt.title(\"실루엣 계수 평균: &#123;:5.2f&#125;\".format(silhouette_avg)) y_lower = y_upper + 10 plt.subplot(4, 2, 2 * i + 2) plt.scatter(X[:, 0], X[:, 1], s=5, color=colors[cluster_labels]) plt.xlim(-2.5, 2.5) plt.ylim(-2.5, 2.5) plt.xticks(()) plt.yticks(()) plt.title(\"클러스터 수: &#123;&#125;\".format(i + 2))plt.tight_layout()plt.show()","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"Recommender System","slug":"Recommender-System","date":"2019-01-10T09:42:01.000Z","updated":"2019-01-10T09:45:44.000Z","comments":true,"path":"2019/01/10/Recommender-System/","link":"","permalink":"https://jyujin39.github.io/2019/01/10/Recommender-System/","excerpt":"","text":"추천 시스템추천 시스템(recommender system)이란, 누적된 기록 등을 기반으로 사용자(user)가 선호하는 상품(item)을 예측하는 시스템이다. 파이썬의 surprise 패키지는 다양한 추천시스템 알고리즘을 제공한다. 123# 먼저 설치가 필요하다!pip install surpriseimport surprise 평점 데이터surprise 패키지에서는 MovieLense라는 영화 추천 웹사이트의 데이터를 샘플 평점 데이터로 제공한다. MovieLense의 데이터 중 10만개의 샘플데이터셋을 다음과 같이 로드한다. 1data = surprise.Dataset.load_builtin('ml-100k') 이 데이터를 데이터프레임으로 변환하면 다음과 같다. 123df = pd.DataFrame(data.raw_ratings, columns=[&quot;user&quot;, &quot;item&quot;, &quot;rate&quot;, &quot;id&quot;])del df[&quot;id&quot;]df.head(10) user 열은 사용자 아이디, item 열은 상품 아이디, rate 열은 각 행의 사용자가 영화에 대해 준 평점에 해당한다. 여기서 볼 수 있듯이, 추천 시스템은 사용자아이디와 상품아이디라는 두 개의 카테고리 입력과 평점 출력을 가지는 예측 시스템 이다. 위 데이터프레임을 피봇테이블로 만들면 x축이 상품, y축이 사용자인 평점 행렬(rate matrix) $R$ 이 된다. 평점행렬의 일부를 살펴보면 다음과 같이 평점데이터가 일부 위치에만 존재하는 sparse matrix임을 알 수 있다. 12df_table = df.set_index([\"user\", \"item\"]).unstack()df_table.iloc[212:222, 808:817].fillna(\"\") 평점행렬의 빈칸을 흰색, 점수를 검은색으로 시각화하면 다음과 같다. 123456plt.imshow(df_table)plt.grid(False)plt.xlabel(\"item\")plt.ylabel(\"user\")plt.title(\"Rate Matrix\")plt.show() 추천 시스템 알고리즘추천시스템은 두 개의 카테고리값 입력에 대한 하나의 실수 출력값을 예측해내는 회귀모형이지만, 여러가지 방법을 통해 예측성능을 향상시키고 있다. 추천시스템에서 사용되는 알고리즘들은 다음과 같다. 베이스라인 모형 Collaborative Filtering 2-1. Neighborhood Models User-based CF Item-based CF 2-2. Latent Factor Models Matrix Factorization SVD Content-Based Recommendation Content-Based Recommendation 1) 베이스라인 모형1baseline_model = surprise.BaseLineOnly(bsl_options=&#123;&#125;, verbose=True) 베이스라인 모형(baseline model)은 사용자 아이디 $u$, 상품아이디 $i$ 라는 두 카테고리 입력값에서 평점 $r_{ui}$ 의 예측치 $\\hat{r}_{ui}$ 를 예측하는 가장 단순한 회귀분석모형으로 다음과 같이 사용자와 상품 특성에 의한 평균 평점의 합으로 구한다. $\\mu$ 는 전체 평점의 평균, $b_u$ 는 동일한 사용자에 의한 평점 평균값, $b_i$ 는 동일한 상품에 대한 사용자들의 평점 평균값이다. \\hat{y}_{ui} = \\mu + b_u + b_i베이스라인 모형은 오차함수를 최소화하는 것을 목적으로 한다. \\sum_{r_{ui}\\in R_{train}}(r_{ui} - (\\mu + b_u + b_i))^2여기서 $R_{train}$은 트레이닝을 위한 데이터셋을 의미한다. 과최적화를 피하기 위해 다음처럼 정규화(regularization) 항을 추가할 수도 있다. \\sum_{r_{ui}\\in R_{train}}(r_{ui} - (\\mu + b_u + b_i))^2 + \\lambda (b_u^2 + b_i^2)surprise 패키지는 오차함수를 최소화하기 위해 다음과 같은 두 가지 최적화 알고리즘을 제공한다. 알고리즘을 선택할 때는 method 인수를 사용한다. 선택한 알고리즘에 따라 나머지 최적화인수도 설정해야 한다. SGD (Stochastic Gradient Descent)의 인수 reg : 정규화 가중치. 디폴트는 0.02 learning_rate : 최적화 스텝사이즈. 디폴트는 0.005 n_epochs : 최적화 반복 횟수. 디폴트는 20 ALS(Alternating Least Squares)의 인수 reg_i: 상품에 대한 정규화 가중치. 디폴트는 10 reg_u: 사용자에 대한 정규화 가중치. 디폴트는 15 n_epochs: 최적화 반복횟수. 디폴트는 10 모형 사용법베이스라인 모형을 비롯한 surprise 패키지 모형을 사용하기 위해서는 다음 순서를 거친다. 데이터셋의 split, folds 메서드를 사용해 K-Folds 트레이닝셋과 테스트셋을 만든다. 모형알고리즘 객체를 생성한다. 모형 알고리즘 객체의 train메서드와 트레이닝셋으로 모수를 추정한 후, test 메서드로 테스트셋에 대한 예측을 실시한다. accuracy 서브패키지의 성능평가함수를 사용해 예측 성능을 계산한다. 추천성능 평가기준accuracy 서브패키지에서는 다음과 같은 추천성능 평가기준들을 제공한다. 아래 식들에서 $\\hat{R}$ 은 테스트 셋을 의미한다. RMSE(Root Mean Squared Error) \\text{RMSE} = \\sqrt{\\frac{1}{|\\hat{R}|}\\sum_{\\hat{r}_{ui}\\in \\hat{R}}(r_{ui}-\\hat{r}_{ui})^2} MAE(Mean Absolute Error \\text{MAE} = \\frac{1}{\\hat{R}}\\sum_{\\hat{r}_{ui}\\in \\hat{R}}|r_{ui}-\\hat{r}_{ui}| FCP(Fraction of Concordant Pairs) \\text{FCP} = \\frac{\\text{number of concordant pairs}}{\\text{number of discordant pairs}} 회귀분석에서 $i$번째 데이터와 $j$번째 데이터에 대해 실제 데이터 $y_i, y_j$ 와 예측데이터 $\\hat{y_i}, \\hat{y_j}$ 사이의 증가 방향이 같으면 concordant pair라고 한다. \\text{sign}(y_i-y_j) = \\text{sign}(\\hat{y_i}-\\hat{y_j})우선 RMSE 평가기준에 따라 베이스라인 모형의 성능을 평가해보자. 123456789101112131415161718from surprise.model_selection import KFoldbsl_options = &#123; 'method': 'als', # method 인수에서 최적화 알고리즘을 'ALS'로 지정 'n_epochs': 5, 'reg_u': 12, 'reg_i': 5&#125;algo = surprise.BaselineOnly(bsl_options) # 베이스라인 모형 생성np.random.seed(0)acc = np.zeros(3)cv = KFold(3)for i, (trainset, testset) in enumerate(cv.split(data)): algo.fit(trainset) predictions = algo.test(testset) acc[i] = surprise.accuracy.rmse(predictions, verbose=True)acc.mean() # accuracy 서브패키지의 rmse 평가기준 사용 model_selection 서브패키지의 cross_validate 명령을 사용하면 위 코드를 아래처럼 짧게 줄이면서도 다양한 평가기준으로 성능을 평가할 수 있다. 1surprise.model_selection.cross_validate(algo, data) 2) Collaborative FilterCF(Collaborative Filter) 방법은 모든 사용자의 데이터를 균일하게 사용하는 것이 아니라 평점행렬이 가진 특정한 패턴을 찾아서 이를 평점 예측에 사용하는 방법이다. CF 방법으로 만들 수 있는 모형은 다음 두 가지가 있다: Neighborhood 모형 사용자나 상품 기준으로 평점의 유사성을 살핌 Latent Factor 모형 평점행렬의 수치적 특징을 이용 (1) Neighborhood 모형Neighborhood 모형은 Memory-based CF라고도 한다. 특정 사용자의 평점을 바로 예측하는 것이 아니라, 해당 사용자와 유사한 사용자에 대해 가중치를 주어 계산해낸다. 평점행렬에서 유사한 사용자정보, 즉 행벡터의 유사도를 기반으로 빈 데이터를 계산하는 방법을 사용자기반 (User-based) CF 라고 하며, 특정 상품에 대해 사용자가 준 점수, 즉 평점행렬의 열벡터끼리의 유사도에 따라 해당 상품의 빈 데이터를 예측하는 방법을 상품기반(item-based) CF 라고 한다. 유사도 계산사용자 특성벡터 혹은 상품특성벡터의 유사도를 비교하기 위한 기준도 여러가지가 있다. surprise 패키지가 제공하는 유사도 기준은 다음과 같다. 평균제곱차이 유사도 (Mean Squared Difference Similarity) 코사인 유사도 (Cosine Similarity) 피어슨 유사도 (Pearson Similarity) 피어슨-베이스라인 유사도 (Pearson-Baseline Similarity) - 평균제곱차이 유사도 (Mean Squared Difference Similarity)일단 다음과 같이 msd(Mean Squared Difference)를 계산한다. msd는 유클리드거리의 제곱에 비례하는 값이다. 사용자 $u$ 와 $v$ 벡터 간의 msd \\text{msd}(u,v) = \\frac{1}{|I_{uv}|}\\cdot \\sum_{i\\in I_{uv}}(r_{ui}-r_[vi])^2 $I_{uv}$ : 사용자 $u$ 와 $v$ 모두에 의해 평가된 상품의 집합 $|I_{uv}|$ : 사용자 $u$ 와 $v$ 모두에 의해 평가된 상품의 수 상품 $i$ 와 $j$ 벡터 간의 msd \\text{msd}(i,j) = \\frac{1}{|U_{ij}|} \\cdot \\sum_{u\\in U_{ij}}(r_{ui}-r_{ui})^2 $U_{ij}$ : 상품 $i$ 와 $j$ 모두를 평가한 사용자의 집합 |$U_{ij}$| : 상품 $i$ 와 $j$ 모두를 평가한 사용자의 수 유사도는 이렇게 계산된 msd 값과 반비례관계에 있다. 즉 거리가 멀수록 유사도는 떨어진다. msd값이 0이 되는 경우를 대비해 1을 더해준 후 역수를 취해준 값이 유사도가 된다. \\text{msd_sim}(u,v) = \\frac{1}{\\text{msd}(u,v)+1} \\text{msd_sim}(i,j) = \\frac{1}{\\text{msd}(i,j)+1}- 코사인 유사도 (Cosine Similarity)코사인 유사도(Cosine Similarity)는 두 벡터의 각도에 대한 코사인 값을 말한다. 벡터 $x$ 와 $y$ 사이의 각도 $\\theta$ 는 두 벡터의 내적 $x\\cdot y$ 와 다음과 같은 관계가 있다. x\\cdot y = |x| |y| \\cos\\theta \\cos\\theta = \\frac{x\\cdot y}{|x| |y|} 사용자 $u$ 와 $v$ 벡터 간의 msd \\text{cosine_sim} (u,v) = \\dfrac{\\sum\\limits_{i\\in I_{uv}}r_{ui}\\cdot r_{vi}}{\\sqrt{\\sum\\limits_{i\\in I_{uv}}r_{ui}^2}\\cdot \\sqrt{\\sum\\limits_{i\\in I_{uv}}r^2_{vi}}} 상품 $i$ 와 $j$ 벡터 간의 msd \\text{cosine_sim} (i,j) = \\dfrac{\\sum\\limits_{u\\in U_{ij}}r_{ui}\\cdot r_{uj}}{\\sqrt{\\sum\\limits_{u\\in U_{ij}}r_{ui}^2}\\cdot \\sqrt{\\sum\\limits_{u\\in U_{ij}}r^2_{uj}}}- 피어슨 유사도 (Pearson Similarity)피어슨 유사도는 두 벡터의 상관계수(Pearson correlation coefficient)로, 다음과 같이 정의한다. 사용자 $u$ 와 $v$ 벡터 간의 msd \\text{pearson_sim}(u, v) = \\frac{\\sum\\limits_{i\\in I_{uv}}(r_{ui}-\\mu_u)\\cdot (r_{vi}-\\mu_v)}{\\sqrt{\\sum\\limits_{i\\in I_{uv}}(r_{ui}-\\mu_u)^2}\\cdot \\sqrt{\\sum\\limits_{i\\in I_uv}(r_{vi}-\\mu_v)^2}}​ - $\\mu_u$ : 사용자 $u$ 의 평균 평점 상품 $i$ 와 $j$ 벡터 간의 msd \\text{pearson_sim}(i, j) = \\frac{\\sum\\limits_{u\\in U_{ij}}(r_{ui}-\\mu_i)\\cdot (r_{uj}-\\mu_j)}{\\sqrt{\\sum\\limits_{u\\in U_{ij}}(r_{ui}-\\mu_i)^2}\\cdot \\sqrt{\\sum\\limits_{u\\in U_ij}(r_{uj}-\\mu_j)^2}}​ - $\\mu_i$ : 상품 $i$ 의 평균 평점 - 피어슨-베이스라인 유사도 (Pearson-Baseline Similarity)피어슨-베이스라인 유사도는 피어슨유사도와 같이 상관계수를 구하지만, 각 벡터의 기댓값을 단순 평균이 아니라 베이스라인 모형에서 예측한 값으로 사용한다. 사용자 $u$ 와 $v$ 벡터 간의 msd \\text{pearson_baseline_sim}(u,v) = \\hat{\\rho}_{uv} = \\frac{\\sum\\limits_{i\\in I_{uv}}(r_{ui}-b_{ui})\\cdot (r_{vi}-b_{vi})}{\\sqrt{\\sum\\limits_{i\\in I_{uv}}(r_{ui}-b_{ui})^2}\\cdot \\sqrt{\\sum\\limits_{i\\in I_uv}(r_{vi}-b_{vi})^2}} 상품 $i$ 와 $j$ 벡터 간의 msd \\text{pearson_baseline_sim(i,j)} = \\hat{\\rho}_{ij} = \\frac{\\sum\\limits_{u\\in U_{ij}}(r_{ui}-b_{ui})\\cdot (r_{uj}-b_{uj})}{\\sqrt{\\sum\\limits_{u\\in U_{ij}}(r_{ui}-b_{ui})^2}\\cdot \\sqrt{\\sum\\limits_{u\\in U_ij}(r_{uj}-b_{uj})^2}}피어슨-베이스라인 유사도는 벡터의 차원, 즉 두 사용자나 상품에 공통적으로 있는 평점 원소의 개수를 이용해 정규화하는 shrinkage 를 추가해 사용한다. \\text{pearson_baseline_shrunk_sim}(u,v) = \\frac{|I_{uv}|-1}{|I_{uv}|-1+\\text{shrinkage}} \\cdot \\hat{\\rho}_{uv} \\text{pearson_baseline_shrunk_sim}(i,j) = \\frac{|U_{ij}|-1}{|U_{ij}|-1+\\text{shrinkage}} \\cdot \\hat{\\rho}_{ij}surprise 패키지에서 유사도를 설정하는 옵션은 다음과 같다. name : 사용할 유사도의 종류를 나타내는 문자열. 디폴트는 MSD user_based : True 면 사용자기반, False면 상품기반 min_support : 두 사용자나 상품에서 공통적으로 있는 평점원소 개수의 최소값 shrinkage : Shrinkage 가중치. 디폴트는 100 KNN 가중치 예측 방법일단 유사도가 구해지면 평점을 예측하고자 하는 사용자(혹은 상품)와 유사도가 큰 $k$ 개의 사용자(혹은 상품) 벡터를 사용하여 가중평균을 구해 가중치를 예측한다. 이러한 방법을 KNN(K Nearest Neighbors) 기반 예측 방법이라고 한다. surprise 패키지는 다음과 같은 3가지 KNN 기반 가중치 예측 알고리즘 클래스를 제공한다. KNNBasic 평점들을 단순히 가중평균한다. \\hat{r}_{ui} = \\frac{\\sum\\limits_{v \\in N_i^k(u)}\\text{sim}(u,v)\\cdot r_{vi}}{\\sum\\limits_{v\\in N_i^k(u)}\\text{sim}(u,v)}또는 \\hat{r}_{ui} = \\frac{\\sum\\limits_{j \\in N_u^k(i)}\\text{sim}(i,j)\\cdot r_{uj}}{\\sum\\limits_{j\\in N_u^k(j)}\\text{sim}(i,j)} KNNWithMeans 평점들을 평균값을 기준으로 가중평균한다. \\hat{r}_{ui} = \\frac{\\sum\\limits_{v \\in N_i^k(u)}\\text{sim}(u,v)\\cdot (r_{vi}-\\mu_v)}{\\sum\\limits_{v\\in N_i^k(u)}\\text{sim}(u,v)}또는 \\hat{r}_{ui} = \\frac{\\sum\\limits_{j \\in N_u^k(i)}\\text{sim}(i,j)\\cdot (r_{uj}-\\mu_j)}{\\sum\\limits_{j\\in N_u^k(j)}\\text{sim}(i,j)} KNNBaseline 평점들을 베이스라인 모형의 값을 기준으로 가중평균한다. \\hat{r}_{ui} = b_{ui} + \\frac{\\sum\\limits_{v \\in N_i^k(u)}\\text{sim}(u,v)\\cdot (r_{vi}-b_{vi})}{\\sum\\limits_{v\\in N_i^k(u)}\\text{sim}(u,v)}​ 또는 \\hat{r}_{ui} = b_{ui} + \\frac{\\sum\\limits_{j \\in N_u^k(i)}\\text{sim}(i,j)\\cdot (r_{uj}-b_{uj})}{\\sum\\limits_{j\\in N_u^k(j)}\\text{sim}(i,j)}Neighborhood 모형을 사용하여 추천시스템을 만들고 평가하는 코드는 아래와 같다. 123sim_options = &#123;'name': 'msd'&#125; # 평균제곱차이 유사도algo = surprise.KNNBasic(sim_options=sim_options)surprise.model_selection.cross_validate(algo, data) 123sim_options = &#123;'name': 'cosine'&#125; # 코사인 유사도algo = surprise.KNNBasic(sim_options=sim_options)surprise.model_selection.cross_validate(algo, data) 123sim_options = &#123;'name': 'pearson'&#125; # 피어슨 유사도algo = surprise.KNNBasic(sim_options=sim_options)surprise.model_selection.cross_validate(algo, data) 123sim_options = &#123;'name': 'pearson_baseline'&#125; # 피어슨-베이스라인 유사도algo = surprise.KNNBasic(sim_options=sim_options)surprise.model_selection.cross_validate(algo, data) (2) Latent Factor 모형사용자의 특성벡터나 상품의 특성벡터의 길이는 수천에서 수십억에 달하는 크기가 될 수도 있다. Latent Factor 모형은 이렇게 긴 벡터를 몇개의 요인벡터로 간략화(approximate)할 수 있다는 가정에서 출발한다. PCA를 사용하면 긴 특성벡터를 작은 수의 차원으로 축소할 수 있는 것처럼 사용자와 상품의 특성도 차원축소할 수 있다. 영화에 대한 평점을 주는 경우, 영화에는 코미디/액션/드라마 등 다양한 장르가 있고 사용자는 그 중 특정한 장르를 선호할 수 있다. 하나의 영화에도 이러한 장르요소가 복합적으로 존재할 수 있기 때문에 하나의 영화에 대한 한 사용자의 평점은, 사용자의 선호장르요인벡터와 영화 자체의 장르요인벡터의 내적으로 표시할 수 있게 된다. 예를 들어 액션을 싫어하고(-1) 코미디(2)나 드라마(3)를 좋아하는 사용자의 장르 요인 벡터는 다음과 같다. p_u^T = (-1, 2, 3)그리고 어떤 영화가 액션요소 2, 코미디요소 1, 드라마요소 1을 갖고 있다면 해당 영화의 장르 요인벡터를 다음과 같이 나타낼 수 있다. q_i^T = (2,1,1)해당 영화에 대한 위 사용자의 평점은 다음과 같을 것이다. r_{ui} = q_i^Tp_u = -1\\cdot 2 + 2\\cdot 1 + 3\\cdot 1 = 3Matrix FactorizationMatrix Factorization 방법은 모든 사용자와 상품에 대해 다음 오차함수를 최소화하는 요인벡터를 찾아낸다. 즉, 다음과 같은 행렬 $P, Q$ 를 찾는다. R \\approx PQ^T여기서 $R \\in \\R^{m\\times n}$ : $m$ 사용자와 $n$ 상품의 평점 행렬 $P \\in \\R^{m\\times k}$ : $m$ 사용자와 $k$ 요인의 관계 행렬 $Q \\in \\R^{n\\times k}$ : $n$ 상품의와 $k$ 요인의 관계 행렬 SVD (Singular Value Decomposition)SVD (Singular Value Decomposition)는 Matrix Factorization 문제를 푸는 방법 중 하나이다. $m \\times n$ 크기의 행렬 $R$ 은 다음과 같이 세 행렬의 곱으로 나타낼 수 있다. 이를 특이치 분해(Singular Value Decomposition) 라고 한다. R = U\\Sigma V^T이 식에서 $U $ : $m\\times m$ 행렬. 역행렬이 대칭행렬 $\\Sigma$ : $m\\times n$ 행렬. 비대각 성분이 0 $V$ : $n\\times n$ 행렬. 역행렬이 대칭행렬 $\\Sigma$ 의 대각 성분을 특이치라고 하며, 전체 특이치 중에서 가장 값이 큰 $k$개의 특이치만을 사용해 다음과 같이 행렬 $\\hat{U}, \\hat{\\Sigma}, \\hat{V}$ 를 만들 수 있다. $\\hat{U}$ : $U$ 에서 가장 값이 큰 $k$개의 특이치에 대응하는 $k$개의 성분만을 남긴 $m\\times k$ 크기의 행렬 $\\hat{\\Sigma}$ : $\\Sigma$ 에서 가장 값이 큰 $k$ 개의 특이치에 대응하는 $k$ 개의 성분만을 남긴 $k\\times k$ 크기의 행렬 $\\hat{V}$ : $V$ 에서 가장 값이 큰 $k$ 개의 특이치에 대응하는 $k$ 개의 성분만을 남긴 $k \\times n$ 크기의 행렬 이 행렬들을 다시 조합하면 원래 행렬과 같은 크기를 가지고 유사한 원소를 가지는 행렬을 만들 수 있다. \\hat{U}\\hat{\\Sigma}\\hat{V}^T = \\hat{R} \\approx R하지만 실제로 평점행렬은 빈 원소가 많은 sparse 행렬이기 때문에 SVD 를 바로 적용하기 어렵다. 따라서 행렬 $P, Q$ 는 다음과 같은 모형에 대해 오차함수를 최소화하여 구한다. \\hat{r}_{ui} = \\mu + b_u + b_i + q_i^T p_u \\sum_{r_{ui}\\in R_{train}}(r_{ui}-\\hat{r}_{ui})^2 + \\lambda (b_i^2+b_u^2 + ||q_i||^2 + ||p_u||^2)123%%timealgo = surprise.SVD(n_factors=20)print(surprise.model_selection.cross_validate(algo, data))","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"Hyper Parameter Tuning","slug":"Hyper-Parameter-Tuning","date":"2019-01-08T08:12:40.000Z","updated":"2019-01-11T05:30:54.000Z","comments":true,"path":"2019/01/08/Hyper-Parameter-Tuning/","link":"","permalink":"https://jyujin39.github.io/2019/01/08/Hyper-Parameter-Tuning/","excerpt":"","text":"모형 최적화머신러닝 예측 모형을 완성한 후에는 최적화 과정을 통해 성능을 향상시킨다. 이 과정을 하이퍼 파라미터 튜닝(hyper parameter tuning)이라고 한다. scikit-learn패키지에서 제공하는 하이퍼파라미터 튜닝 도구들은 다음과 같다. validation curve 단일 하이퍼 파라미터 최적화 GridSearchCV 그리드를 사용한 복수 하이퍼 파라미터 최적화 ParameterGrid 복수 파라미터 최적화용 그리드 validadtion_curvevalidation_curve 함수는 최적화할 파라미터의 이름과 범위, 성능평가기준을 param_name,param_range,scoring 인수로 받아, 지정해준 범위의 모든 경우에 대해 설정한 성능평가기준에 따라 성능을 계산한다. 12345678from sklearn.datasets import load_digitsfrom sklearn.svm import SVCfrom sklearn.model_selection import validation_curvedigits = load_digits()X, y = digits.data, digits.targetparam_range = np.logspace(-6, -1, 10) 123train_scores, test_scores = validation_curve(SVC(), X, y, param_name=\"gamma\", param_range=param_range, cv=10, scoring=\"accuracy\", n_jobs=1) 설정한 범위 내에서 감마값이 커질수록 오버피팅이 돼서 trainingscore가 올라간다. 그러나 감마가 일정 값 이상으로 커지게 되면 아래 그래프에서 볼 수 있듯이 trainingscore가 더이상 올라가지 않고 머무른다. cross-validation 점수는 어느 순간 아예 감소하는 현상을 보인다. GridSearchCVGridSearchCV 클래스는 파라미터, 성능평가기준 등을 지정해준 객체를 만들어 사용한다. 생성한 클래스 객체에 fit 메서드를 호출하면 grid search를 사용하여 자동으로 모형들을 만들고 실행해 최적 파라미터를 찾아준다. 모형들과 실행결과는 다음 속성에 저장된다. grid_scores_ param_grid로 설정해준 모든 파라미터 조합에 대한 성능 결과. best_score_ 설정한 성능평가기준의 최고 점수 best_params_ 최고 점수를 낸 파라미터 조합 best_estimator_ 최고점수를 낸 파라미터를 가진 모형 12345678910111213141516from sklearn.model_selection import GridSearchCVfrom sklearn.pipeline import Pipelinefrom sklearn.preprocessing import StandardScalerfrom sklearn.svm import SVCpipe_svc = Pipeline([('scl', StandardScaler()), ('clf', SVC(random_state=1))]) #pipeline 안에도 scl, clf의 두 파라미터가 있다param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0] # 8개param_grid = [ &#123;'clf__C': param_range, 'clf__kernel': ['linear']&#125;, &#123;'clf__C': param_range, 'clf__gamma': param_range, 'clf__kernel': ['rbf']&#125;] # 파라미터를 이런식으로 집어넣어준다. linear일 때 8개, rbf일 때 8개 총 64회 + 8gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=1) #총 72회 * 10번gs = gs.fit(X, y) 최고 점수와 최적 파라미터 값을 출력하면 위와 같지만, 이 값들을 너무 믿으면 안 된다. 과최적화되었을 수도 있기 때문에 직접 플롯을 그려서 피팅이 잘 됐는지 확인해봐야 한다. ParameterGridParameterGrid는 GridSearchCV 에서 param_grid 라는 인수로 사용되었던 것이다. 그리드서치 방법을 사용할 수 없을 때 직접 그리드를 생성하는 iterator역할을 한다. 123from sklearn.model_selection import ParameterGridparam_grid = [&#123;'kernel': ['linear']&#125;, &#123;'kernel': ['rbf'], 'gamma': [1, 10]&#125;]list(ParameterGrid(param_grid)) 병렬처리 / 분산처리1) 병렬처리병렬처리는 어떤 명령을 수행할 때 프로세스를 단일로 사용하지 않고 여러 개 사용해서 처리 속도를 빠르게 하는 것이다. scikit-learn에서는 분산처리는 지원하지 않지만 병렬처리는 지원한다. 이 병렬처리를 수행할지 여부를 결정하는 인수가 GridSearchCV 의 n_jobs 라는 인수다. 디폴트 값은 1이고, 최대로는 내가 사용하는 CPU코어의 수만큼 늘려주면 그리드서치 속도가 빨라진다. 2) 분산처리분산처리는 병렬처리를 여러 동일한 환경들에 분산해서 계산량이 많은 것들을 처리하는 방법이다. 분산처리를 해주는 도구들이 따로 있는데, aws나 구글클라우드 등 서버를 통해 할 수 있다..","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"Kernel SVM","slug":"Kernel-SVM","date":"2019-01-01T09:39:39.000Z","updated":"2019-01-01T09:44:14.000Z","comments":true,"path":"2019/01/01/Kernel-SVM/","link":"","permalink":"https://jyujin39.github.io/2019/01/01/Kernel-SVM/","excerpt":"","text":"커널 서포트 벡터 머신XORXOR(exclusive OR) 문제는 이진수에서의 or 연산이라고 생각하면 된다. 다음과 같이 하나만 1일 때 1이 되고, 나머지 경우는 0이 된다. x2=0 x2=1 X1=0 0 1 x1=1 1 0 이러한 경우 다음 그림처럼 클래스가 구분되는데, 퍼셉트론이나 SVM과 같은 선형판별함수 분류모형으로는 이 문제를 풀 수 없다. 이 문제를 SVM으로 풀게되면 아래처럼 선형 경계선이 그어져, 성능이 50정도밖에 나오지 않는다. 따라서 곡선을 사용해 경계를 판별해야 한다. 이러한 경우 사용할 수 있는 방법은 𝐷 차원 독립 변수 벡터 𝑥 대신 기저함수(basis function)으로 변환한 𝑀 차원 벡터 𝜙(𝑥)를 독립 변수 벡터로 사용하는 방법이다. 기저함수를 사용한 비선형 판별 모형 \\phi (\\cdot) : R^D \\to R^M x = (x_1,x_2,\\cdots , x_D) \\,\\,\\,\\,\\,\\to\\,\\,\\,\\,\\,\\phi(x) = (\\phi_1(x),\\phi_2(x),\\cdots , \\phi_M(x))기저함수 $\\phi $ 는 D차원 벡터인 독립변수를 입력받아 함수식에 따라 계산하여 M개의 스칼라를 출력해 M차원 벡터를 만든다. 앞의 XOR 문제를 풀기 위해 다음과 같이 상호곱(cross-multiplication) 항을 추가한 기저함수를 사용해보자. (x_1, x_2) \\,\\,\\,\\,\\,\\to \\,\\,\\,\\,\\,\\phi(x) = (x_1^2, \\sqrt2 x_1x_2,x_2^2)FunctionTransformer 전처리 클래스를 이용하면 기저함수를 이용한 변환을 할 수 있다. 위 기저함수로 변환한 데이터는 다음과 같은 분포를 갖게 되고, $\\phi _2$ 가 0보다 큰지 작은지를 기준으로 클래스를 분류할 수 있게 된다. 12345678X_xor2 = FunctionTransformer(basis).fit_transform(X_xor)plt.scatter(X_xor2[y_xor == 1, 0], X_xor2[y_xor == 1, 1], c=\"b\", marker='o', s=50)plt.scatter(X_xor2[y_xor == 0, 0], X_xor2[y_xor == 0, 1], c=\"r\", marker='s', s=50)plt.ylim(-6, 6)plt.title(\"변환 공간에서의 데이터 분포\")plt.xlabel(r\"$\\phi_1$\")plt.ylabel(r\"$\\phi_2$\")plt.show() FunctionTransformer 와 SVC 클래스를 합쳐 $\\phi$와 $x$ 사이의 비선형관계를 원래의 독립변수공간으로 다시 돌려놓으면 아래와 같이 휘어진 곡선으로 클래스가 분리된다. 123456from sklearn.pipeline import Pipelinebasismodel = Pipeline([(\"basis\", FunctionTransformer(basis)), (\"svc\", SVC(kernel=\"linear\"))]).fit(X_xor, y_xor)plot_xor(X_xor, y_xor, basismodel, \"기저함수 SVC 모형을 사용한 XOR 분류 결과\")plt.show() 결국 이러한 문제에서는 적절한 기저함수 $\\phi$ 를 찾아내는 것이 관건이다. 위처럼 제곱, 루트, 곱하기 등 다양한 연산을 해보다 보면 어떻게든 찾을 수 있다. 그런데 이 때는 아래와 같은 문제들이 발생한다. 기저함수를 너무 많이 만들어봐야 해서 계산이 많아진다. 그 중 단 한 개도 제대로 된 기저함수가 안 나올 수도 있다. 그래서 나온 것이 커널이라는 개념이다. 커널 트릭SVM모델의 목적함수와 예측모형은 다음과 같은 dual form으로 표현할 수 있었다. L = \\sum^N_{m=1}a_n-\\frac{1}{2}\\sum^N_{n=1}\\sum^N_{m=1}a_na_my_ny_mx_n^Tx_m y = w^Tx - w_0 = \\sum^N_{n-1}a_ny_nx_n^Tx-w_0여기서 기저함수를 사용하면 svm 모형을 푸는 것은 아래 수식을 푸는 문제가 된다. L = \\sum^N_{m=1}a_n-\\frac{1}{2}\\sum^N_{n=1}\\sum^N_{m=1}a_na_my_ny_m\\phi(x_n)^T\\phi(x_m) y = w^Tx - w_0 = \\sum^N_{n-1}a_ny_n\\phi(x_n)^T\\phi(x)-w_0즉 모든 기저함수는 두 개의 변환된 독립변수벡터를 내적한 $\\phi(x_i)^T \\phi(x_j)$의 형태로만 사용되며 독립적으로 사용되지 않는다. 따라서 이 값을 하나의 스칼라 함수로 나타낼 수 있다.(입력변수는 벡터) k(x_i,x_j) = \\phi(x_i)^T\\phi(x_j)이 함수를 커널(kernel)함수라고 한다. 대응하는 기저함수가 존재할 수만 있다면 기저함수를 먼저 정의하고 커널을 정의하는 것이 아니라 커널을 먼저 정의해도 상관 없다. 커널의 의미위 수식을 커널함수로 바꿔 표현하면 다음과 같다. L = \\sum^N_{m=1}a_n-\\frac{1}{2}\\sum^N_{n=1}\\sum^N_{m=1}a_na_my_ny_mk(x_n,x_m) y = w^Tx - w_0 = \\sum^N_{n-1}a_ny_nk(x_n,x)-w_0두 벡터를 내적하는 것은 두 벡터 사이의 유사도를 측정하는 것과 같으므로 커널함수는 두 표본데이터 간의 유사도를 측정하는 기준으로 볼 수도 있다. 커널 사용의 장점커널을 사용하면 기저함수를 하나하나 생각해내는 수고를 덜 수 있고, 변환과 내적에 들어가는 계산도 줄어든다. 예를 들어, \\phi(x_i) = \\phi([x_{i,1},x_{i,2}])= (x_{i,1}^2, \\sqrt{2}x_{i,1}x_{i,2},x_{i,2}^2)총 11번의 곱셈을 필요로 하는 위 기저함수는 다음과 같은 커널함수로 대체 가능하다. \\begin{eqnarray} k(x_1,x_2) &=& (x_1^Tx_2)^2\\\\ &=& (x_{1,1}x_{2,1} + x_{1,2}x_{2,2})^2\\\\ &=& x^2_{1,1}x^2_{2,1} + 2x_{1,1}x_{2,1}x_{1,2}x_{2,2} + x^2_{1,2}y^2_{2,2}\\\\ &-& (x_{1,1}^2,\\sqrt{2}x_{1,1}x_{1,2},x_{1,2}^2)(x_{2,1}^2,\\sqrt{2}x_{2,1}x_{2,2},x_{2,2}^2)^T\\\\ &=& \\phi(x_1)^T\\phi(x_2) \\end{eqnarray}여기서는 같은 계산을 하는 데 3번의 곱셈이면 된다. 커널의 확장생성다음 규칙을 통해 두 개의 커널함수 $k_1(x_1,x_2), k_2(x_1,x_2)$로부터 새로운 커널을 쉽게 만들어내 사용할 수 있다. 커널함수를 양수인 상수배한 함수는 커널함수다. (단위를 바꾸는 것에 지나지 않기 때문이다.) k(x_1,x_2) = ck_1(x_1,x_2) \\,\\,\\,(c>0) 커널함수에 양수인 상수를 더한 함수는 커널함수다.(기준점이 달라질 뿐 같은 함수다.) k(x_1,x_2) = k_1(x_1,x_2) + c \\,\\,\\,\\,(c>0) 두 커널함수를 더한 함수는 커널함수다. k(x_1,x_2) = k_1(x_1,x_2) + k_2(x_1,x_2) 두 커널함수를 곱한 함수는 커널함수다. (하나의 커널함수를 몇제곱해도 커널함수다.) k(x_1,x_2) k_1(x_1,x_2)k_2(x_1,x_2) k(x_1,x_2) k_1(x_1,x_2)k_2(x_1,x_2) 단조증가(monotonically increasing)하는 $\\exp$, $\\text{sigmoid}$ 등의 함수에 집어넣은 커널함수도 커널함수다. k(x_1,x_2) = (k_1(x_1,x_2))^n\\,\\,\\,(n=1,2,\\cdots)\\\\ k(x_1,x_2) = \\exp(k_1(x_1,x_2))\\\\ k(x_1,x_2) = \\text{sigmoid}(k_1(x_1,x_2)) x1, x2 각각의 커널함수 값의 곱도 커널함수다. k(x_1,x_2) = k_1(x_1,x_1)k_2(x_2,x_2)위 규칙에 따르면 무한히 많은 커널함수를 생성해낼 수 있다. 많이 사용되는 커널아래 소개하는 커널은 scikit learn에 구현되어있는 커널함수들로, 대부분의 비선형성을 처리할 수 있다. 기본 커널함수 형태에 해당하는 선형 서포트벡터머신에 위 규칙들을 적용해보면 아래 커널들이 다 생성될 수 있음을 알 수 있다. 선형 서포트벡터머신 k(x_1, x_2) = x_1^T x_2 다항 커널 k(x_1,x_2) = (\\gamma(x_1^T x-2)+\\theta)^d RBF(Radial Basis Kernel) 또는 가우시안 커널(Gaussian Kernel) k(x_1,x_2) = \\exp(-\\gamma||x_1-x_2||^2) 시그모이드 커널(Sigmoid Kernel) k(x_1, x_2) = \\tanh(\\gamma(x_1^Tx_2)+\\theta) 1) 다항 커널위에서 소개한 다항 커널(Polynomial Kernel)은 벡터의 내적으로 정의된 커널을 1번, 2번, 4번 규칙을 통해 확장하여 만들 수 있는 커널이다. k(x_1,x_2) = (\\gamma(x_1^Tx_2)+\\theta)^d간단한 예로 $\\gamma = 1, \\theta = 1, d = 3$ 이고 $x$ 가 스칼라인 경우, \\begin{eqnarray} k(x_1,x_2) &=& (x^T_1x_2+1)^4\\\\ &=& x_1^4x_2^4 + 4x_1^3x_2^3 + 6x_1^2x_2^2 + 4x_1x_2 + 1\\\\ &=& (x_1^4,2x_1^3,\\sqrt6 x_1,2x_1,1)^T(x_2^4,2x_2^3,\\sqrt6 x_2,2x_2,1) \\end{eqnarray}와 같이 기저함수의 내적으로 표현되는 4차 다항커널이 된다. 여기서 기저함수는 다음 5개가 된다. \\begin{eqnarray} \\phi_1(x) &=& x^4\\\\ \\phi_2(x) &=& 2x^3\\\\ \\phi_3(x) &=& \\sqrt6 x^2\\\\ \\phi_4(x) &=& 2x\\\\ \\phi_5(x) &=& 1 \\end{eqnarray}이 커널과 기저함수들을 그래프로 나타내면 아래와 같다. 2) RBF 커널가우시안 커널이라고도 불리는 RBF 커널은 차수가 무한대인 다항커널과 같다. 간단하게 하기 위해 $\\gamma = \\frac{1}{2}$ 로 놓았을 때 다음과 같은 RBF 커널이 나온다. \\begin{eqnarray} k(x_1,x_2) &=& \\exp\\left(-\\dfrac{||x_1-x_2||^2}{2}\\right)\\\\ &=&\\exp\\left(-\\frac{x_1^Tx_1}{2} - \\frac{x_2^Tx_2}{2} + 2x_1^Tx_2\\right)\\\\ &=&\\exp\\left(-\\frac{x_1^Tx_1}{2}\\right)\\exp\\left(-\\frac{x_2^Tx_2}{2}\\right)\\exp(x_1^Tx_2)\\\\ &=&C\\exp(x_1^Tx_2)\\\\ &\\approx& C\\left(1 + (x_1^Tx_2) + \\frac{1}{2!}(x_1^Tx_2)^2 + \\frac{1}{3!}(x_1^Tx_2)^3 + \\cdots\\right) \\end{eqnarray}이 RBF 커널함수를 그래프로 보면 다음과 같다. 1234567891011121314151617181920212223242526x1 = 0.0x2 = np.linspace(-7, 7, 100)def rbf(x1, x2, gamma): return np.exp(-gamma * np.abs(x2 - x1) ** 2)plt.figure(figsize=(8, 4))plt.subplot(121)plt.plot(x2, rbf(x1, x2, 1), ls=&quot;-&quot;, label=&quot;gamma = 1&quot;)plt.plot(x2, rbf(x1, x2, 0.5), ls=&quot;:&quot;, label=&quot;gamma = 0.5&quot;)plt.plot(x2, rbf(x1, x2, 5), ls=&quot;--&quot;, label=&quot;gamma = 5&quot;)plt.xlabel(&quot;x2 - x1&quot;)plt.xlim(-3, 7)plt.legend(loc=1)plt.title(&quot;RBF 커널&quot;)plt.subplot(122)plt.plot(x2, rbf(-4, x2, 1))plt.plot(x2, rbf(-2, x2, 1))plt.plot(x2, rbf(0, x2, 1))plt.plot(x2, rbf(2, x2, 1))plt.plot(x2, rbf(4, x2, 1))plt.xlabel(&quot;x2&quot;)plt.title(&quot;RBF 커널의 기저함수들&quot;)plt.show() scikit-learn의 커널 SVMscikit-learn의 SVM 클래스에서는 kernel 인수를 지정하여 커널을 설정할 수 있다. kernel = &#39;linear&#39; : 선형 SVM 커널 kernel = &#39;poly&#39; : 다항 커널 gamma : $\\gamma$ coef0 : $\\theta$ degree : $d$ kernel = &#39;rbf&#39; : RBF 커널(디폴트값이 rbf라서 써주지 않아도 된다.) kernel = &#39;sigmoid&#39; : 시그모이드 커널 12345678910111213polysvc = SVC(kernel=\"poly\", degree=2, gamma=1, coef0=0).fit(X_xor, y_xor)rbfsvc = SVC(kernel=\"rbf\").fit(X_xor, y_xor)sigmoidsvc = SVC(kernel=\"sigmoid\", gamma=2, coef0=2).fit(X_xor, y_xor)plt.figure(figsize=(8, 12))plt.subplot(311)plot_xor(X_xor, y_xor, polysvc, \"다항커널 SVC를 사용한 분류 결과\")plt.subplot(312)plot_xor(X_xor, y_xor, rbfsvc, \"RBF커널 SVC를 사용한 분류 결과\")plt.subplot(313)plot_xor(X_xor, y_xor, sigmoidsvc, \"시그모이드커널 SVC를 사용한 분류 결과\")plt.tight_layout()plt.show() 커널 파라미터의 영향$\\gamma$ 값이 작으면 $x_2$와 $x_1$의 유사도에 따라 커널함수의 기울기와 값이 많이 달라진다. $\\gamma$ 값이 크면 $x_2$와 $x_1$이 멀리 떨어져있든 가까이 있든 커널함수 값이 별로 차이 나지 않는다. svm은 서포트벡터라는 대표값과의 유사도를 측정하여 가까이 있는 애들을 기준으로 클래스를 판별하는 거였다. 커널 svm에서는 그 유사도의 계산기준이 커널이기 때문에 감마값이 작으면 새로운 데이터와 기존 애들과의 유사도를 측정할 때 넓은 영역 안에서 유사도가 있다고 판단하지만, 감마값이 커지면 서포트벡터(기존의 빨간 점들)와의 유사도가 진짜 가깝지 않으면 없다고 판단하므로 오버피팅이 된다. 위에서 $\\gamma$가 2인 것은 정규화된 것이고 100인 것은 오버피팅된 것이다.","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"SVM(support vector machine)","slug":"SVM-support-vector-machine","date":"2018-12-20T07:37:09.000Z","updated":"2019-01-12T04:31:05.000Z","comments":true,"path":"2018/12/20/SVM-support-vector-machine/","link":"","permalink":"https://jyujin39.github.io/2018/12/20/SVM-support-vector-machine/","excerpt":"","text":"서포트 벡터 머신퍼셉트론에서는 영역을 구분하는 판별경계선(decision hyperplane)이 한 문제에도 다양하게 존재할 수 있었다. 서포트 벡터머신(SVM: Support Vector machine)은 퍼셉트론 기반 모형에 가장 안정적인 하나의 판별 경계선을 찾기 위한 제한조건을 추가한 모형이다. 서포트: 판별경계선을 하나로 정해줄 수 있는 근거가 되는 벡터: 데이터 음의 서포트 벡터(o)와 양의 서포트 벡터(x) 사이의 거리 : 마진 서포트와 마진다음과 같이 N개의 학습용 데이터가 있을 때, (x_1,y_1),(x_2,y_2),\\cdots,(x_i,y_i),\\cdots,(x_N,y_N)판별함수모형에서 $y$ 는 +1 혹은 -1 의 값을 갖는다. y = \\begin{cases} +1\\\\-1 \\end{cases}판별함수모형에서 판별함수를 정의하기 전에 다음 수식들을 복습삼아 짚고 넘어가자. $w^Tx - w_0 = 0$ : 벡터 w에 수직인 x의 직선방정식 $\\dfrac{|w^Tx - w_0|}{||w||}$ : 점과 직선의 거리 이제 판별함수 모형에서 직선인 판별함수 $f(x)$ 는 다음과 같은 수식으로 나타낼 수 있다. f(x) = w^Tx - w_0데이터 중에서 $y$값이 +1인 데이터를 $x_+$, $y$값이 -1인 데이터를 $x_-$라고 하면, 판별함수 정의에 따라 $x_+$에 대한 판별함수 값은 양수가 되고, $x_-$에 대한 판별함수 값은 음수가 된다. f(x^+) = w^Tx^+ - w_0> 0\\\\ f(x^-) = w^Tx^- - w_0","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"perceptron","slug":"perceptron","date":"2018-12-19T14:06:02.000Z","updated":"2018-12-19T14:09:57.000Z","comments":true,"path":"2018/12/19/perceptron/","link":"","permalink":"https://jyujin39.github.io/2018/12/19/perceptron/","excerpt":"","text":"퍼셉트론퍼셉트론(perceptron)은 가장 오래되고 단순한 형태의 판별함수 기반 이진분류모형이다. 퍼셉트론은 입력값 $x=(1,x_1,\\cdots ,x_m)$ 에 대해 1 또는 -1의 값을 가지는 $y$를 출력하는 비선형 함수이다. 1을 포함하는 입력요소 $x_i$ 에 대해 가중치 $w_i$ 를 곱한 값 $a = w^Tx$ 을 활성화값(activations)이라고 하며 이 $a$가 판별함수 역할을 한다. 판별함수 값이 활성화함수(activation function) $h(a)$를 지나면 분류 결과에 해당하는 $\\hat{y}$ 가 생성된다. \\hat{y} = h(w^Tx)퍼셉트론의 활성화함수는 단위 계단함수(heaviside step function)이다. h(a) = \\begin{cases} -1, & a","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"model combining - 2. Boosting","slug":"model-combining-2-Boosting","date":"2018-12-18T13:45:53.000Z","updated":"2018-12-18T13:48:45.000Z","comments":true,"path":"2018/12/18/model-combining-2-Boosting/","link":"","permalink":"https://jyujin39.github.io/2018/12/18/model-combining-2-Boosting/","excerpt":"","text":"2. 부스팅 boosting부스트(boost) 방법은 처음부터 여러 개의 모형을 합쳐 문제를 푸는 취합(aggregation)과 달리 하나의 모형에서 시작해 하나씩 모형을 추가해나간다. 이 때 모형들의 집합을 위원회(commitee) $C$ 라고 하고, m개의 모형을 갖는 위원회를 $C_m$ 으로 표시한다. 위원회에 포함된 개별모형은 weak classifier라고 부르며 $k$ 로 표시한다. C_1 = {k_1}\\\\ C_2 = C1 \\cup k_2 = \\{k_1,k_2\\}\\\\ \\vdots\\\\ C_m = C_{m-1} \\cup k_m = \\{k_1,k_2,\\cdots ,k_m\\}m번째로 위원회에 추가되는 개별모형 $k_m$ 의 목표는 이전단계의 위원회 $C_{m-1}$ 이 잘 못 푼 문제를 풀어내는 것이다. 위원회의 최종 결정은 다수결 방법을 사용하지 않고 각각의 개별모형의 출력을 가중치 $\\alpha$ 로 가중선형조합한 값을 판별함수로 사용한다. 새로운 모형이 추가될 때 해당 모형의 가중치가 결정된다. 이진분류에만 쓸 수 있으며, y 값은 1 혹은 -1이다. y = -1 \\,\\,\\,\\text{or}\\,\\,\\, 1 C_m(x_i) = \\text{sign}(\\alpha_1k_1(x_i) + \\cdots + \\alpha_mk_m(x_i))1) 에이다부스트에이다부스트(adaboost)는 적응부스트(adaptive + boost)에서 나온 이름이다. 에이다부스트에서는 위원회에 추가할 개별모형 $k_m$ 을 선별하는 방법으로, 학습데이터 집합의 i번째 데이터에 가중치 $w_i$ 를 주고 분류모형이 틀리게 예측한 데이터의 가중치를 합한 값을 손실함수 L로 사용한다. 이 손실함수값을 최소화하는 모형을 $k_m$ 으로 선택한다. 쉽게 설명하면, 1부터 N까지의 트레이닝 데이터에 대해 새로운 개별모형 $k_m$이 분류를 해서 1 혹은 -1의 답을 낸다. 그 답이 정답이라면 0점, 오답이라면 1점을 부여한다. 즉, 틀리면 벌점 1점을 받는 벌점제도와 같다. 각 데이터에 대해 얻어진 이 벌점의 가중합을 최소화하는 모델을 찾아내는 것이다. L_m = \\sum_{i=1}^N w_{m,i}I(k_m(x_i)\\neq y_i)위 손실함수 $L_m$에서 $I$ 가 벌점에 해당한다. 즉 0 혹은 1값을 갖는 지시함수 역할을 한다. 그리고 $w_{m,i}$ 은 모델마다, 또 데이터마다 주어지는 가중치로, 특정 로직에 의해 이미 결정된 수치이다. 따라서 손실함수 $L$은 예측이 틀렸을 경우에만 해당 데이터에 주어진 가중치에 1이 곱해져 더하는, 즉 틀린 문제에 대한 가중치의 합이 된다. 이렇게 손실함수값을 최소화하는 개별모형 $k_m$ 이 선택된 후에는 개별 모형의 출력값에 대한 가중치 $\\alpha_m$ 을 결정해야 한다. 이 값을 계산하려면 먼저 다음 식이 필요하다. \\epsilon_m = \\dfrac{\\Sigma^N_{i=1} w_{m,i}I(k_m(x_i)\\neq y_i)}{\\Sigma^N_{i=1}w_{m,i}}$\\epsilon _m$ 은 벌점을 0-1사이로 정규화한 점수이다. 분모는 모든 데이터 예측을 다 틀렸을 때 계산된 벌점, 분자는 실제 틀린 문제에 대한 벌점을 의미한다. 데이터에 대한 가중치 $w_{m,i}$는 맨 처음 위원회에 모델이 1개일 경우 모든 데이터에 대해 같은 값을 갖지만, 위원회 멤버가 증가하면서 값이 바뀐다. 가중치 값은 지수함수를 사용해 맞춘 문제는 작게, 틀린 문제는 크게 확대(boosting)된다. 즉, 그 전에 적용한 모형이 정답을 맞추지 못한 데이터는 가중치가 커지고 맞춘 데이터들의 가중치는 작아져서 다음 추가된 모형은 가중치가 커진 데이터에 중점을 두고 분류를 하게 된다. w_{m,i} = w_{m-1,i}\\exp(-y_iC_{m-1}) = \\begin{cases}w_{m-1,i}e^{-1} && \\text{if}\\,\\, C_{m-1} = y_i\\\\ w_{m-1,i}e && \\text{if} \\,\\, C_{m-1} \\neq y_i \\end{cases}결국 에이다부스팅은 아래와 같이 전체 모형집단에 대한 손실함수를 최소화하는 모형집단을 찾아나가는 과정이라고 볼 수 있다. L_m = \\sum^N_{i=1} \\exp(-y_iC_m(x_i))이에 따라 유도된 가중치 $\\alpha_m$ 의 공식은 다음과 같다. \\alpha_m = \\frac{1}{2}\\log\\left(\\frac{1-\\epsilon_m}{\\epsilon_m}\\right)다음은 scikit-learn의 ensemble 서브패키지가 제공하는 AdaBoostClassifier 클래스를 사용하여 분류 예측을 하는 예이다. 약분류기로는 깊이가 1인 단순한 의사결정나무를 채택하였다. 각 단계의 분류 모형에 대한 가중치 값과 분류 모형의 분류 결과를 시각화하면 다음과 같다. 데이터의 가중치는 스캐터플롯의 점의 크기로 표현하였다. 단계가 진행될 수록 가중치값의 변화가 커지는 것을 볼 수 있다. 2) 그레디언트 부스트그레디언트 부스트(gradient boost) 모형은 변분법(calculus of variations)을 사용한 모형이다. 손실 범함수(loss functional) $ L(y, C_{m-1})$를 최소화하는 개별 분류모형 $k_m$ 을 찾는다. 이론적으로 가장 최적의 $k_m$은 범함수의 미분이다. C_m = C_{m-1} - \\alpha_m \\dfrac{\\delta L(y,C_{m-1})}{\\delta C_{m-1}} = C_{m-1} + \\alpha_m k_m결국 그레디언트 부스트는 범함수를 최적화하는 과정이다. 앞에서는 기존의 데이터에서 가중치만 바꿔서 최적의 $k_m$ 을 선택했다면 여기서는 범함수의 그레디언트와 가장 비슷한 $k_m$ 을 찾는다. 그레디언트 부스트모형에서는 다음과 같은 과정을 반복해 개별모형과 그 가중치를 계산한다. $-\\frac{\\delta L(y,C_m)}{\\delta C_m}$ 을 목표값으로 개별 멤버 모형 $k_m$ 을 찾는다. $\\left(y - (C_{m-1} + \\alpha_m k_m)\\right)^2$ 를 최소화하는 스텝사이즈 $\\alpha_m$ 을 찾는다. $C_m = C_{m-1} + \\alpha_m k_m$ 최종 모형을 갱신한다. 만약 손실범함수가 오차제곱형태라면 , L(y, C_{m-1}) = \\frac{1}{2}(y-C_{m-1})^2범함수의 미분은 실제 목푯값 y와 $C_{m-1}$ 과의 차이, 즉 잔차(residual)가 된다. -\\frac{dL(y,C_m)}{dC_m} = y - C_{m-1}이 값과 가장 비슷한 다음 모델을 찾는 것이 그레디언트부스팅 방법이 된다. scikit learn의 ensemble 에서는 그레이디언트부스팅방법을 위해 GradientBoostingClassifier 를 제공하지만, 그보다 그레디언트 부스팅만을 전문으로 구현해놓은 라이브러리들을 사용하는 것이 더 좋다. XGBoost 라이브러리 :scikit learn에 비해 빠르다. Light GBM (gradient boosting machine) 라이브러리 : xgboost보다 더 빨라서 많이 쓰인다. 그래디언트 부스팅모델에 들어가게 되는 인수는 함수이므로 decision tree classifier가 아니라 decision tree regressor이다. 따라서 개별 모형들은 0 또는 1의 클래스가 아니라 각각 다른 높이를 지닌 계단식 함수값을 출력한다. 그걸 다 합쳤을 때 최종결과에서 바이너리 클래스로 분류하게 되는 것이다. XGBoost 라이브러리 1234import xgboostmodel_xgb = xgboost.XGBClassifier(n_estimators=100, max_depth=1, random_state=0)model_xgb.fit(X_train, y_train) LightGBM 라이브러리 1234import lightgbmmodel_lgbm = lightgbm.LGBMClassifier(n_estimators=100, max_depth=1, random_state=0)model_lgbm.fit(X, y)","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"model combining - 1. aggregation","slug":"model-combining-1-aggregation","date":"2018-12-17T08:58:36.000Z","updated":"2018-12-17T09:13:26.000Z","comments":true,"path":"2018/12/17/model-combining-1-aggregation/","link":"","permalink":"https://jyujin39.github.io/2018/12/17/model-combining-1-aggregation/","excerpt":"","text":"모형 결합모형 결합(model combining) 방법은 앙상블 방법론(ensemble methods)라고도 한다. 단일모형으로 예측이 잘 되지 않을 때, 복수의 모형을 결합해 예측성능을 높이고자 할 때 사용한다. 장점 개별 모형의 성능이 안좋을 때는 결합모형을 하게 되면 성능이 향상된다. 단일모형으로 할 때보다 과최적화를 방지할 수 있다. 모형 결합 방법은 크게 취합(aggregation) 방법론과 부스팅(boosting) 방법론으로 나눌 수 있다. 취합(aggregation) 처음부터 여러 모델로 한 문제를 푼다. 부스팅(boosting) 한 모델이 문제를 풀다가 잘 못하면 그 다음 다른모형을 투입한다. 그 두 모형이 풀다가 잘 못푸는 문제가 생기면 한 모델을 또 추가한다. 모형마다 하는 역할이 다르다. 각 방법론의 대표적인 방법들은 아래와 같다. 취합 방법론 다수결 (Majority Voting) 배깅 (Bagging) 랜덤 포레스트 (Random Forests) 부스팅 방법론 에이다부스트 (AdaBoost) 그레디언트 부스트 (Gradient Boost) 1. 취합 aggregation1) 다수결 방법: 가장 단순한 모형결합 방법으로, 전혀 다른 모형끼리도 결합할 수 있다. 5가지 모형이 있으면 그 5개의 모형들로 하나의 분류문제를 다 풀어본다. scikitlearn의 ensemble 서브패키지는 다수결 방법을 위해 VotingClassifier 클래스를 제공하는데, 이를 이용해 모형들을 합치면 이 세 모형이 마치 하나의 모델인것처럼 사용할 수 있게 된다. 이렇게 모델을 취합하는 방법은 두 가지로 나뉜다. hard voting: 모형들의 가중치가 모두 동일한 단순투표. 개별모형의 결과를 단순히 취합. soft voting: 모형마다 가중치를 다르게 주는 가중치 투표. 개별모형의 조건부 확률값을 취합. 두 방식으로 각각 했을때 분류 결과가 달라진다. 예를 들어 로지스틱 회귀모형, QDA 모형, 가우시안 나이브 베이즈 모형, 이 세 가지 모형으로 하나의 이진분류 문제를 다수결방법으로 푼다고 하자. 이 때 가우시안 나이브 베이즈모형에만 다른 모형들에 비해 가중치를 두 배로 주고 예측을 진행하면, 각각의 모형에서 예측한 클래스와 소프트 보팅으로 다수결방법을 했을 때 예측된 클래스는 다음과 같다. 소프트 다수결 모형은 각 모형마다의 가중치를 고려해 확률값의 합으로 클래스를 결정하기 때문에 세 모델의 조건부확률값의 합이 더 큰 클래스 2로 예측한다. 그러나 만약 하드 다수결모형을 사용했다면 1개의 모델(QDA)에서만 선택된 클래스 2가 아닌, 나머지 2개의 모델에서 예측된 클래스 1을 답으로 예측해내게 된다. 모형 결합을 사용한 성능 향상다수결 모형의 핵심가정 : 개별 모델들은 상호간에 영향을 받지 않고 독립적으로 문제를 예측한다. 위 가정을 따르면 N개의 모델이 모여 정답을 출력할 확률은 아래와 같아진다. \\sum^N_{k>\\frac{N}{2}}\\binom N k p^k (1-p)^{N-k}아래 그래프를 보면, 개별모형의 성능이 정답률 60프로일 때, 그런 모형이 10개가 모이면 성능이 80프로, 100개가 모이면 거의 99프로까지도 올라가는 것을 확인할 수 있다. 다만, 개별모형의 성능이 50프로가 안되면 모형결합을 했을 때 오히려 더 성능이 나빠지는 것도 확인된다. 즉, 다수결모형을 만들 때는 최소한 정확도가 50은 넘는 개별모형들로 모아야 한다. 그런데 우리가 지금까지 배운 모형의 종류가 5개 정도밖에 안 되는데 어떻게 10개, 100개의 모형을 모을 수 있을까? 2) 배깅배깅(bagging)은 동일한 확률모형을 쓰지만 모형마다 데이터를 다르게 줌으로써 서로 다른 결과를 출력하는 다수의 모형을 만들어 다수결모형을 적용하는 방법이다. 부트스트래핑이나 크로스 밸리데이션에서처럼 트레이닝데이터를 랜덤하게 선택해서 각각의 모형에 주면 모형마다 다른 결과가 나오게 된다. 이런 식으로 다른 결과를 출력하는 모델들을 많이 만들어내는 것이다. 배깅은 트레이닝데이터를 선택하는 방식에 따라 다음과 같이 부르기도 한다. 같은 데이터 샘플을 중복사용(replacement)하지 않으면: Pasting 같은 데이터 샘플을 중복사용하면: Bagging 데이터가 아니라 다차원 독립변수 중 일부 차원을 선택하는 경우는: Random Subspaces 데이터 샘플과 독립변수 차원 모두 일부만 랜덤하게 사용하면: Random Patches 배깅 방법은 회귀분석, 분류 등 어떤 문제도 풀어낸다는 장점이 있지만, 계산량이 많다는 단점이 있다. Scikit-Learn 의 ensemble 서브패키지는 배깅 모형 결합을 위한 BaggingClassifier 클래스를 제공한다. 아래는 모형 한 개를 사용했을 때와 배깅모형을 사용했을 때의 분류 결과를 시각화한 것이다. depth=5로 설정한 개별모형 빨간 영역 안에 끼어들어간 녹색 아웃라이어 데이터를 분류하기 위해 그 위치에 해당하는 부분만 영역이 나누어졌다. 하지만 이것은 분명한 오버피팅이다. 그 영역에 새로운 데이터가 들어온다면 빨간색일 가능성이 높은데 녹색으로 분류되어버리기 때문이다. 배깅 모형(10개의 개별모형을 합침) 배깅모형을 사용한 경우에는 오버피팅이 이루어지지 않은 것을 확인할 수 있다. 이유가 뭘까? 배깅방법은 모델들에 데이터를 분배하기 때문에 각 모델에는 데이터의 일부만 들어가게 된다. 따라서 대부분의 모델에는 아웃라이어인 데이터가 안들어갔을 확률이 높다. 즉, 여러 모델 중 아웃라이어에 대해 오버피팅을 하지 않은 모델이 더 많게 된다. 이러한 모델들로 다수결을 하게 되면 오버피팅 발생 확률이 낮아진다. 자동으로 정규화가 되는 것이다. 3) 랜덤 포레스트의사결정나무 여러 개를 개별모형으로 사용해서 포레스트라는 이름이 붙여진 랜덤포레스트(Random Forest)는 정말 많이 사용되는 다수결방법이다. 배깅과 마찬가지로 랜덤포레스트 방법에서는 트리 여러 개에 데이터들을 분배해서 준다. 각 트리에서 하위 노드로 내려갈 때는, 부모노드에서썼던 그 변수를 그대로 선택하는 게 아니라 전체 데이터에서 다시 한 번 서브스페이싱(subspacing)을 해서 랜덤하게 변수를 선택해 사용한다. 노드마다마다 이렇게 랜덤하게 데이터 서브스페이싱을 새로 한다. 이렇게 하면 개별모델들의 독립성이 증가해 모형성능의 변동이 감소하는 효과가 있다. 원래 개별 의사결정나무는 greedy한 선택, 즉 위에서 내려올 때 항상 그순간에 가장 좋은 변수를 사용한다. 그런데 랜덤포레스트는 제약조건을 줘서 non-greedy한 변수선택을 한다. 랜덤포레스트의 극단적 형태인 Extremely Randomized Trees 모형은 맨 처음 변수를 분배할 때부터 어디부터 어디까지 특정 범위로 주는게 아니라 각 노드마다 아예 하나의 변수를 랜덤하게 준다. 랜덤 포레스트의 장점 중 하나는 각 독립변수의 중요도(Feature Importance)를 계산할 수 있다는 점이다. feature importance 랜덤하게 선택된 변수들의 IG, 즉 아래 노드로 내려가면서 엔트로피가 얼마나 감소하는지를 비교해보면 각 변수의 중요도를 계산할 수 있다. 의사결정나무의 경우 선택되는 변수들이 정해져 있기 때문에 선택 기회조차 얻지 못하는 변수들에 대해서는 IG를 계산하기가 힘들다. 그런데 랜덤포레스트의 경우 변수가 랜덤으로 선택되기 때문에 좀더 공정하게 변수들의 중요도를 파악할 수 있다.","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"decision_tree","slug":"decision-tree","date":"2018-12-13T11:17:27.000Z","updated":"2018-12-13T11:23:44.000Z","comments":true,"path":"2018/12/13/decision-tree/","link":"","permalink":"https://jyujin39.github.io/2018/12/13/decision-tree/","excerpt":"","text":"의사 결정 나무의사결정나무(decision tree)는 여러 가지 규칙을 순차적으로 적용하면서 독립변수 공간을 분할하는 분류 모형이다. 판별적 확률모형이긴 하지만 분류해야 하는 class가 multi든 binary든, 혹은 문제 자체가 classification이든 regression이든 모두 적용할 수 있는 만능 모형이다. 분류와 회귀분석 모두에 사용될 수 있다는 점에서 CART(Classification And Regression Tree)라고도 한다. 의사 결정 나무를 이용한 분류의사결정나무를 이용해 분류를 할 때는 다음과 같은 방식을 따른다. 여러가지 독립변수 중 하나의 독립변수를 선택하고, 그 독립변수에 대한 기준값을 정한다. 이를 분류 규칙이라고 하고, 최적의 분류 규칙을 찾는 방법은 추후 설명한다. 전체 학습데이터 집합(부모노드)을 선택한 독립변수 값이 기준값보다 작은 데이터와 큰 데이터의 두 그룹(자식노드 1, 2)으로 나눈다. 각각의 자식노드에 대해 또 새롭게 독립변수와 기준값을 선택해 1~2의 단계를 반복하여 하위 자식노드를 만들어나간다. 자식노드에 한 가지 클래스의 데이터만 남게 된다면 그 노드는 거기서 중단한다. 그런데 현실적으로 한 클래스의 데이터 수가 0이 아니더라도 두 클래스 데이터 비율이 10:1 정도라면 계산의 편의를 위해 그정도에서 멈출 수 있다. 또한 학습용 데이터가 너무 작아서 마지막노드의 클래스의 비율이 2:1 과 같이 너무 작게 나오면 신뢰도가 떨어지기 때문에 그 전에 중단해준다. 이렇게 자식노드 나누기를 계속하다보면 노드가 계속 뻗어나가는 나무와 같은 형태로 표현된다. 이 나무가 의사결정 나무가 된다. 의사결정 나무에 전체 트레이닝 데이터를 모두 적용해 보면 각 데이터는 갈라지는 두 노드 중 하나의 노드로 계속해서 흘러내려가게 된다. 그렇게 해서 각 노드는 특정 데이터 집합을 갖게 되는데, 각 노드에 속한 데이터들의 클래스 비율을 해당 노드의 조건부 확률분포 $P(Y=k\\mid X)_{\\text{node}}$ 라고 정의한다. P(Y = k|X)_{node} \\approx \\frac{N_{\\text{node},k}}{N_{\\text{node}}}이 의사결정나무를 이용해 테스트 데이터의 클래스를 예측할 때는 가장 상위의 노드에 데이터를 집어넣어 나무의 노드를 따라 흘러내려가게 만들고 맨 마지막에 도달하는 노드의 조건부 확률분포를 이용해 클래스를 예측한다. 그렇다면 첫 번째 단계에서 분류규칙을 정하는 기준은 무엇일까? 이 때 조건부 엔트로피 개념이 사용되는데, 모든 독립변수와 가능한 기준값들에 대해 부모노드와 자식노드 간의 엔트로피를 계산한 후 어떤 조합에서 가장 엔트로피가 낮아지는지를 본다. 즉, 자식노드의 엔트로피가 부모노드의 엔트로피에 비해 얼마나 낮아졌는가가 기준이 된다. 이러한 기준을 정량화한 것을 정보획득량(information gain)이라고 한다. 정보 획득량정보 획득량(information gain)이란, $X$ 라는 조건에 의해 확률변수 $Y$의 엔트로피가 얼마나 감소했는지를 타나내는 값이다. $Y$의 엔트로피에서$ X$에 대한 $Y$의 조건부엔트로피를 뺀 값으로 정의된다. IG값이 큰 조건, 즉 분류규칙을 선택한다. IG[Y,X] = H[Y] - H[Y|X]H[Y] : 부모노드의 엔트로피 H[Y|X] : 두 자식노드의 조건부 엔트로피의 평균값 . 낮으면 낮을수록 좋다 예를 들어 하나의 데이터셋에 A, B 두 가지의 다른 분류 규칙을 적용하여 다음처럼 서로 다른 의사결정나무가 만들어졌다고 가정하자. A와 B의 부모노드에 들어간 데이터는 같지만, 자식노드에서는 데이터가 다르게 나뉘어 들어갔다. A의 왼쪽 자식노드 - Y=0인 데이터가 30개, Y=1인 데이터가 10개 A의 오른쪽 자식노드 - Y=0인 데이터가 10개, Y=1인 데이터가 30개 B의 왼쪽 자식노드 - Y=0인 데이터가 20개, Y=1인 데이터가 40개 B의 오른쪽 자식노드 - Y=0인 데이터가 20개, Y=1인 데이터가 0개 우선 A와 B의 공통된 부모 노드의 엔트로피를 계산하면 다음과 같다. H[Y] = -\\frac{1}{2}\\log_2\\left(\\frac{1}{2}\\right) - \\frac{1}{2}\\log_2\\left(\\frac{1}{2}\\right) = \\frac{1}{2}+\\frac{1}{2}=1그런 후 A와 B 각각의 IG를 계산해본다. ​ 1) A의 정보획득량 H[Y\\mid X=X_1] = -\\frac{3}{4}\\log_2\\left(\\frac{3}{4}\\right) -\\frac{1}{4}\\log_2\\left(\\frac{1}{4}\\right) = 0.81 \\\\ H[Y\\mid X=X_2] = -\\frac{1}{4}\\log_2\\left(\\frac{1}{4}\\right) -\\frac{3}{4}\\log_2\\left(\\frac{3}{4}\\right) = 0.81 \\\\ H[Y\\mid X]= \\frac{1}{2}H[Y\\mid X=X_1] + \\frac{1}{2}H[Y\\mid X=X_2] = 0.81 IG = H[Y] - H[Y\\mid X] = 0.19​ 2) B의 정보획득량 H[Y\\mid X=X_1] = -\\frac{1}{3}\\log_2\\left(\\frac{1}{3}\\right) -\\frac{2}{3}\\log_2\\left(\\frac{2}{3}\\right) = 0.92 \\\\ H[Y\\mid X=X_2] = 0 H[Y\\mid X]= \\frac{3}{4}H[Y\\mid X=X_1] + \\frac{1}{4}H[Y\\mid X=X_2] = 0.69 IG = H[Y] - H[Y\\mid X] = 0.31따라서 B가 더 나은 분류규칙임을 알 수 있다. 처음에 독립변수와 임계점을 선정하는 방법은 다음과 같다. 독립변수들 중 맨 첫 번째 변수를 우선 선택하고, 임계점은 처음 두 데이터의 해당 독립변수에 대한 값들의 중간값으로 설정해 IG값을 계산한다. 그 후 두번째와 세번째 데이터의 중간값으로 임계점을 재설정하고 IG값을 또 계산한다. 이 과정을 데이터 끝까지 반복해나가고, 모든 독립변수에 대해 전 과정을 또 반복한다. 여기서 끝이 아니라, 그렇게 해서 나눠진 자식노드에서 위 과정을 반복해나간다. 사실 현실적으로는 위처럼 전 데이터에 대해 하지는 않고 임계점을 특정 기준에 따라 선택해서 일부만 계산한다. 일단은 그냥 위와 같은 방식으로 일일히 IG값을 비교해 분류규칙을 선택한다고 생각하면 된다. Scikit-Learn의 의사 결정 나무 클래스scikit-learn이 제공하는 DecisionTreeClassifier 클래스로 붓꽃 분류 문제를 풀어보도록 하자. 여기서는 편의상 꽃의 길이와 폭만을 독립변수로 사용한다. 123456789from sklearn.datasets import load_irisiris = load_iris()X = iris.data[:, [2, 3]]y = iris.targetfrom sklearn.tree import DecisionTreeClassifiertree1 = DecisionTreeClassifier(criterion='entropy', max_depth=1, random_state=0).fit(X, y) #max_depth는 의사결정나무의 높이, 즉 자식노드를 몇 단계까지 만들 것인지를 의미한다. 다음은 의사결정나무를 시각화하기 위한 코드이다. draw_decision_tree 함수는 의사결정나무가 의사결정을 하는 과정을 다이어그램으로 보여주고, plot_decision_regions 함수는 이러한 의사결정에 의해 데이터의 영역이 어떻게 나눠졌는지를 보여준다. 12345678910111213141516171819202122232425262728293031323334353637383940414243import ioimport pydotfrom IPython.core.display import Imagefrom sklearn.tree import export_graphvizdef draw_decision_tree(model): dot_buf = io.StringIO() export_graphviz(model, out_file=dot_buf, feature_names=iris.feature_names[2:]) graph = pydot.graph_from_dot_data(dot_buf.getvalue())[0] image = graph.create_png() return Image(image)def plot_decision_regions(X, y, model, title): resolution = 0.01 markers = ('s', '^', 'o') colors = ('red', 'blue', 'lightgreen') cmap = mpl.colors.ListedColormap(colors) x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1 x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1 xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution)) Z = model.predict( np.array([xx1.ravel(), xx2.ravel()]).T).reshape(xx1.shape) plt.contour(xx1, xx2, Z, cmap=mpl.colors.ListedColormap(['k'])) plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap) plt.xlim(xx1.min(), xx1.max()) plt.ylim(xx2.min(), xx2.max()) for idx, cl in enumerate(np.unique(y)): plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=0.8, c=[cmap(idx)], marker=markers[idx], s=80, label=cl) plt.xlabel(iris.feature_names[2]) plt.ylabel(iris.feature_names[3]) plt.legend(loc='upper left') plt.title(title) return Z 1draw_decision_tree(tree1) 생성된 의사결정나무를 보면 독립변수로는 Petal width가 선택되었고, 임계점으로는 0.8이 설정되었다. 이 때 부모노드의 IG값을 구하면 다음과 같다. H[Y] = 1.585\\\\ H[Y|X]= \\frac{1}{3} \\times 0 + \\frac{2}{3} \\times 1 = 0.667\\\\ IG = 1.585 - 0.667 = 0.918이 의사결정나무에 의해 나눠진 데이터의 영역을 확인해본다. 12plot_decision_regions(X, y, tree1, \"Depth 1\")plt.show() 클래스 1과 2의 영역이 나눠지지 않았으므로 의사결정나무의 max_depth인수를 2로 설정해 데이터 분류를 한 번 더 실시한다. 123tree2 = DecisionTreeClassifier( criterion='entropy', max_depth=2, random_state=0).fit(X, y)draw_decision_tree(tree2) 이번에도 petalwidth가 독립변수로 선택됐는데 기준값은 1.75로 바뀌었다. 맨 아래 단계의 왼쪽 자식노드에는 클래스2인 데이터가 훨씬 많고 오른쪽 자식노드에는 클래스3인 데이터가 훨씬 많게 나누어졌므로 이 정도면 꽤 분류가 잘 될 수 있는 모델이다. 12plot_decision_regions(X, y, tree2, \"Depth 2\")plt.show() 여기서 한단계 더 해주면, 맨 아래 자식노드드에 엔트로피가 커진 것들이 있긴 하지만 데이터수가 각각 6, 3으로 매우 작고, 그 외 자식노드들은 데이터가 많고 엔트로피가 확 낮아졌기 때문에 결과적으로 평균 엔트로피는 낮아진다. 123tree3 = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)draw_decision_tree(tree3) 12plot_decision_regions(X, y, tree3, \"Depth 3\")plt.show() 위 단계에서 맨 오른쪽 노드를 보면 클래스 2에 해당하는 초록색 구간도 4.85를 기준으로 각각 2개와 43개의 데이터로 나눠졌는데 그래프에서 나타나지 않는다. 왜 그럴까? 어차피 나눠진 두 자식노드에서 모두 3번째 클래스인 데이터가 더 많게 나왔으므로 사실 마지막 그 단계는 큰 의미가 없는 작업이라서 경계가 표시되지 않는다. 그 위 노드에서 1:45로 나눠졌을 때 멈췄어도 된다. 여기서 두 단계를 더 해주면 마지막에는 아래와 같이 나눠진다. 123tree5 = DecisionTreeClassifier( criterion='entropy', max_depth=5, random_state=0).fit(X, y)draw_decision_tree(tree5) 12plot_decision_regions(X, y, tree5, \"Depth 5\")plt.show() 이 결과에 대해 confusion matrix를 보면 아래와 같다. 1confusion_matrix(y, tree5.predict(X)) 회귀 나무예측값 $\\hat{y}$ 을 다음처럼 각 영역마다 고정된 값을 사용하고, 특징을 구분하는 기준값으로 IG값이 아닌 오차 제곱합을 사용하면 회귀분석에서도 의사결정나무를 쓸 수 있다. 이러한 모형을 회귀 나무(regression tree) 라고 한다. \\hat{y} = \\begin{cases} y_1 & \\;\\; \\text{if} x \\geq x_{\\text{threshold}}\\\\ y_2 & \\;\\; \\text{if} x < x_{\\text{threshold}} \\end{cases}12345678910111213141516171819202122from sklearn.tree import DecisionTreeRegressorrng = np.random.RandomState(1)X = np.sort(5 * rng.rand(80, 1), axis=0)y = np.sin(X).ravel()y[::5] += 3 * (0.5 - rng.rand(16))regtree = DecisionTreeRegressor(max_depth=3)regtree.fit(X, y)X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]y_hat = regtree.predict(X_test)# Plot the resultsplt.figure()plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"데이터\")plt.plot(X_test, y_hat, color=\"cornflowerblue\", linewidth=2, label=\"예측\")plt.xlabel(\"x\")plt.ylabel(r\"$y$ &amp; $\\hat&#123;y&#125;$\")plt.title(\"회귀 나무\")plt.legend()plt.show()","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"entropy","slug":"entropy","date":"2018-12-11T15:00:00.000Z","updated":"2018-12-12T11:53:23.000Z","comments":true,"path":"2018/12/12/entropy/","link":"","permalink":"https://jyujin39.github.io/2018/12/12/entropy/","excerpt":"","text":"엔트로피엔트로피란?$Y=0$ 또는 $Y=1$ 인 두 가지 값을 갖는 확률분포가 다음처럼 세 종류 있다고 하자. 확률 분포 $Y_1$ : $P(Y=0) = 0.5, P(Y=1) = 0.5$ 확률 분포 $Y_2$ : $P(Y=0) = 0.8, P(Y=1) = 0.2$ 확률 분포 $Y_3$ : $P(Y=0) = 1.0, P(Y=1) = 0$ 이 확률값이 베이지안 확률 베이지안 확률과 빈도주의적 확률. 베이지안 관점에서의 확률은 데이터로부터 얻은 법칙이나 규칙을 표현하기 위한 수단이고, 빈도주의적 관점에서의 확률은 데이터 자체의 값이 어떤 특성을 갖는지를 표현하기 위한 수단이다. &#8617; 이라면, 확률분포 $Y_1$ 은 $y$ 값에 대해 아무것도 모르는 상태(확률이 반반이므로), $Y_2$ 는 $y$ 값이 0이 아니라고 믿지만 확신할 수는 없는 상태, $Y_3$ 은 $y$ 값이 0이라고 100% 확신하는 상태일 것이다. 이렇게 확률분포들이 가지는 확신의 정도를 수치로 나타낸 것을 엔트로피(entropy) 라고 한다. 확률변수에서 나올 수 있는 값들의 확률이 비슷비슷한 경우 엔트로피가 높아지고, 특정 값이 나올 확률이 높다면 엔트로피가 작아진다. 물리학에서는 상태가 분산되어 있는 정도를 엔트로피로 정의한다. 여러가지로 고루 분산되어 있을 수 있으면 엔트로피가 높고 특정한 하나의 상태로 몰려있으면 엔트로피가 낮다. 확률분포의 엔트로피는 물리학의 엔트로피 용어를 빌려온 것이다. 엔트로피는 수학적으로 다음과 같이 정의한다. 확률변수 Y가 이산 확률변수이면, H[Y] = -\\sum_{k=1}^K P(y_k)\\log_2 P(y_k) 확률변수 Y가 연속 확률변수이면, H[Y] = -\\int^\\infin_{-\\infin}p(y)\\log_2p(y)\\,\\,dy이 식에서 $p(y)$ 는 확률밀도함수다. 위에서 예를 든 $Y_1, Y_2, Y_3$ 에 대해 엔트로피를 구하면 다음과 같다. H[Y_1] = -\\dfrac{1}{2}\\log_2\\dfrac{1}{2} -\\dfrac{1}{2}\\log_2\\dfrac{1}{2} = 1\\\\ H[Y_2] = -\\dfrac{8}{10}\\log_2\\dfrac{8}{10} -\\dfrac{2}{10}\\log_2\\dfrac{2}{10} = 0.72\\\\ H[Y_3] = -1\\log_2 1 -0\\log_2 0 = 0\\\\엔트로피의 성질확률변수가 결정론적 결정론적 데이터. 예측할 수 없는 값이 나오는 확률적 데이터가 아닌, 항상 같은 값이 나오는 데이터를 결정론적 데이터라고 한다. &#8617; 이면 확률분포에서 특정한 하나의 값이 나올 확률이 1이다. 이 때 엔트로피는 0이 되고, 이 값은 엔트로피가 가질 수 있는 최소값이다. 반대로 엔트로피의 최대값은 이산 확률변수의 클래스 개수에 따라 달라진다. 만약 이산확률변수가 갖는 클래스가 $2^K$ 개라면, 엔트로피의 최대값은 각 클래스가 모두 같은 확률을 갖는 때이다. 이 때 엔트로피의 값은 H = -\\frac{2^K}{2^K}\\log_2\\frac{1}{2^K} = K엔트로피와 정보량엔트로피는 확률변수가 담을 수 있는 정보의 양을 의미한다고 볼 수도 있다. 확률변수가 담을 수 있는 정보량이란, 확률변수의 표본값을 관측해서 얻을 수 있는 추가적인 정보의 종류를 말한다. 엔트로피가 0이면 확률변수는 결정론적이므로 확률변수의 표본값은 항상 같다. 따라서 확률변수의 표본값을 관측한다고 해도 우리가 얻을 수 있는 추가 정보는 없다. 반대로 엔트로피가 크다면 확률변수의 표본값이 가질 수 있는 경우의 수가 증가하므로 표본값을 실제로 관측하기 전까지는 알 수 있는 게 거의 없다. 즉, 확률변수의 표본값이 우리에게 가져다줄 수 있는 정보의 양이 많다. 엔트로피의 추정확률변수모형, 즉 이론적인 확률밀도(질량)함수가 아닌 실제 데이터가 주어진 경우에는 확률밀도(질량)함수를 추정하여 엔트로피를 계산해야 한다. 예를 들어 데이터가 80개가 있고 그 중 Y=0 인 데이터가 40개, Y=1인 데이터가 40개 있는 경우는 엔트로피가 1이다. P(y=0) = \\frac{40}{80} = \\frac{1}{2}\\\\ P(y=1) = \\frac{40}{80} = \\frac{1}{2}\\\\ H[Y] = -\\frac{1}{2}\\log_2\\left(\\frac{1}{2}\\right) -\\frac{1}{2}\\log_2\\left(\\frac{1}{2}\\right) = \\frac{1}{2} + \\frac{1}{2} = 1만약 데이터가 40개가 있고 그 중 Y=0인 데이터가 30개, Y=1인 데이터가 10개 있는 경우는 엔트로피가 약 0.81이다. P(y=0) = \\dfrac{30}{40} = \\dfrac{3}{4}\\\\ P(y=1) = \\dfrac{10}{40} = \\dfrac{1}{4}\\\\ H[Y] = -\\dfrac{3}{4}\\log_2\\left(\\dfrac{3}{4}\\right) - \\dfrac{1}{4}\\log_2\\left(\\dfrac{1}{4}\\right) = 0.81지니불순도엔트로피와 유사한 개념으로 지니불순도(Gini impurity)라는 것이 있다. 지니불순도는 엔트로피처럼 확률분포가 어느쪽에 치우쳐있는지를 재는 척도지만, 로그를 사용하지 않기 때문에 계산량이 더 적어서 엔트로피 대용으로 많이 사용된다. G[Y] = \\sum^K_{k=1} P(y_k)(1-P(y_k)) 결합 엔트로피두 확률변수 $X, Y$에 대해 결합 엔트로피(joint entropy)는 다음과 같이 정의한다. $X, Y$가 이산확률변수인 경우 H[X,Y] = -\\sum^{K_x}_{i=1}\\sum^{K_y}_{j=1} P(x_i,y_j)\\log_2P(x_i,y_j) $X, Y$가 이산확률변수인 경우 H[X, Y] = -\\int_x\\int_y p(x,y)\\log_2p(x,y)\\;dxdy조건부 엔트로피조건부 엔트로피는 상관관계가 있는 두 확률변수 X, Y가 있고 X의 값을 알 때 Y가 가질 수 있는 정보량을 의미한다. 수학적인 정의는 다음과 같다. $X, Y$가 이산확률변수인 경우 H[Y\\mid X] = -\\sum^{K_x}_{i=1}\\sum^{K_y}_{j=1}\\log_2P(y_j\\mid x_i) $X, Y$가 연속확률변수인 경우 H[Y\\mid X] = -\\int_x\\int_y p(x,y)\\log_2p(y\\mid x)\\;dxdy조건부 엔트로피는 조건부 확률분포의 정의를 사용해 다음과 같이 고칠 수 있다. $X, Y$가 이산확률변수인 경우 H[Y\\mid X] = \\sum^{K_x}_{i=1}P(x_i)H[Y\\mid X=x_i] $X, Y$가 연속확률변수인 경우 H[Y\\mid X] = \\int_x p(x)H[Y \\mid X=x] \\;dx조건부 엔트로피 예시조건부 엔트로피 개념을 스팸메일 분류문제를 통해 알아보자. 스팸메일 분류모형을 만들기 위한 메일 표본 80개가 있다. 이 중 40개가 정상메일($Y=0$), 40개가 스팸 메일($Y=1$)이다. 스팸메일 여부를 특정 키워드가 존재하는지($X=1$) 혹은 존재하지 않는지($X=0$)의 여부로 알아보고자 한다. 키워드 후보로는 $X_1, X_2, X_3$ 세 가지가 있다. 1) 우선 $X_1$과 $Y$의 관계가 다음과 같다고 하자. $Y=0$ $Y=1$ $X_1 = 0$ 30 10 40 $X_1 = 1$ 10 30 40 40 40 80 이 때 조건부 엔트로피는 0.81이다. \\begin{eqnarray} H[Y\\mid X_1] &=& p(X_1 = 0)H[Y\\mid X_1=0] + p(X_1=1)H[Y\\mid X_1=1]\\\\ &=& \\frac{40}{80}\\cdot 0.81 + \\frac{40}{80}\\cdot 0.81 = 0.81 \\end{eqnarray}2) $X_2$와 $Y$의 관계는 다음과 같다. $Y=0$ $Y=1$ $X_2 = 0$ 20 40 60 $X_2 = 1$ 20 0 20 40 40 80 이 때 조건부 엔트로피는 0.69이다. \\begin{eqnarray} H[Y\\mid X_2] &=& p(X_2 = 0)H[Y\\mid X_2=0] + p(X_2=1)H[Y\\mid X_2=1]\\\\ &=& \\frac{60}{80}\\cdot 0.92 + \\frac{20}{80}\\cdot 0 = 0.69 \\end{eqnarray}3) $X_3$ 과 $Y$ 의 관계는 다음과 같다. $Y=0$ $Y=1$ $X_3=0$ 0 40 40 $X_3 = 1$ 40 0 40 40 40 80 이 때 조건부 엔트로피는 0이 된다. \\begin{eqnarray} H[Y\\mid X_3] &=& p(X_3 = 0)H[Y\\mid X_3=0] + p(X_3=1)H[Y\\mid X_3=1]\\\\ &=& \\frac{40}{80}\\cdot 0 + \\frac{40}{80}\\cdot 0 = 0 \\end{eqnarray}위를 통해 조건부 엔트로피는 X값에 의해 만들어지는 새로운 Y 확률분포의 가중평균임을 알 수 있다. 크로스 엔트로피같은 확률변수에 대한 두 개의 추정 확률분포를 비교하는 데 주로 쓰이는 크로스 엔트로피(cross entropy)는 두 확률분포의 차이를 정량화한 값으로, 예측의 틀린 정도를 나타내주는 일종의 loss function 역할을 해준다. 확률변수를 인수로 사용하는 joint 엔트로피와 달리 확률분포를 인수로 사용해 다음과 같이 정의된다. 이산확률변수인 경우 H[P,Q] = -\\sum_{k=1}^K P(y_k)\\text{log}_2Q(y_k) 연속확률변수인 경우 H[p,q] = -\\int_y p(y)\\log_2q(y)\\;dy 여기서 $P(y_k)$ 는 실제 값, $Q(y_k)$는 예상 값에 해당한다. 크로스 엔트로피 값은 실제값과 예측값이 일치할 경우 0으로 수렴하고, 값이 틀릴 경우 무한대로 발산하기 때문에 크로스 엔트로피를 최소화하는 방향으로 분류모델 성능을 수정한다. 크로스 엔트로피는 확률분포의 차이를 정량화한 값이지만 기준이 되는 분포가 p로 고정되어 있다. q에서 p가 얼만큼 떨어져있는지를 측정한 것과 p에서 q가 얼만큼 떨어져있는지를 측정한 것은 다른 값이다. 즉, p와 q가 바뀌면 값이 달라진다. H[p,q] \\neq H[q,p]크로스 엔트로피는 분류모형의 성능을 측정할 때 사용된다. Y가 0 또는 1이라는 값만 가지는 이진 분류문제를 예로 들어보자. $P_Y$ 는 $X$가 정해졌을 때 실제 $Y$가 가지는 분포를 뜻한다. $X$가 정해지면 $Y$는 확실히 0이거나 확실히 1이다. 즉, $P_Y$는 $(0,1)$ 또는 $(1,0)$이 된다. 하지만 예측값 $\\hat{Y}$의 분포 $Q_\\hat{Y}$는 모수가 $\\mu$인 베르누이 분포이다. 즉 $Q_\\hat{Y}$는 $(1-\\mu, \\mu)$이다. 특정한 X에 대해 P와 Q의 크로스 엔트로피는 아래와 같다. H[P,Q] = \\begin{cases} & -\\log_2 (1-\\mu) & \\text{Y=0일 때} \\\\ & -\\log_2 \\mu & \\text{Y=1일 때} \\\\ \\end{cases}분류문제에서는 $P(Y\\mid X)$ 와 $P(\\hat{Y}\\mid X)$ 가 같으면 최상인 케이스. H[P_Y, P_{\\hat{Y}}] = P_Y(Y=0)\\,\\text{log}P_{\\hat{Y}}(\\hat{Y}=0)\\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,+ P_Y(Y=1)\\,\\text{log}P_{\\hat{Y}}(\\hat{Y}=1)Y는 0이거나 1이다. 로지스틱 회귀분석에서 나왔던 $G^2$ 와 크로스엔트로피의 비교 H[P,Q] = -\\dfrac{1}{N}\\sum_{i=1}^N(y_i\\log_2\\mu_i + (1-y_i)\\log_2(1-\\mu_i)) G^2 = 2\\sum^N_{i=1}\\left(y_i\\log\\dfrac{y_i}{\\hat{y}_i} + (1-y_i)\\log\\dfrac{1-y_i}{1-\\hat{y}_i}\\right)쿨백 - 라이블러 발산쿨백-라이블러 발산(Kullback-Leibler divergence)은 두 확률분포 $p(y)$ 와 $q(y)$ 의 차이를 정량화하는 방법의 하나로, 크로스 엔트로피에서 기준이 되는 분포의 엔트로피 값을 뺀 값이다. 따라서 상대 엔트로피(relative entropy)라고도 한다. 값은 항상 양수이며, 두 확률분포가 완전히 같을 때에만 0이 된다. 이산확률변수의 경우 KL(P\\mid\\mid Q) = H[P,Q] - H[P] = \\sum_{i=1}^K P(y_i)\\log_2\\left(\\dfrac{P(y_i)}{Q(y_i)}\\right) 연속확률변수의 경우 KL(p\\mid\\mid q) = H[p,q] - H[p] = \\int p(y)\\log_2\\left(\\frac{p(y)}{q(y)}\\right)","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"naive bayesian classification model","slug":"naive_bayesian_classification_model","date":"2018-12-06T15:00:00.000Z","updated":"2018-12-07T08:38:34.000Z","comments":true,"path":"2018/12/07/naive_bayesian_classification_model/","link":"","permalink":"https://jyujin39.github.io/2018/12/07/naive_bayesian_classification_model/","excerpt":"","text":"나이브베이즈 분류모형나이브 가정모든 차원의 개별 독립변수 요소들이 서로 조건부 독립이라는 가정을 나이브 가정이라고 한다. 이 가정은 그냥 생각해봐도 말이 안 된다. 예를 들어 iris데이터에서 독립변수 $x_1$은 꽃잎의 길이, $x_2$는 꽃잎의 폭이라고 할 때, 꽃잎의 길이가 길어지면 상식적으로 폭도 커지므로 두 변수 사이에는 매우 큰 상관관계가 있다. 그런데 수많은 데이터에서 상관관계를 모두 구하기가 현실적으로 힘들기 때문에 어떨 수 없이 나이브하게 변수들이 서로 독립이라고 가정하는 것이다. 이 가정을 베이즈 분류모형에 적용한 것이 나이브 베이즈 분류모형(Naive Bayes classification model) 이다. 나이브베이즈 분류모형에서는 데이터들이 서로 독립이라서, 데이터들의 확률분포가 개별 데이터의 확률의 곱으로 표현된다. 주의할 점은 그냥 독립인 게 아니라 y가 특정 클래스라는 조건 하에서 독립, 즉 조건부 독립이다. P(x_1, \\cdots , x_D \\mid y=k) = \\prod_{d=1}^D P(x_d \\mid y=k) P(y=k \\mid x) \\;\\; \\propto \\;\\; \\prod^D_{d=1} P(x_d \\mid y=k)P(y=k) 나이브베이즈 분류모형의 강점 이렇게 나이브한 가정을 했음에도 실제로는 분류가 잘 된다. x들을 서로 독립으로 놓음으로써 qda와 lda가 가지지 못한 또다른 장점이 생기는데, 각 x마다 개별적으로 맞는 모델을 사용할 수 있다는 점이다. 꼭 하나의 분포를 모든 데이터에 대해 사용하지 않아도 되는 것이다. 가우시안 정규분포를 따르지 않아도 되므로 x가 연속이 아니라 이산분포(베르누이, 다항분포 등)인 경우에도 모델링할 수가 있게 된다. Scikit-Learn의 naive_bayes 서브패키지에서는 다음과 같은 세가지 나이브 베이즈 모형 클래스를 제공한다. GaussianNB: 가우시안 정규 분포 나이브 베이즈 BernoulliNB: 베르누이 분포 나이브 베이즈 MultinomialNB: 다항 분포 나이브 베이즈 이 클래스들은 다양한 속성값 및 메서드를 가진다. 우선 사전 확률과 관련된 속성은 다음과 같다. classes_ 종속 변수 y의 클래스 class_count_ 종속 변수 y의 값이 특정한 클래스인 표본 데이터의 수 class_prior_ 종속 변수 y의 무조건부 확률 분포 $P(Y)$ (가우시안 정규 분포의 경우에만) class_log_prior_ 종속 변수 y의 무조건부 확률 분포의 로그 $\\text{log}P(Y)$(베르누이 분포와 다항 분포의 경우에만) 1) 가우시안 정규분포 나이브 베이즈 모형가우시안 분포에서는 $\\mu$(기댓값) 과 $\\sigma$ (표준편차)만 구하면 된다. theta_: 가우시안 정규 분포의 기댓값 $\\mu$ sigma_: 가우시안 정규 분포의 분산 $\\sigma^2$ 예를 들어 두 개의 실수인 독립변수 $x_1, x_2$ 와 두 종류의 클래스 $y=0,1$ 을 가지는 분류 모형이 있다고 하자. 독립변수의 분포는 y의 클래스에 다라 다음처럼 분포가 달라진다. \\mu_0 = \\begin{bmatrix}-2\\\\ -2\\end{bmatrix}, \\;\\; \\Sigma_0 = \\begin{bmatrix} 1 & 0.9 \\\\ 0.9 & 2 \\end{bmatrix} \\mu_1 = \\begin{bmatrix} 2 \\\\ 2\\end{bmatrix}, \\;\\; \\Sigma_1 = \\begin{bmatrix} 1.2 & -0.8 \\\\ -0.8 & 2\\end{bmatrix}이 데이터를 가우시안 나이브베이즈모형으로 다음처럼 풀 수 있다. 12345678910np.random.seed(0)rv0 = sp.stats.multivariate_normal([-2, -2], [[1, 0.9], [0.9, 2]])rv1 = sp.stats.multivariate_normal([2, 2], [[1.2, -0.8], [-0.8, 2]])X0 = rv0.rvs(40)X1 = rv1.rvs(60)X = np.vstack([X0, X1])y = np.hstack([np.zeros(40), np.ones(60)])from sklearn.naive_bayes import GaussianNBmodel_norm = GaussianNB().fit(X, y) 클래스 값이 0일 때와 1일 때 각각 x가 이루는 확률분포의 모수를 계산하면 다음과 같다. 1234567model_norm.theta_[0], model_norm.sigma_[0]#클래스 0일 때 결과(array([-1.96197643, -2.00597903]), array([1.02398854, 2.31390497]))model_norm.theta_[1], model_norm.sigma_[1]#클래스 1일 때 결과(array([2.19130701, 2.12626716]), array([1.25429371, 1.93742544])) 추정 결과 실제 모수와 유사한 모수를 구할 수 있다. 다만, 아래 그래프를 보면 알 수 있듯이, 원래 데이터의 분포는 무시된다. 위 그래프는 원래 데이터의 분포를 나타낸 플롯이고, 아래 그래프는 나이브베이즈 모형으로 추정한 데이터의 분포 그래프이다. 원래 데이터의 분포를 보면 0번 클래스(파란색)에 해당하는 데이터는 약간 양의상관관계가 보이고, 1번 클래스(빨간색)에 해당하는 데이터는 약간 음의 상관관계를 보인다. 그러나 나이브베이즈 모형에서는 그러한 상관관계를 없다고 배제해버리고 두 클래스의 분포를 동일하다고 가정하기 때문에 아래와 같은 모양이 된다. 만들어진 모형으로 $x_{new}=(-0.7, -0.8)$ 인 데이터의 y 값을 예측해보자. 12345x_new = [-0.7, -0.8]model_norm.predict_proba([x_new])#결과:array([[0.98300323, 0.01699677]])#x_new가 클래스 0일 확률, 1일 확률 따라서 $y=0$일 확률이 $y=1$일 확률보다 훨씬 크다는 것을 알 수 있다. 2) 베르누이 분포 나이브베이즈 모형베르누이 모형에서는 타겟변수뿐 아니라 독립변수도 0 또는 1의 값을 가져야 한다. 예를 들어 문서에 특정 단어가 포함되어있는지의 여부를 베르누이 확률변수로 모형화할 수 있다. 여기서 추정해야 되는 것은 개별 x와 y마다의 뮤 값이다. 스팸 메일을 디텍팅하는 데 이 모형을 사용한다고 해보자. 아래의 경우 총 10개의 메일을 4개의 키워드의 포함여부에 따라 0 또는 1 값을 부여한 것이다. 독립변수가 0이면 특정 키워드가 포함되지 않은 것이고, 1이면 특정 키워드가 포함된 것이다. 종속변수 값은 0이면 정상메일, 1이면 스팸메일에 해당한다. 123456789101112X = np.array([ [0, 1, 1, 0], #행 하나가 메일 하나, 열 하나가 키워드 하나 [1, 1, 1, 1], [1, 1, 1, 0], [0, 1, 0, 0], [0, 0, 0, 1], [0, 1, 1, 0], [0, 1, 1, 1], [1, 0, 1, 0], [1, 0, 1, 1], [0, 1, 1, 0]])y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])#정상메일인지 아닌지 라벨링 스무딩(Smoothing) : 표본 데이터의 수가 적은 경우에는 베르누이 모수가 0 또는 1이라는 극단적인 추정값이 나올 수도 있다. 하지만 현실적으로는 그럴 가능성은 매우 적다. 따라서 베르누이분포 나이브베이즈 모형 내에서, 추정한 모수들의 값이 0.5에 좀더 가까워지도록 각각의 x에 가상의 데이터 0과 1을 하나씩 추가한다. \\hat{\\mu}_{d,k} = \\dfrac{N_{d,k}+\\alpha}{N_k + 2\\alpha}이렇게 스무딩을 거치면 1에 가까웠던 모수는 작아지고, 0에 가까웠던 모수는 커져서 모두 0.5에 조금씩 더 가까워지게 된다. 만약 2개의 데이터에서 개수를 더 늘려서 $\\alpha$ 개 만큼의 데이터를 추가하면 모수값이 좀 더 0.5에 가까워질 것이다. 이제 위 데이터를 베르누이 나이브 베이즈 모형으로 예측해 보자. 12from sklearn.naive_bayes import BernoulliNBmodel_bern = BernoulliNB().fit(X, y) 각 클래스와 키워드별로 총 8개의 베르누이 확률변수의 모수를 구해보면 실제 값은 다음과 같다. 12345fc = model_bern.feature_count_fc / np.repeat(model_bern.class_count_[:, np.newaxis], 4, axis=1)#결과array([[0.5 , 1. , 0.75 , 0.25 ], [0.33333333, 0.5 , 0.83333333, 0.5 ]]) 그런데 모형으로 예측해보면 값이 다르다. 모형 내부에서 디폴트 알파값이 1인 스무딩을 거쳐 각 모수가 0.5에 가까워진 추정값을 출력하기 때문이다. 12345theta = np.exp(model_bern.feature_log_prob_)theta#결과array([[0.5 , 0.83333333, 0.66666667, 0.33333333], [0.375 , 0.5 , 0.75 , 0.5 ]]) 이렇게 만들어진 모형에 테스트데이터를 넣고 클래스 예측을 해 보면 다음처럼 정상메일일 확률을 구할 수 있다. 1234x_new = np.array([1, 1, 0, 0])model_bern.predict_proba([x_new])#결과array([[0.72480181, 0.27519819]]) 3) 다항 분포 나이브 베이즈 모형다항 분포 나이브베이즈 모형에서는 독립변수 x가 0 또는 자연수이다. 베르누이에서 x가 특정 단어의 출현 여부였다면, 다항분포에서는 특정단어가 한 문서에 나온 빈도 수가 된다. 여기서는 각 클래스 k에서 x의 개수 d(아래의 경우 4개)만큼의 면을 가진 주사위를 던졌을 때 d번째 면이 나온 횟수가 입력변수로 들어간다. 따라서 다항 분포 가능도모형을 기반으로 하는 나이브 베이즈 모형은 주사위를 던진 결과로부터 $1,K_1,\\cdots,K_K$ 중 어느 주사위를 던졌는지를 찾아내는 모형이라고 할 수 있다. 다항분포 나이브베이즈 모형에서 스무딩 공식은 다음과 같다. 주사위의 각 면이 $\\alpha$ 번씩 나온 경우를 추가해주는 것이라고 생각하면 된다. $N_{d,k}$ 는 클래스 k에서 d번째 면이 나온 횟수를 의미한다. \\hat{\\mu}_{d,k} = \\dfrac{N_{d,k} + \\alpha}{N_k + D\\alpha}123456789101112131415X = np.array([ #[1, 1, 1, 1] 클래스 0의 스무딩. 주사위 각면이 1번씩 나온 경우를 추가 [3, 4, 1, 2], [3, 5, 1, 1], [3, 3, 0, 4], [3, 4, 1, 2], #여기까지 클래스 0 [1, 2, 1, 4], [0, 0, 5, 3], [1, 2, 4, 1], [1, 1, 4, 2], [0, 1, 2, 5], [2, 1, 2, 3]]) #여기까지 클래스 1y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]) 베르누이 분포에서와 마찬가지로 실제 데이터의 모수와 스무딩을 거친 모형에서 추정한 모수는 다르게 된다. 12345678910111213#실제 모수fc = model_mult.feature_count_fc / np.repeat(fc.sum(axis=1)[:, np.newaxis], 4, axis=1)#결과array([[0.3 , 0.4 , 0.075 , 0.225 ], [0.10416667, 0.14583333, 0.375 , 0.375 ]]) #추정 모수theta = np.exp(model_mult.feature_log_prob_)theta#결과array([[0.29545455, 0.38636364, 0.09090909, 0.22727273], [0.11538462, 0.15384615, 0.36538462, 0.36538462]]) 다항분포에서는 스무딩을 하면 각 모수가 0.25에 조금씩 더 가까워진다. 이 모형으로 새로운 데이터의 클래스를 예측해보면 다음과 같이 클래스 1에 해당할 확률이 2배 가량 높다는 결론을 낼 수 있다. 12345x_new = np.array([10, 10, 10, 10])model_mult.predict_proba([x_new])#결과array([[0.38848858, 0.61151142]]) 만약 문서에 TF-IDF(inverse document frequency) 인코딩을 하게되면 텍스트에 나온 단어의 빈도수가 정수가 아닌 실수값이 나올 수도 있다. 이 때에도 다항분포 나이브베이즈 모형을 쓸 수 있을까? 아래와 같이 TF-IDF 인코딩을 거친 벡터가 있을 때, 원소를 모두 정수로 만들어주는 과정을 거치게 되면 숫자가 커질 뿐 기존의 다항분포와 똑같은 데이터가 된다. 123456789TF_IDF_X = np.array([ [3.2, 5.4, 1.1, 0.3], [1.1, 2.3, 10.9, 5.8]])#한 클래스가 이런 식으로 있다고 할 때, 모든 값에 10을 곱하면TF_IDF_X = np.array([ [32, 54, 11, 3], [11, 23, 109, 58]])#총 횟수가 늘어났을 뿐 MultinomialNB 계산이 가능하다. 그렇다면 만약 x 값에 실수 변수, 0/1 값을 가지는 변수, 일정 변수 집합이 특정한 분포를 이루는 변수들이 섞여있다면 어떻게 풀 수 있을까? 나이브베이지안 모형에서 각 변수는 서로 독립이므로, 성격을 공유하는 변수끼리 모아서 각각에 맞는 모형에 넣으면 된다. 예를 들어 데이터가 100개일 때 1~20개는 가우시안, 21~50은 베르누이, 51~100은 다항 분포라면, 세 모델을 predict_proba 한 후 P(y)값만을 제거하고 다 곱해준다. 그 후 P(y)를 한번만 곱해주면 구하고자 하는 조건부확률을 구할 수 있게 된다. \\begin{eqnarray} P(y \\mid x_{1:100}) &=& P(x_{1:100}\\mid y)P(y)\\\\ &=& P(x_{1:20}\\mid y)P(x_{21:50}\\mid y)P(x_{51:100}\\mid y)P(y)\\\\ \\end{eqnarray} \\text{Gaussian_P} = P(x_{1:20}\\mid y)P(y)\\\\ \\text{Bernoulli_P} = P(x_{21:50}\\mid y)P(y)\\\\ \\text{Multinomial_P} = P(x_{51:100}\\mid y)P(y)참조:","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"QDA & LDA","slug":"QDA_LDA","date":"2018-12-05T15:00:00.000Z","updated":"2018-12-06T13:17:13.000Z","comments":true,"path":"2018/12/06/QDA_LDA/","link":"","permalink":"https://jyujin39.github.io/2018/12/06/QDA_LDA/","excerpt":"","text":"QDA와 LDA확률론적 생성모형에서는 베이즈 정리를 사용하여 조건부확률을 계산한다고 했다. P(y=k\\mid x) = \\dfrac{P(x\\mid y=k)P(y=k)}{P(x)}하나의 독립변수 x에 대해 y가 k일 경우의 조건부확률을 모두 구해서 그 중 가장 값이 큰 y로 추정하는데, 위 베이즈정리 공식에서 분모는 P(x)이므로 이 때 분모값은 고정이다. 따라서 확률의 크기만을 비교해도 되는 경우에는 현실적으로 분모를 따로 구하지 않고 분자만을 계산해 비교하여 클래스를 판별하기도 한다. P(y=k\\mid x) \\; \\; \\propto \\;\\; P(x\\mid y=k)P(y=k)여기서 사전확률, 즉 $P(y=k)$ 는 다음처럼 계산한다. P(y=k) \\approx \\dfrac{\\;\\;\\;y=k\\text{인 데이터의 수}\\;\\;\\;}{모든 데이터의 수}그리고 가능도 $P(x \\mid y=k)$ 는 다음과 같이 계산한다. $P(x \\mid y= k)$ 가 특정한 확률분포 모형을 따른다고 가정한다. k번째 클래스에 속하는 학습데이터 {$x_1, \\cdots , x_{N}$} 을 사용하여 이 모형의 모수 값을 구한다. 모수값을 알고 있으므로 $P(x \\mid y=k)$ 의 확률밀도함수를 구한 것이다. 즉, 새로운 독립변수가 어떤 x가 되더라도 가능도를 구할 수 있다. QDA베이즈 정리를 사용하여 조건부확률 $p(y=k\\mid x)$ 을 계산하는 확률적 생성모형 중에서, 독립변수 x가 다변수 가우시안 정규분포(Multivariable Gaussian Normal distribution)을 따른다고 가정하는 모형이 QDA(Quadratic Discriminant Analysis)이다. p(x\\mid y=k) = \\dfrac{1}{(2\\pi)^{D/2}|\\Sigma_k|^{1/2}}\\text{exp}\\left(-\\dfrac{1}{2}(x-\\mu_k)^T\\Sigma_k^{-1}(x-\\mu_k)\\right) $\\sum_k$ : k클래스에 해당하는 x들의 공분산행렬 $\\mu_k$ : 1클래스에 해당하는 x들의 평균 이 분포들을 알고 있으면 독립변수 x에 대한 y의 조건부확률 분포는 다음과 같이 베이즈 정리와 전체확률의 법칙으로 구할 수 있다. P(y=k\\mid x) = \\dfrac{p(x\\mid y=k)P(y=k)}{p(x)}=\\dfrac{p(x\\mid y=k)P(y=k)}{\\sum_l p(x\\mid y=l)P(y=l)}예를 들어 y가 1, 2, 3 세 개의 클래스를 가지고, 각 클래스에서의 x의 확률분포가 다음과 같은 기댓값 및 공분산행렬을 갖는다고 가정하자. \\mu_1 = \\begin{bmatrix} 0\\\\0 \\end{bmatrix},\\;\\; \\mu_2 = \\begin{bmatrix} 1\\\\1 \\end{bmatrix}, \\;\\;\\mu_3 = \\begin{bmatrix} -1\\\\1 \\end{bmatrix}\\\\ \\Sigma_1 = \\begin{bmatrix} 0.7 & 0\\\\0 & 0.7 \\end{bmatrix},\\;\\; \\Sigma_2 = \\begin{bmatrix} 0.8 & 0.2\\\\0.2 & 0.8 \\end{bmatrix}, \\;\\; \\Sigma_3 = \\begin{bmatrix} 0.8 & 0.2\\\\0.2 & 0.8 \\end{bmatrix}y의 사전확률은 다음과 같이 동일하다. P(Y = 1) = P(Y=2) = P(Y=3) = \\dfrac{1}{3}Scikit-Learn은 QDA 모형을 위한QuadraticDiscriminantAnalysis 클래스를 제공한다. 이 클래스로 위에서 가정한 바에 따라 모형을 만들어 보자. 1234567891011121314N = 100np.random.seed(0)X1 = sp.stats.multivariate_normal([0, 0], [[0.7, 0], [0, 0.7]]).rvs(100)X2 = sp.stats.multivariate_normal([1, 1], [[0.8, 0.2], [0.2, 0.8]]).rvs(100)X3 = sp.stats.multivariate_normal([-1, 1], [[0.8, 0.2], [0.2, 0.8]]).rvs(100)y1 = np.zeros(N)y2 = np.ones(N)y3 = 2*np.ones(N)X = np.vstack([X1, X2, X3])y = np.hstack([y1, y2, y3])from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysisqda = QuadraticDiscriminantAnalysis(store_covariance=True).fit(X, y)#store_covariance=True로 놓으면 공분산행렬을 제공한다 123456qda.means_ #각 클래스에서의 추정된 기댓값 벡터 #결과array([[-8.01254084e-04, 1.19457204e-01], # class 1일 때 [ 1.16303727e+00, 1.03930605e+00], # 2일 때 [-8.64060404e-01, 1.02295794e+00]])# 3일 때 1234567qda.covariance_ #공분산행렬#결과[array([[ 0.73846319, -0.01762041], [-0.01762041, 0.72961278]]), array([[0.66534246, 0.21132313], [0.21132313, 0.78806006]]), array([[0.9351386 , 0.22880955], [0.22880955, 0.79142383]])] 이 확률분포를 사용하여 분류를 한 결과는 다음과 같다. 1234567891011121314151617x1min, x1max = -5, 5x2min, x2max = -4, 5XX1, XX2 = np.meshgrid(np.arange(x1min, x1max, (x1max-x1min)/1000), np.arange(x2min, x2max, (x2max-x2min)/1000))YY = np.reshape(qda.predict(np.array([XX1.ravel(), XX2.ravel()]).T), XX1.shape)cmap = mpl.colors.ListedColormap(sns.color_palette([\"r\", \"g\", \"b\"]).as_hex())plt.contourf(XX1, XX2, YY, cmap=cmap, alpha=0.5)plt.scatter(X1[:, 0], X1[:, 1], alpha=0.8, s=50, marker=\"o\", color='r', label=\"클래스 1\")plt.scatter(X2[:, 0], X2[:, 1], alpha=0.8, s=50, marker=\"s\", color='g', label=\"클래스 2\")plt.scatter(X3[:, 0], X3[:, 1], alpha=0.8, s=50, marker=\"x\", color='b', label=\"클래스 3\")plt.xlim(x1min, x1max)plt.ylim(x2min, x2max)plt.xlabel(\"x1\")plt.ylabel(\"x2\")plt.title(\"QDA 분석 결과\")plt.legend()plt.show() 이 그래프는 predict 결과를 등고선으로 나타낸 것이다. 경계선이 그려진 영역에서 높이가 구분되고, 다른 곳은 높이가 일정한 평지이다. 각 영역에 다른 색깔로 misclassification된 데이터들이 많지만 그건 어쩔 수가 없다. QDA의 약점 모형을 만들어 예측하려면 독립변수들의 Covariance 행렬을 먼저 추정해내야 한다는 점이다. 데이터가 적을 때는 괜찮지만 현실에서 데이터가 수천 수만개가 되면, 공분산 행렬의 크기는 데이터수의 제곱만큼 커지게 된다. 데이터가 많아질수록 공분산행렬에는 노이즈가 많아지고, 추정도 부정확하게 된다. LDA(Linear discriminant analysis)LDA(Linear Discriminant Analysis)에서는 클래스별로 중심의 위치만 다를 뿐 데이터의 분포는 같다고 가정한다. 즉, 각 클래스 y에 대한 독립변수 x의 조건부 확률분포가 공통된 공분산 행렬을 갖는 다변수 가우시안 정규분포라고 가정한다. \\Sigma_k = \\Sigma \\;\\;\\;\\;\\text{for all} \\;\\;k이러한 가정은 현실과는 다를 수 있지만 데이터 자체에 노이즈가 섞이는 것을 막아주어, 분류가 qda보다 오히려 정확하게 이루어질 수 있다. 각 class 영역을 구분하는 경계가 곡선이었던 QDA와 달리 LDA에서는 직선이 된다. Scikit-Learn은 LDA 모형을 위한 LinearDiscriminantAnalysis 클래스를 제공한다. 아래 사용한 데이터는 위 QDA를 진행했던 것과 같은 데이터다. 12from sklearn.discriminant_analysis import LinearDiscriminantAnalysislda = LinearDiscriminatAnalysis(n_components=3, solver='svd', store_covariance=True).fit(X, y) LDA에서는 기댓값 벡터만 클래스에 따라 달라지고, 공분산행렬은 모든 클래스에 대해 하나로 동일하다. 12345lda.means_#결과array([[-8.01254084e-04, 1.19457204e-01], [ 1.16303727e+00, 1.03930605e+00], [-8.64060404e-01, 1.02295794e+00]]) 1234lda.covariance_#결과array([[0.7718516 , 0.13942905], [0.13942905, 0.7620019 ]]) LDA 모형에 따른 분류 결과는 다음과 같다. 1234567891011121314151617x1min, x1max = -5, 5x2min, x2max = -4, 5XX1, XX2 = np.meshgrid(np.arange(x1min, x1max, (x1max-x1min)/1000), np.arange(x2min, x2max, (x2max-x2min)/1000))YY = np.reshape(lda.predict(np.array([XX1.ravel(), XX2.ravel()]).T), XX1.shape)cmap = mpl.colors.ListedColormap(sns.color_palette([\"r\", \"g\", \"b\"]).as_hex())plt.contourf(XX1, XX2, YY, cmap=cmap, alpha=0.5)plt.scatter(X1[:, 0], X1[:, 1], alpha=0.8, s=50, marker=\"o\", color='r', label=\"클래스 1\")plt.scatter(X2[:, 0], X2[:, 1], alpha=0.8, s=50, marker=\"s\", color='g', label=\"클래스 2\")plt.scatter(X3[:, 0], X3[:, 1], alpha=0.8, s=50, marker=\"x\", color='b', label=\"클래스 3\")plt.xlim(x1min, x1max)plt.ylim(x2min, x2max)plt.xlabel(\"x1\")plt.ylabel(\"x2\")plt.legend()plt.title(\"LDA 분석 결과\")plt.show() LDA의 약점 문제는, LDA에서도 데이터가 너무 많아지면 공분산행렬이 너무 커진다는 점이다. 그래서 나온 가정이 공분산행렬의 대각성분만 구하고 나머지 비대각성분은 0이라고 하자는 나이브 가정이다. QDA를 간략화한 모형이 LDA이고, 그걸 더 간략화한 모형이 다음 설명할 나이브베이즈 모형이다. 참조:","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"classification performance evaluation","slug":"classification_performance_evaluation","date":"2018-12-01T15:00:00.000Z","updated":"2018-12-04T06:49:37.000Z","comments":true,"path":"2018/12/02/classification_performance_evaluation/","link":"","permalink":"https://jyujin39.github.io/2018/12/02/classification_performance_evaluation/","excerpt":"","text":"분류 성능 평가분류 문제는 회귀분석과 달리 다양한 성능 평가기준이 필요하다. Scikit-Learn에서 제공하는 분류 성능평가 메서드들은 다음과 같다. sklearn.metrics 서브 패키지 confusion_matrix() classfication_report() accuracy_score(y_true, y_pred) precision_score(y_true, y_pred) recall_score(y_true, y_pred) fbeta_score(y_true, y_pred, beta) f1_score(y_true, y_pred) 분류 결과표 Confusion Matrix분류 결과표는 타겟의 실제 클래스와 모형이 예측한 클래스가 일치하는 개수를 표로 나타낸 것이다. 원래 클래스는 행으로, 예측한 클래스는 열로 나타낸다. 예측 클래스 0 예측 클래스 1 예측 클래스 2 원래 클래스 0 2 0 0 원래 클래스 1 0 0 1 원래 클래스 2 1 0 2 이를 코드로 구현하면 다음과 같다. 1234from sklearn.metrics import confusion_matrixy_true = [2, 0, 2, 2, 0, 1]y_pred = [0, 0, 2, 2, 0, 2]confusion_matrix(y_true, y_pred) 1234#분류결과표array([[2, 0, 0], [0, 0, 1], [1, 0, 2]]) 이진 분류 결과표 Binary Confusion Matrix클래스가 두 개인 경우에는 일반적으로 클래스 이름을 “Positive”와 “Negative”로 표시한다. positive : 특이한 케이스에 해당하는 경우 negative : 그렇지 않은 일반적인 경우 이진 분류 결과표는 다음과 같은 모양이다. Positive라고 예측 Negative라고 예측 실제 Positive True Positive False Negative 실제 Negative False Positive True Negative FDS (Fraud Detection System)잘못된 거래 및 사기 거래 등을 예측하는 시스템으로, 예측 결과가 실제와 일치하는지에 따라 다음과 같이 구분한다. TP(True Positive): 사기를 사기라고 정확하게 예측 TN(True Negative): 정상을 정상이라고 정확하게 예측 FP(False Positive): 정상을 사기라고 잘못 예측 FN(False Negative): 사기를 정상이라고 잘못 예측 FDS는 병의 진단에도 쓰일 수 있다. (positive: 병에 걸린 것, negative: 병에 걸리지 않은 것) 이진분류결과표에 따르면 분류모델의 성능평가척도가 4개로 추려지지만 그래도 여전히 많다. 그래서 그 4개의 수를 조합해 하나의 점수로 만든 것이 아래 설명할 평가점수다. 평가 점수FDS 의 결과로 나온 TP, TN, FP, FN 네 가지를 조합해 다음의 평가점수들을 계산한다. accuracy (정확도) precision (정밀도) recall (재현율) fallout (위양성율) F (beta) score 1) Accuracy​ : 전체 샘플 중 맞게 예측한 샘플 수의 비율 \\text{accuracy} = \\dfrac{TP + TN}{TP + TN + FP + FN}2) Precision​ : Positive 클래스라고 예측한 데이터 중 실제로 Positive에 해당하는 데이터의 비율 사기거래 추정에서 일단 positive라고 추정이 됐으면 그게 실제 사기문제일 수 있기 때문에 중요하게 여겨지고, 사기거래 특정 시스템이 실제로 잘 작동하고 있는지 파악할 수 있어야 되기 때문에 precision점수가 중요하게 된다. \\text{precision} = \\dfrac{TP}{TP + FP}3) Recall​ : 실제 Positive인 데이터 중 Positive라고 예측된 데이터의 비율 \\text{recall} = \\dfrac{TP}{TP + FN}4) Fall-Out​ : 실제 Negative인 데이터 중 Positive로 잘못 에측된 표본의 비율 \\text{fallout} = \\dfrac{FP}{FP + TN}5) F (beta) score​ :반비례관계에 있는 precision과 recall은 둘 다 중요한 점수이기 때문에 같이 봐야 하는데, 그 때 그 두 점수를 가중조화 평균낸 점수가 F-score다. 베타 값에 따라 달라진다. F_\\beta = \\dfrac{(1 + \\beta^2) \\, ({\\text{precision} \\times \\text{recall}})}{({\\beta^2 \\, \\text{precision} + \\text{recall}})} F1 score (beta = 1) F_1 = \\dfrac{2\\cdot\\text{precision}\\cdot\\text{recall}}{\\text{precision} + \\text{recall}} Scikit-Learn의 metrics 패키지에서는 정밀도, 재현율, F1-score를 구하는 classification_report 명령을 제공한다. 이 명령은 각각의 클래스를 positive로 보았을 때의 precision, recall, F1-score를 구하고 그 평균값으로 전체 모형의 성능을 평가한다. 123456from sklearn.metrics import classification_reporty_true = [0, 0, 0, 1, 1, 0, 0]y_pred = [0, 0, 0, 0, 1, 1, 1]print(classification_report(y_true, y_pred, target_names=[&apos;class 0&apos;, &apos;class 1&apos;])) 1234567#결과 precision recall f1-score support class 0 0.75 0.60 0.67 5 class 1 0.33 0.50 0.40 2avg / total 0.63 0.57 0.59 7 위의 평가 점수들은 서로 밀접한 관계를 맺고 있다. 재현율(recall)과 위양성률(fall-out)은 양의 상관 관계가 있다. 정밀도(precision)와 재현율(recall)은 대략적으로 음의 상관 관계가 있다. Precision vs. Recall분류모델 예측결과 precision과 recall이 모두 높으면 좋지만, 사실 두 점수는 반비례하는 경향이 있다. precision은, 예를들어 의사가 진단을 하는 경우 의사의 권위 및 능력과 직결되는 점수이다. precision이 낮으면 신뢰도가 떨어지기때문에 의사는 precision을 높이기 위해 판별함수 f(x)의 기준점을 0보다 높게 설정하게 된다. f(x)가 10 이상인 경우에만 positive라고 진단해버림으로써 0이상 10 미만일 때 오진이었던 경우를 배제해버리는 것이다. 그러면 precision점수가 높아진다. 이와 반대로 recall을 높이려면 존재하는 모든 positive를 잡아내야만 하는 것이 목표가 된다. 그러기 위해서는 반대로 f(x)의 임계점을 0보다 낮게 만든다. 일단 negative인 것들도 막 잡아내고 보면 positive가 다 잡히게 되어있기 때문이다. 따라서 precision과 recall을 동시에 높이기는 쉽지 않다. ROC 커브ROC(Receiver Operator Characteristic) 커브란, fall-out과 recall 값이 판별함수 기준값의 변화에 따라 어떻게 달라지는지를 시각화한 것이다. 아래 표는, 16개의 데이터에 대해 판별함수 기준값을 0으로 설정하고 이진분류를 진행한 결과이다. ​ 표를 보면 6번, 7번, 10번 데이터의 예측에 실패했음을 알 수 있다. 이 때 만약 판별함수 기준값을 6번데이터의 판별함수값인 0.244729보다 높이게 되면 6번데이터는 0클래스로 예측되게 되므로 정확한 예측이 된다. 이런 식으로 기준값을 높이거나 낮춰가면서 recall과 fall-out 점수를 확인하는 과정을 자동으로 진행하고 시각화해주는 것이 scikit-learn의 roc_curve 명령이다. ​ 아래 그래프는 위 16개의 데이터에 대한 ROC 곡선이다. 데이터가 더 많으면 더 곡선에 가까운 형태의 그래프가 그려진다. AUC분류모델은 Fall-Out 점수가 낮으면서 Recall이 높으면 좋기 때문에 ROC커브 그래프에서는 좌측 상단의 점이 높게 그려질수록 좋은 모델에 해당한다. 따라서 곡선 아래 면적이 클수록 좋은데, 그 면적을 측정한 것이 AUC(Area Under the Curve)이다. AUC가 1에 가까울수록 좋은 모델이라고 볼 수 있다. 12from sklearn.metrics import aucauc(fpr, tpr) 12#AUC 결과값0.9112016520622872","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"multi-class classification","slug":"multi-class-classification","date":"2018-11-29T11:37:09.000Z","updated":"2018-11-29T11:57:04.000Z","comments":true,"path":"2018/11/29/multi-class-classification/","link":"","permalink":"https://jyujin39.github.io/2018/11/29/multi-class-classification/","excerpt":"","text":"다중 클래스 분류 이진(Binary Class) 분류 : 종속변수의 클래스가 2개인 분류 문제 다중 클래스(Multi-Class) 분류 : 종속변수의 클래스가 3 개 이상인 분류문제 OvO 혹은 OvR 방법을 통해 여러 개의 이진 클래스 분류문제로 변환해서 푼다 OvO (One-vs-One): K개의 타겟 클래스가 존재할 때, 그 중 2개씩 선택해 이진 클래스 분류 문제를 풀고, 그 결과로 가장 많은 판별값을 얻은 클래스를 선택하는 방법 풀어야 하는 이진 클래스분류 문제의 수 : $ _KC_2 $ 두 개의 클래스씩 비교했을 때 선택받은 횟수의 총합으로 비교하면 여러 클래스가 동점이 나오는 tie case가 발생할 수 있기 때문에 각 클래스가 얻은 조건부 확률값을 모두 더한 값으로 비교하면 그 문제가 해결된다. OneVsOneClassifier 클래스를 사용하면 이진 클래스용 모형을 OvO 방법으로 다중 클래스용 모형으로 변환한다. 12345from sklearn.multiclass import OneVsOneClassifierfrom sklearn.linear_model import LogisticRegressionmodel_ovo = OneVsOneClassifier(LogisticRegression()).fit(iris.data, iris.target) #2진 모형 인스턴스를 만들고 OvO로 wrapping하면 내부에서 세 번 경합 실시 각 클래스가 얻는 조건부 확률값을 합한 값을 decision_function으로 출력한다. 12345678ax1 = plt.subplot(211)pd.DataFrame(model_ovo.decision_function(iris.data)).plot(ax=ax1, legend=False)plt.title(\"판별 함수\")ax2 = plt.subplot(212)pd.DataFrame(model_ovo.predict(iris.data), columns=[\"prediction\"]).plot(marker='o', ls=\"\", ax=ax2)plt.title(\"클래스 판별\")plt.tight_layout()plt.show() ​ 0(파란색), 1(주황색), 2(초록색)의 총 3개 클래스로 데이터가 판별되었고, 총 세 개의 데이터가 잘못 예측되었음이 확인 가능하다. OvR (One-vs-the-Rest): 클래스 개수가 K개이면 풀어야할 이진분류 문제가 K의 제곱에 비례하여 많아지는 OvO와 달리, OvR은 K개의 문제를 풀면 되기 때문에 훨씬 빠르고 효율적이다. 클래스 A, B, C가 있을 때, A vs B,C 즉, A vs A$^C$ B vs A,C 즉, B vs B$^C$ C vs A,B 즉, C vs C$^C$ 이렇게 3 번 이진문제를 푸는데, OvR에서도 판별 결과의 수가 같은 동점 문제가 발생할 수가 있기 때문에 각 클래스가 얻은 조건부 확률값을 더하여 그 값이 +가 나오면 해당 클래스고 -가 나오면 해당 클래스가 아니라고 판단한다. 결과적으로는 +값이 나온 클래스들 중 가장 그 값이 큰 클래스를 정답으로 예측한다. OneVsRestClassifier 클래스를 사용하면 이진 클래스용 모형을 OvR 방법으로 다중 클래스용 모형으로 변환한다. 12345678910111213from sklearn.multiclass import OneVsRestClassifierfrom sklearn.linear_model import LogisticRegressionmodel_ovr = OneVsRestClassifier(LogisticRegression()).fit(iris.data, iris.target)ax1 = plt.subplot(211)pd.DataFrame(model_ovr.decision_function(iris.data)).plot(ax=ax1, legend=False)plt.title(\"판별 함수\")ax2 = plt.subplot(212)pd.DataFrame(model_ovr.predict(iris.data), columns=[\"prediction\"]).plot(marker='o', ls=\"\", ax=ax2)plt.title(\"클래스 판별\")plt.tight_layout()plt.show() ​ 그래프를 보면 클래스 판별 예측에 실패한 데이터의 수가 약 6개로 OvO보다 예측 성능이 조금 떨어지는 것을 볼 수 있다. 하지만 현실적으로 클래스가 많아지면 OvO는 아예 쓸 수가 없기 때문에 OvR을 쓰는 것이 일반적이다.","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]},{"title":"classification models","slug":"classification-models","date":"2018-11-27T15:00:00.000Z","updated":"2018-12-07T08:36:11.000Z","comments":true,"path":"2018/11/28/classification-models/","link":"","permalink":"https://jyujin39.github.io/2018/11/28/classification-models/","excerpt":"","text":"분류모형분류(classification)는 독립 변수 값이 주어졌을 때 그 독립 변수 값과 가장 연관성이 큰 종속변수 카테고리(클래스)를 계산하는 문제이다. 분류 모형의 종류 판별함수(discriminant function) 모형 : 주어진 데이터를 서로 다른 영역으로 나누는 경계면을 찾는다. 확률적 모형 확률적 판별(discriminative) 모형 : 주어진 데이터가 특정 카테고리일 조건부확률을 직접 계산한다. 확률적 생성(generative) 모형 : 주어진 데이터가 특정 카테고리일 조건부확률을 베이즈정리를 통해 계산한다. 모형 방법론 Linear/Quadratic Discriminant Analysis 확률적 생성 모형 나이브 베이지안 (Naive Bayes) 확률적 생성 모형 로지스틱 회귀 (Logistic Regression) 확률적 판별 모형 의사결정나무 (Decision Tree) 확률적 판별 모형 퍼셉트론 (Perceptron) 판별함수 모형 서포트 벡터 머신 (Support Vector Machine) 판별함수 모형 신경망 (Neural Network) 판별함수 모형 1. 확률적 모형1) 확률적 생성모형조건부확률 기반 생성모형의 장점 중 하나는 클래스가 3개 이상인 경우에도 바로 적용할 수 있다는 점이다. 생성모형은 더 구하기 쉬운 클래스별 특징 데이터의 확률분포 $ P(x | y = k) $, 즉 가능도를 먼저 추정한 다음 베이즈 정리를 사용하여 $ P(y = k | x) $ 를 계산한다. P(y = k | x) = \\dfrac{P(x | y = k)P(y = k)}{P(x)}또한 전체확률의 법칙을 이용하여 $ P(x) $ 를 구할 수 있다. 이 값을 알면 x라는 데이터만 입력되어도 그 데이터 자체가 정상적인 데이터인지 아닌지 판단할 수 있다. P(x) = \\sum^K_{k=1}P(x|y = k)P(y = k)확률적 생성모형의 예로 QDA와 Naive Bayesian model이 있다. QDA QDA(Quadratic Discriminant Analysis)에서는 다음과 같은 코드로 분류문제를 푼다. 1234from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysismodel = QuadraticDiscriminantAnalysis().fit(X, y)test_data = [[0.2, 0.2]]p = model.predict_proba(test_data) 나이브 베이지안 모형** TfidfVectorizer 전처리기는 텍스트 데이터를 BoW에 따라 실수 벡터로 변환한다. MultinomialNB 모형은 나이브 베이즈 방법으로 분류 문제를 예측한다. Pipeline을 사용하여 이 두 클래스 객체를 하나의 모형으로 합친다. 1234567891011from sklearn.datasets import fetch_20newsgroupsfrom sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.naive_bayes import MultinomialNBfrom sklearn.pipeline import Pipelinenews = fetch_20newsgroups(subset=\"all\")model = Pipeline([ ('vect', TfidfVectorizer(stop_words=\"english\")), ('nb', MultinomialNB()),])model.fit(news.data, news.target) ​ 20개의 클래스 중 3번 클래스에 가장 높은 조건부확률을 갖기 때문에 3번째 클래스에 해당한다고 판별한다. 2) 확률적 판별 모형확률적 생성 모형과 달리 확률적 판별 모형에서는 조건부확률 $ p(y = 1 | x) $ 가 x값에 따라 0에서 1 사이에서 달라지는 값을 갖는 함수라고 가정하고, 그 함수를 직접 찾아낸다. p(y = k | x) = f(x)​ 확률적 판별 모형에는 로지스틱 회귀모형과 의사결정나무가 있다.​​​ - **로지스틱** **회귀모형** 123456from sklearn.datasets import make_classificationfrom sklearn.linear_model import LogisticRegressionX0, y = make_classification(n_features=1, n_redundant=0,n_informative=1, n_clusters_per_class=1, random_state=4)model = LogisticRegression().fit(X0, y) ​ ​​​​ ### 2. 판별함수 기반 모형 ​ 판별함수 기반 모형은 클래스의 영역을 나누는 경계면 혹은 경계선 함수 $ f(x) $ 를 정의하고, 이 판별함수 값의 부호에 따라 클래스가 나뉘어진다.​ $$$$ ​ \\text{판별 경계선} : f(x) = 0 ​ \\​ $$$$$$ ​ \\text{클래스 1} : f(x) > 0 ​ $$$$$$ ​ $$$$ ​ \\text{클래스 0} : f(x) < 0 ​​ scikit-learn에서는 decision_function메서드를 통해 판별함수 값을 출력할 수 있다.​​ 판별함수기반 모형으로는 퍼셉트론과 커널 SVM이 있다.​​​​ - 퍼셉트론​​ 가장 단순한 판별함수 모형으로, 두 개의 클래스만 구분해낼 수 있으며 직선으로 구분되는 경계선만을 찾아낸다.​​ 123456789​ from sklearn.linear_model import Perceptron​ from sklearn.datasets import load_iris​ iris = load_iris()​ idx = np.in1d(iris.target, [0, 2])​ X = iris.data[idx, 0:2]​ y = iris.target[idx]​ ​ model = Perceptron(max_iter=100, eta0=0.1, random_state=1).fit(X, y)​ ​​ ​​ ​​ 만약 데이터가 3차원이라면 경계선이 아닌 경계면(boundary surface)를 갖게 된다. 경계면 혹은 경계선을 decision hyperplane 이라고 한다.​​ ​​​​ - 커널 SVM​​ 직선인 경계면밖에 구분하지 못하는 퍼셉트론과 달리 곡선인 경계면을 찾아낼수 있다.​​ 123456789101112​ from sklearn import svm​ ​ xx, yy = np.meshgrid(np.linspace(-3, 3, 500),​ np.linspace(-3, 3, 500))​ np.random.seed(0)​ X = np.random.randn(300, 2)​ Y = np.logical_xor(X[:, 0] &gt; 0, X[:, 1] &gt; 0)​ ​ model = svm.NuSVC().fit(X, Y)​ Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])​ Z = Z.reshape(xx.shape)​ ​​ ​​ ​","categories":[{"name":"Math","slug":"Math","permalink":"https://jyujin39.github.io/categories/Math/"},{"name":"Classification","slug":"Math/Classification","permalink":"https://jyujin39.github.io/categories/Math/Classification/"}],"tags":[{"name":"study","slug":"study","permalink":"https://jyujin39.github.io/tags/study/"}]}]}