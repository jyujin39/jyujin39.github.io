<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>classification performance evaluation | Data Science YJ</title>
  <meta name="author" content="Yujin Jeon">
  
  <meta name="description" content="분류 성능 평가분류 문제는 회귀분석과 달리 다양한 성능 평가기준이 필요하다.
Scikit-Learn에서 제공하는 분류 성능평가 메서드들은 다음과 같다.
sklearn.metrics 서브 패키지

confusion_matrix()
classfication_report()">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="classification performance evaluation">
  <meta property="og:site_name" content="Data Science YJ">

  
    <meta property="og:image" content="">
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Data Science YJ" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>
</html>

<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Data Science YJ</a></h1>
  <h2><a href="/">my daily study blog for Data Science</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2018-12-01T15:00:00.000Z"><a href="/2018/12/02/classification_performance_evaluation/">2018-12-02</a></time>
      
      
  
    <h1 class="title">classification performance evaluation</h1>
  

    </header>
    <div class="entry">
      
        <h1 id="분류-성능-평가"><a href="#분류-성능-평가" class="headerlink" title="분류 성능 평가"></a>분류 성능 평가</h1><p>분류 문제는 회귀분석과 달리 다양한 성능 평가기준이 필요하다.</p>
<p>Scikit-Learn에서 제공하는 분류 성능평가 메서드들은 다음과 같다.</p>
<p><code>sklearn.metrics</code> 서브 패키지</p>
<ul>
<li><code>confusion_matrix()</code></li>
<li><code>classfication_report()</code></li>
<li><code>accuracy_score(y_true, y_pred)</code></li>
<li><code>precision_score(y_true, y_pred)</code></li>
<li><code>recall_score(y_true, y_pred)</code></li>
<li><code>fbeta_score(y_true, y_pred, beta)</code></li>
<li><code>f1_score(y_true, y_pred)</code></li>
</ul>
<h3 id="분류-결과표-Confusion-Matrix"><a href="#분류-결과표-Confusion-Matrix" class="headerlink" title="분류 결과표 Confusion Matrix"></a>분류 결과표 Confusion Matrix</h3><p>분류 결과표는 타겟의 실제 클래스와 모형이 예측한 클래스가 일치하는 개수를 표로 나타낸 것이다. 원래 클래스는 행으로, 예측한 클래스는 열로 나타낸다.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">예측 클래스 0</th>
<th style="text-align:center">예측 클래스 1</th>
<th style="text-align:center">예측 클래스 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>원래 클래스 0</strong></td>
<td style="text-align:center">2</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td><strong>원래 클래스 1</strong></td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td><strong>원래 클래스 2</strong></td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">2</td>
</tr>
</tbody>
</table>
</div>
<p>이를 코드로 구현하면 다음과 같다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">y_true = [<span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>]</span><br><span class="line">confusion_matrix(y_true, y_pred)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#분류결과표</span><br><span class="line">array([[2, 0, 0],</span><br><span class="line">       [0, 0, 1],</span><br><span class="line">       [1, 0, 2]])</span><br></pre></td></tr></table></figure>
<h2 id="이진-분류-결과표-Binary-Confusion-Matrix"><a href="#이진-분류-결과표-Binary-Confusion-Matrix" class="headerlink" title="이진 분류 결과표 Binary Confusion Matrix"></a>이진 분류 결과표 Binary Confusion Matrix</h2><p>클래스가 두 개인 경우에는 일반적으로 클래스 이름을 “Positive”와 “Negative”로 표시한다.</p>
<ul>
<li>positive : 특이한 케이스에 해당하는 경우</li>
<li>negative :  그렇지 않은 일반적인 경우</li>
</ul>
<p>이진 분류 결과표는 다음과 같은 모양이다.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">Positive라고 예측</th>
<th style="text-align:center">Negative라고 예측</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>실제 Positive</strong></td>
<td style="text-align:center">True Positive</td>
<td style="text-align:center">False Negative</td>
</tr>
<tr>
<td><strong>실제 Negative</strong></td>
<td style="text-align:center">False Positive</td>
<td style="text-align:center">True Negative</td>
</tr>
</tbody>
</table>
</div>
<h4 id="FDS-Fraud-Detection-System"><a href="#FDS-Fraud-Detection-System" class="headerlink" title="FDS (Fraud Detection System)"></a>FDS (Fraud Detection System)</h4><p>잘못된 거래 및 사기 거래 등을 예측하는 시스템으로, 예측 결과가 실제와 일치하는지에 따라 다음과 같이 구분한다.</p>
<ul>
<li><strong>TP</strong>(True Positive): 사기를 사기라고 정확하게 예측</li>
<li><strong>TN</strong>(True Negative): 정상을 정상이라고 정확하게 예측</li>
<li><strong>FP</strong>(False Positive): 정상을 사기라고 잘못 예측</li>
<li><strong>FN</strong>(False Negative): 사기를 정상이라고 잘못 예측</li>
</ul>
<p>FDS는 병의 진단에도 쓰일 수 있다. (positive: 병에 걸린 것, negative: 병에 걸리지 않은 것)</p>
<p>이진분류결과표에 따르면 분류모델의 성능평가척도가 4개로 추려지지만 그래도 여전히 많다.</p>
<p>그래서 그 4개의 수를 조합해 하나의 점수로 만든 것이 아래 설명할 평가점수다.</p>
<h3 id="평가-점수"><a href="#평가-점수" class="headerlink" title="평가 점수"></a>평가 점수</h3><p>FDS 의 결과로 나온 TP, TN, FP, FN 네 가지를 조합해 다음의 평가점수들을 계산한다.</p>
<ul>
<li>accuracy (정확도)</li>
<li>precision (정밀도)</li>
<li>recall (재현율)</li>
<li>fallout (위양성율)</li>
<li>F (beta) score</li>
</ul>
<h4 id="1-Accuracy"><a href="#1-Accuracy" class="headerlink" title="1) Accuracy"></a>1) Accuracy</h4><p>​    : 전체 샘플 중 맞게 예측한 샘플 수의 비율</p>
<script type="math/tex; mode=display">
\text{accuracy} = \dfrac{TP + TN}{TP + TN + FP + FN}</script><h4 id="2-Precision"><a href="#2-Precision" class="headerlink" title="2) Precision"></a>2) Precision</h4><p>​    : Positive 클래스라고 예측한 데이터 중 실제로 Positive에 해당하는 데이터의 비율</p>
<ul>
<li>사기거래 추정에서 일단 positive라고 추정이 됐으면 그게 실제 사기문제일 수 있기 때문에 중요하게 여겨지고, 사기거래 특정 시스템이 실제로 잘 작동하고 있는지 파악할 수 있어야 되기 때문에 precision점수가 중요하게 된다. </li>
</ul>
<script type="math/tex; mode=display">
\text{precision} = \dfrac{TP}{TP + FP}</script><h4 id="3-Recall"><a href="#3-Recall" class="headerlink" title="3) Recall"></a>3) Recall</h4><p>​    : 실제 Positive인 데이터 중 Positive라고 예측된 데이터의 비율</p>
<script type="math/tex; mode=display">
\text{recall} = \dfrac{TP}{TP + FN}</script><h4 id="4-Fall-Out"><a href="#4-Fall-Out" class="headerlink" title="4) Fall-Out"></a>4) Fall-Out</h4><p>​    : 실제 Negative인 데이터 중 Positive로 잘못 에측된 표본의 비율</p>
<script type="math/tex; mode=display">
\text{fallout} = \dfrac{FP}{FP + TN}</script><h4 id="5-F-beta-score"><a href="#5-F-beta-score" class="headerlink" title="5) F (beta) score"></a>5) F (beta) score</h4><p>​    :반비례관계에 있는 precision과 recall은 둘 다 중요한 점수이기 때문에 같이 봐야 하는데, 그 때 그 두 점수를 가중조화 평균낸 점수가 F-score다. 베타 값에 따라 달라진다.</p>
<p><img src="/Users/jeon-yujin/Library/Application%20Support/typora-user-images/image-20181201093234513.png" alt="image-20181201093234513"></p>
<script type="math/tex; mode=display">
F_\beta = \dfrac{(1 + \beta^2) \, ({\text{precision} \times \text{recall}})}{({\beta^2 \, \text{precision} + \text{recall}})}</script><ul>
<li>F1 score    (beta = 1)<script type="math/tex; mode=display">
F_1 = \dfrac{2\cdot\text{precision}\cdot\text{recall}}{\text{precision} + \text{recall}}</script></li>
</ul>
<p>Scikit-Learn의 metrics 패키지에서는 정밀도, 재현율, F1-score를 구하는 <code>classification_report</code> 명령을 제공한다. </p>
<p>이 명령은 각각의 클래스를 positive로 보았을 때의 precision, recall, F1-score를 구하고 그 평균값으로 전체 모형의 성능을 평가한다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import classification_report</span><br><span class="line"></span><br><span class="line">y_true = [0, 0, 0, 1, 1, 0, 0]</span><br><span class="line">y_pred = [0, 0, 0, 0, 1, 1, 1]</span><br><span class="line"></span><br><span class="line">print(classification_report(y_true, y_pred, target_names=[&apos;class 0&apos;, &apos;class 1&apos;]))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#결과</span><br><span class="line">             precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">    class 0       0.75      0.60      0.67         5</span><br><span class="line">    class 1       0.33      0.50      0.40         2</span><br><span class="line"></span><br><span class="line">avg / total       0.63      0.57      0.59         7</span><br></pre></td></tr></table></figure>
<p>위의 평가 점수들은 서로 밀접한 관계를 맺고 있다.</p>
<ul>
<li>재현율(recall)과 위양성률(fall-out)은 양의 상관 관계가 있다.</li>
<li>정밀도(precision)와 재현율(recall)은 대략적으로 음의 상관 관계가 있다.</li>
</ul>
<h3 id="Precision-vs-Recall"><a href="#Precision-vs-Recall" class="headerlink" title="Precision vs. Recall"></a>Precision vs. Recall</h3><p>분류모델 예측결과 precision과 recall이 모두 높으면 좋지만, 사실 두 점수는 반비례하는 경향이 있다.</p>
<p>precision은, 예를들어 의사가 진단을 하는 경우 의사의 권위 및 능력과 직결되는 점수이다. precision이 낮으면 신뢰도가 떨어지기때문에 의사는 precision을 높이기 위해 판별함수 f(x)의 기준점을 0보다 높게 설정하게 된다. f(x)가 10 이상인 경우에만 positive라고 진단해버림으로써 0이상 10 미만일 때 오진이었던 경우를 배제해버리는 것이다. 그러면 precision점수가 높아진다.</p>
<p>이와 반대로 recall을 높이려면 존재하는 모든 positive를 잡아내야만 하는 것이 목표가 된다. 그러기 위해서는 반대로 f(x)의 임계점을 0보다 낮게 만든다. 일단 negative인 것들도 막 잡아내고 보면 positive가 다 잡히게 되어있기 때문이다.</p>
<p>따라서 precision과 recall을 동시에 높이기는 쉽지 않다.</p>
<h3 id="ROC-커브"><a href="#ROC-커브" class="headerlink" title="ROC 커브"></a>ROC 커브</h3><p>ROC(Receiver Operator Characteristic) 커브란, fall-out과 recall 값이 판별함수 기준값의 변화에 따라 어떻게 달라지는지를 시각화한 것이다.</p>
<p>아래 표는, 16개의 데이터에 대해 판별함수 기준값을 0으로 설정하고 이진분류를 진행한 결과이다. </p>
<p><img src="/images/image-20181201094238076.png" alt=""></p>
<p>​    표를 보면 6번, 7번, 10번 데이터의 예측에 실패했음을 알 수 있다. 이 때 만약 판별함수 기준값을 6번데이터의 판별함수값인 0.244729보다 높이게 되면 6번데이터는 0클래스로 예측되게 되므로 정확한 예측이 된다. 이런 식으로 기준값을 높이거나 낮춰가면서 recall과 fall-out 점수를 확인하는 과정을 자동으로 진행하고 시각화해주는 것이 scikit-learn의 <code>roc_curve</code> 명령이다.</p>
<p><img src="/Users/jeon-yujin/Library/Application%20Support/typora-user-images/image-20181202204820835.png" alt="image-20181202204820835"></p>
<p>​    아래 그래프는 위 16개의 데이터에 대한 ROC 곡선이다.</p>
<p><img src="/images/image-20181202204930413.png" alt=""></p>
<p>  데이터가 더 많으면 더 곡선에 가까운 형태의 그래프가 그려진다.</p>
<h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p>분류모델은 Fall-Out 점수가 낮으면서 Recall이 높으면 좋기 때문에 ROC커브 그래프에서는 좌측 상단의 점이 높게 그려질수록 좋은 모델에 해당한다. 따라서 곡선 아래 면적이 클수록 좋은데, 그 면적을 측정한 것이 AUC(Area Under the Curve)이다. AUC가 1에 가까울수록 좋은 모델이라고 볼 수 있다. </p>
<p><img src="/images/image-20181201101735894.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import auc</span><br><span class="line">auc(fpr, tpr)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#AUC 결과값</span><br><span class="line">0.9112016520622872</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/Math/">Math</a>, <a href="/categories/Math/Classification/">Classification</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/study/">study</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
    
    
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">Comments</h1>

  
      <div id="fb-root"></div>
<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345";
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>

<div class="fb-comments" data-href="https://jyujin39.github.io/2018/12/02/classification_performance_evaluation/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div>
      
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:jyujin39.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/Math/Classification/">Classification</a><small>6</small></li>
  
    <li><a href="/categories/Math/">Math</a><small>6</small></li>
  
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/study/">study</a><small>6</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2018 Yujin Jeon
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>
