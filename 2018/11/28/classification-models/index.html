<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>classification models | Data Science YJ</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="분류모형분류(classification)는 독립 변수 값이 주어졌을 때 그 독립 변수 값과 가장 연관성이 큰 종속변수 카테고리(클래스)를 계산하는 문제이다.  분류 모형의 종류 판별함수(discriminant function) 모형 : 주어진 데이터를 서로 다른 영역으로 나누는 경계면을 찾는다.  확률적 모형   확률적 판별(discriminative) 모">
<meta name="keywords" content="study">
<meta property="og:type" content="article">
<meta property="og:title" content="classification models">
<meta property="og:url" content="https://jyujin39.github.io/2018/11/28/classification-models/index.html">
<meta property="og:site_name" content="Data Science YJ">
<meta property="og:description" content="분류모형분류(classification)는 독립 변수 값이 주어졌을 때 그 독립 변수 값과 가장 연관성이 큰 종속변수 카테고리(클래스)를 계산하는 문제이다.  분류 모형의 종류 판별함수(discriminant function) 모형 : 주어진 데이터를 서로 다른 영역으로 나누는 경계면을 찾는다.  확률적 모형   확률적 판별(discriminative) 모">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://jyujin39.github.io/images/image-20181128193332516.png">
<meta property="og:image" content="https://jyujin39.github.io/images/image-20181128195225135.png">
<meta property="og:image" content="https://jyujin39.github.io/images/image-20181128200223956.png">
<meta property="og:image" content="https://jyujin39.github.io/images/image-20181128201127059.png">
<meta property="og:image" content="https://jyujin39.github.io/images/image-20181128201158344.png">
<meta property="og:image" content="https://jyujin39.github.io/images/image-20181128201256638.png">
<meta property="og:image" content="https://jyujin39.github.io/images/image-20181128202549867.png">
<meta property="og:image" content="https://jyujin39.github.io/images/image-20181128202607054.png">
<meta property="og:updated_time" content="2018-12-07T08:36:11.533Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="classification models">
<meta name="twitter:description" content="분류모형분류(classification)는 독립 변수 값이 주어졌을 때 그 독립 변수 값과 가장 연관성이 큰 종속변수 카테고리(클래스)를 계산하는 문제이다.  분류 모형의 종류 판별함수(discriminant function) 모형 : 주어진 데이터를 서로 다른 영역으로 나누는 경계면을 찾는다.  확률적 모형   확률적 판별(discriminative) 모">
<meta name="twitter:image" content="https://jyujin39.github.io/images/image-20181128193332516.png">
  
    <link rel="alternate" href="/atom.xml" title="Data Science YJ" type="application/atom+xml">
  
  
    <link rel="icon" href="/icons8-account-40.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/styles.css">
  

</head>
</html>
<body>
  <nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class="" href="/index.html">Home</a></li>
        
          <li><a class="" href="/archives/">Archives</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title">Data Science YJ</h1>
  
    <p class="lead blog-description">my daily study blog for Data Science</p>
  
</div>

    <div class="row">
        <div class="col-sm-8 blog-main">
          <article id="post-classification-models" class="article article-type-post" itemscope="" itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 class="article-title" itemprop="name">
      classification models
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2018/11/28/classification-models/" class="article-date"><time datetime="2018-11-27T15:00:00.000Z" itemprop="datePublished">2018-11-28</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Math/">Math</a> / <a class="article-category-link" href="/categories/Math/Classification/">Classification</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="분류모형"><a href="#분류모형" class="headerlink" title="분류모형"></a>분류모형</h1><p><strong>분류</strong>(classification)는 독립 변수 값이 주어졌을 때 그 독립 변수 값과 가장 연관성이 큰 종속변수 카테고리(클래스)를 계산하는 문제이다. </p>
<h3 id="분류-모형의-종류"><a href="#분류-모형의-종류" class="headerlink" title="분류 모형의 종류"></a>분류 모형의 종류</h3><ul>
<li><p>판별함수(discriminant function) 모형</p>
<p>: 주어진 데이터를 서로 다른 영역으로 나누는 경계면을 찾는다.</p>
</li>
<li><p>확률적 모형 </p>
<ul>
<li><p>확률적 판별(discriminative) 모형</p>
<p>: 주어진 데이터가 특정 카테고리일 조건부확률을  직접 계산한다.</p>
</li>
<li><p>확률적 생성(generative) 모형</p>
<p>: 주어진 데이터가 특정 카테고리일 조건부확률을 베이즈정리를 통해 계산한다.</p>
</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>모형</th>
<th>방법론</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linear/Quadratic  Discriminant  Analysis</td>
<td>확률적 생성 모형</td>
</tr>
<tr>
<td>나이브 베이지안 (Naive  Bayes)</td>
<td>확률적 생성 모형</td>
</tr>
<tr>
<td>로지스틱 회귀 (Logistic Regression)</td>
<td>확률적 판별 모형</td>
</tr>
<tr>
<td>의사결정나무  (Decision Tree)</td>
<td>확률적 판별 모형</td>
</tr>
<tr>
<td>퍼셉트론  (Perceptron)</td>
<td>판별함수 모형</td>
</tr>
<tr>
<td>서포트 벡터 머신 (Support Vector Machine)</td>
<td>판별함수 모형</td>
</tr>
<tr>
<td>신경망 (Neural Network)</td>
<td>판별함수 모형</td>
</tr>
</tbody>
</table>
</div>
<h3 id="1-확률적-모형"><a href="#1-확률적-모형" class="headerlink" title="1. 확률적 모형"></a>1. 확률적 모형</h3><h4 id="1-확률적-생성모형"><a href="#1-확률적-생성모형" class="headerlink" title="1) 확률적 생성모형"></a>1) 확률적 생성모형</h4><p>조건부확률 기반 생성모형의 장점 중 하나는 클래스가 3개 이상인 경우에도 바로 적용할 수 있다는 점이다.</p>
<p>생성모형은 더 구하기 쉬운 클래스별 특징 데이터의 확률분포 $ P(x |  y = k) $, 즉 가능도를  먼저 추정한 다음 베이즈 정리를 사용하여 $ P(y = k | x) $ 를 계산한다.</p>
<script type="math/tex; mode=display">
P(y = k |  x) = \dfrac{P(x | y = k)P(y  = k)}{P(x)}</script><p>또한 전체확률의 법칙을 이용하여  $ P(x)  $ 를 구할 수 있다. 이 값을 알면  x라는 데이터만 입력되어도 그 데이터 자체가 정상적인 데이터인지 아닌지 판단할 수 있다.</p>
<script type="math/tex; mode=display">
P(x)  = \sum^K_{k=1}P(x|y = k)P(y = k)</script><p>확률적 생성모형의 예로 QDA와 Naive Bayesian model이 있다.</p>
<ul>
<li><p><strong>QDA</strong></p>
<p>QDA(Quadratic Discriminant Analysis)에서는 다음과 같은 코드로 분류문제를 푼다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> QuadraticDiscriminantAnalysis</span><br><span class="line">model = QuadraticDiscriminantAnalysis().fit(X, y)</span><br><span class="line">test_data =  [[<span class="number">0.2</span>, <span class="number">0.2</span>]]</span><br><span class="line">p = model.predict_proba(test_data)</span><br></pre></td></tr></table></figure>
<p><img src="/images/image-20181128193332516.png" alt=""></p>
<ul>
<li><p>나이브 베이지안 모형**</p>
<p><code>TfidfVectorizer</code> 전처리기는 텍스트 데이터를 BoW에  따라 실수 벡터로 변환한다. </p>
<p><code>MultinomialNB</code> 모형은 나이브 베이즈 방법으로 분류 문제를 예측한다. </p>
<p><code>Pipeline</code>을 사용하여 이 두 클래스 객체를 하나의 모형으로 합친다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_20newsgroups</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line">news = fetch_20newsgroups(subset=<span class="string">"all"</span>)</span><br><span class="line">model = Pipeline([</span><br><span class="line">    (<span class="string">'vect'</span>, TfidfVectorizer(stop_words=<span class="string">"english"</span>)),</span><br><span class="line">    (<span class="string">'nb'</span>, MultinomialNB()),</span><br><span class="line">])</span><br><span class="line">model.fit(news.data, news.target)</span><br></pre></td></tr></table></figure>
<p><img src="/images/image-20181128195225135.png" alt=""></p>
<p>​    20개의 클래스 중 3번 클래스에 가장 높은 조건부확률을 갖기 때문에 3번째 클래스에 해당한다고 판별한다.</p>
<h4 id="2-확률적-판별-모형"><a href="#2-확률적-판별-모형" class="headerlink" title="2) 확률적 판별 모형"></a>2) 확률적 판별 모형</h4><p>확률적 생성 모형과 달리 확률적 판별 모형에서는  조건부확률 $  p(y = 1 |  x) $ 가 x값에 따라 0에서 1 사이에서 달라지는 값을 갖는 함수라고 가정하고, 그 함수를 직접 찾아낸다.</p>
<script type="math/tex; mode=display">
p(y = k |  x) = f(x)</script><p>​    확률적 판별 모형에는 로지스틱 회귀모형과 의사결정나무가 있다.<br>​<br>​<br>​    </p>
<pre><code>- **로지스틱** **회귀모형**

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">X0, y = make_classification(n_features=<span class="number">1</span>, n_redundant=<span class="number">0</span>,</span><br><span class="line">n_informative=<span class="number">1</span>, n_clusters_per_class=<span class="number">1</span>, random_state=<span class="number">4</span>)</span><br><span class="line">model = LogisticRegression().fit(X0, y)</span><br></pre></td></tr></table></figure>
</code></pre><p>​    <img src="/images/image-20181128200223956.png" alt=""><br>​<br>​<br>​<br>​    ### 2. 판별함수 기반 모형</p>
<p>​    판별함수 기반 모형은 클래스의 영역을 나누는 경계면 혹은 경계선 함수 $ f(x) $ 를 정의하고, 이  판별함수 값의 부호에 따라 클래스가 나뉘어진다.<br>​    <script type="math/tex">$$$$
​    \text{판별 경계선} : f(x) = 0
​    \</script><br>​    <script type="math/tex">$$$$$$
​    \text{클래스 1} : f(x) > 0
​    $$$$$$
​    $$$$
​    \text{클래스 0} : f(x) < 0
​</script><br>​    scikit-learn에서는 <code>decision_function</code>메서드를 통해 판별함수 값을 출력할 수 있다.<br>​<br>​    판별함수기반 모형으로는 퍼셉트론과  커널 SVM이 있다.<br>​<br>​<br>​<br>​    - <strong>퍼셉트론</strong><br>​<br>​    가장 단순한 판별함수 모형으로, 두 개의 클래스만 구분해낼 수 있으며 직선으로 구분되는 경계선만을 찾아낸다.<br>​<br>​    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">​    <span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line">​    <span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line">​    iris = load_iris()</span><br><span class="line">​    idx = np.in1d(iris.target, [<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">​    X = iris.data[idx, <span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">​    y = iris.target[idx]</span><br><span class="line">​    </span><br><span class="line">​    model = Perceptron(max_iter=<span class="number">100</span>, eta0=<span class="number">0.1</span>, random_state=<span class="number">1</span>).fit(X, y)</span><br><span class="line">​</span><br></pre></td></tr></table></figure></p>
<p>​<br>​    <img src="/images/image-20181128201127059.png" alt=""><br>​<br>​    <img src="/images/image-20181128201158344.png" alt=""><br>​<br>​    만약 데이터가 3차원이라면 경계선이 아닌 경계면(boundary surface)를 갖게 된다. 경계면 혹은 경계선을 decision hyperplane 이라고 한다.<br>​<br>​    <img src="/images/image-20181128201256638.png" alt=""><br>​<br>​<br>​<br>​    - <strong>커널 SVM</strong><br>​<br>​    직선인 경계면밖에 구분하지 못하는 퍼셉트론과 달리 곡선인 경계면을 찾아낼수 있다.<br>​<br>​    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">​    <span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">​    </span><br><span class="line">​    xx, yy = np.meshgrid(np.linspace(<span class="number">-3</span>, <span class="number">3</span>, <span class="number">500</span>),</span><br><span class="line">​    np.linspace(<span class="number">-3</span>, <span class="number">3</span>, <span class="number">500</span>))</span><br><span class="line">​    np.random.seed(<span class="number">0</span>)</span><br><span class="line">​    X = np.random.randn(<span class="number">300</span>, <span class="number">2</span>)</span><br><span class="line">​    Y = np.logical_xor(X[:, <span class="number">0</span>] &gt; <span class="number">0</span>, X[:, <span class="number">1</span>] &gt; <span class="number">0</span>)</span><br><span class="line">​    </span><br><span class="line">​    model = svm.NuSVC().fit(X, Y)</span><br><span class="line">​    Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">​    Z = Z.reshape(xx.shape)</span><br><span class="line">​</span><br></pre></td></tr></table></figure></p>
<p>​<br>​    <img src="/images/image-20181128202549867.png" alt=""><br>​<br>​    <img src="/images/image-20181128202607054.png" alt=""><br>​    </p>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://jyujin39.github.io/2018/11/28/classification-models/" data-id="cjpm75a480000zebac150h9yg" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/study/">study</a></li></ul>


    </footer>
  </div>
  
    
<ul id="article-nav" class="nav nav-pills nav-justified">
  
  
  <li role="presentation">
    <a href="/2018/11/29/multi-class-classification/" id="article-nav-newer" class="article-nav-link-wrap">
      <span class="article-nav-link-title">multi-class classification</span>
      <i class="fa fa-chevron-right pull-right"></i>
    </a>
  </li>
  
</ul>


  
</article>




        </div>
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p>Welcome to <strong>yujin's git blog</strong> for data science!</p>

</div>


  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/Math/">Math</a><span class="sidebar-module-list-count">6</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/Math/Classification/">Classification</a><span class="sidebar-module-list-count">6</span></li></ul></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="/2018/12/12/entropy/">entropy</a>
        </li>
      
        <li>
          <a href="/2018/12/07/naive_bayesian_classification_model/">naive bayesian classification model</a>
        </li>
      
        <li>
          <a href="/2018/12/06/QDA_LDA/">QDA &amp; LDA</a>
        </li>
      
        <li>
          <a href="/2018/12/02/classification_performance_evaluation/">classification performance evaluation</a>
        </li>
      
        <li>
          <a href="/2018/11/29/multi-class-classification/">multi-class classification</a>
        </li>
      
    </ul>
  </div>


  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/12/">December 2018</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/11/">November 2018</a><span class="sidebar-module-list-count">2</span></li></ul>
  </div>



  


        </div>
    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2018 Yujin Jeon<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

  

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>



<script src="/js/script.js"></script>

</body>
</html>
